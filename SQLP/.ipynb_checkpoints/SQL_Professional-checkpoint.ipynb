{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27cbf588",
   "metadata": {},
   "source": [
    "# SQL 고급 활용 및 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367cef90",
   "metadata": {},
   "source": [
    "# 제 1장 아키텍처 기반 튜닝 원리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee8842e",
   "metadata": {},
   "source": [
    "# 제1절 데이터베이스 아키텍처"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08a9a55",
   "metadata": {},
   "source": [
    "## 1. 아키텍처 개관"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561ea934",
   "metadata": {},
   "source": [
    "### 가. ORACLE 아키텍처"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2b2b82",
   "metadata": {},
   "source": [
    "- 데이터베이스 : 물리적인 디스크에 저장된 데이터집합 (데이터파일, 리두로그파일, 컨트롤파일)\n",
    "- 인스턴스 : 공유메모리(SGA)와 이를 엑세스하는 프로세스 집합\n",
    "\n",
    "#### 하나의 인스턴스는 하나의 데이터베이스를 액세스(Single)\n",
    "#### 여러개의 인스턴스는 하나의 데이터베이스를 엑세스(RAC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15d2f5e",
   "metadata": {},
   "source": [
    "### 나. SQL Server 아키텍처"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baf45f1",
   "metadata": {},
   "source": [
    "- 하나의 인스턴스당 최고 32,767개의 데이터베이스를 정의해서 사용\n",
    "- 기본적으로 시스템데이터베이스가 만들어지면, 사용자데이터베이스를 추가하여 생성하는 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6997b8a4",
   "metadata": {},
   "source": [
    "- 시스템데이터베이스 : mster, model, msdb, tempdb 등\n",
    "- 사용자데이터베이스 : 데이터파일(mdf), 트랜잭션로그파일(ldf), 보조데이터파일(ndf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8240afb7",
   "metadata": {},
   "source": [
    "## 2. 프로세스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cdd279",
   "metadata": {},
   "source": [
    "- 서버프로세스 : 전면에 나서 사용자가 던지는 각종 명령을 처리\n",
    "- 백그라운드프로세스 : 뒤에서 묵묵히 주어진 역할을 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbd5d1e",
   "metadata": {},
   "source": [
    "### 가. 서버프로세스(Server Process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000c9d4c",
   "metadata": {},
   "source": [
    "- 사용자 프로세스와 통신하면서 사용자의 각종 명령어 처리\n",
    "- ORACLE : 서버프로세스\n",
    "- SQL Server : Worker thread\n",
    "\n",
    "#### 처리절차\n",
    "- 사용자의 요청\n",
    "- SQL 파싱\n",
    "- 커서를 열어서 SQL을 실행하면서 블록 READ\n",
    "- 읽은 데이터를 정렬하여 요청한 결과집합을 만들어 네트워크를 통해 전송"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90ec961",
   "metadata": {},
   "source": [
    "#### 클라이언트가 서버프로세스와 연결하는 방식(예 오라클)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68278031",
   "metadata": {},
   "source": [
    "#### 전용서버 방식(Dedicated Server)\n",
    "- 클라이언트 세션과 서버프로세스가 1:1 로 매핑\n",
    "- 오라클의 가장 일반적인 방식\n",
    "- 클라이언트 요청에 의해 리스너 프로세스는 dedicated server 생성\n",
    "- 새로운 dedicated server 프로세스는 리스너에 의해 커넥션 권한을 상속받음\n",
    "- 데이터베이스와 물리적인 커넥션을 맺음\n",
    "\n",
    "\n",
    "1. (User)     연결요청                       ==> (Listener)\n",
    "2. (Listnenr) 프로세스 생성 및 연결요청 상속 ==> (Server)\n",
    "3. (Server)   RESEND 패킷 전송               ==> (User)\n",
    "4. (User)     연결 후 작업 요청              ==> (Server)\n",
    "5. (Server)   처리 후 결과 전송              ==> (User)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcf5fea",
   "metadata": {},
   "source": [
    "#### 공유서버 방식(Shared Server)\n",
    "- 클라이언트 세션과 서버프로세스가 1:N로 매핑\n",
    "- 클라이언트 요청에 의해 리스너 프로세스는 현재 사용가능한 dispatcher pool 탐색확인\n",
    "- 리스너는 사용가능한 dispatcher 커넥션 정보를 클라이언트에 되돌려줌\n",
    "- 클라이언트는 리스너 접속을 끝내고 바로 dispatcher로 접속\n",
    "\n",
    "1. (User) 연결요청 ==> (Listener)\n",
    "2. (Listener) 가용한 Dispatcher 포트번호 전송 ==> (User)\n",
    "3. (User) 연결 후 작업 요청 ==> (Dispatcher)\n",
    "4. (Dispatcher) 요청등록 ==> (SGA Request Queue)\n",
    "5. (SGA Request Queue) 요청접수 ==> (Server)\n",
    "6. (Server) 결과 등록 ==> (SGA Reponcse Queue)\n",
    "7. (SGA Reponcse Queue) 결과수렴 ==> (Dispatcher)\n",
    "8. (Dispatcher) 결과 전송 ==> (User)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f18350e",
   "metadata": {},
   "source": [
    "### 나. 백그라운드프로세스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d228ce",
   "metadata": {},
   "source": [
    "####              오라클                 ==                       SQL SERVER\n",
    "**SMON(System Monitor) == Databese cleanup / Shrinking Thread**\n",
    "- 장애가 발생한 시스템을 재기동할 때 인스턴스 복구를 수행하고, 임시 세그먼트와 익스텐트를 모니터링한다.\n",
    "\n",
    "**PMON(Process Monitor) == Open data Services(OPS)**\n",
    "- 이상이 생긴 프로세스가 사용하던 리소스를 복구한다.\n",
    "\n",
    "**DBWn(Database Writers) == Lazywriter Thread**\n",
    "- 버퍼 캐시에 있는 더티 버퍼를 데이터 파일에 기록\n",
    "\n",
    "**LGWR(Log Writer) == Log writer Thread**\n",
    "- 로그 버퍼 엔트리를 redo 로그 파일에 기록한다.\n",
    "\n",
    "**ARCn(Archiver) == N/A**\n",
    "- 꽉찬 리두로그가 덮어 쓰여지기 전에 archive로그 디렉토리로 백업한다.\n",
    "\n",
    "**CKPT(Checkpoint) == Database Checkpoint Thread**\n",
    "- checkpoint 프로세스는 이전의 checkpoint가 일어났던 마지막 시점 이후의 데이터베이스 변경 사항을 데이터파일에 기록하도록  \n",
    "트리거링하고, 기록이 완료되면 현재 어디까지 기록했는지를 컨트롤 파일과 데이터 파일 헤더에 기록한다.\n",
    "- 좀더 자세히 설명하면 write Ahead Logging 방식을 사용하는 DBMS는 리두로그에 기록해 둔 버퍼 브록에 대한 변경사항 중\n",
    "현재 어디까지를 데이터 파일에 기록했는지 체크 포인트정보를 관리해야 한다.\n",
    "- 이는 버퍼캐시와 데이터 파일이 동기화된 시점을 가리키며, 장애가 발생하면 마지막 체크포인트 이후 로그 데이터만 디스크에 \n",
    "기록함으로써 인스턴스를 복구할 수 있도록 하는 용도로 사용된다.\n",
    "- 이 정보를 갱신하는 주기가 길수록 장애 발생시 인스턴스 복구 시간도 길어진다.\n",
    "\n",
    "**RECO(Recoverer) == Distributed Transaction Coordinator(DTC)**\n",
    "- 분산 트랜잭션 과정에 발생한 문제를 해결한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0698c6cd",
   "metadata": {},
   "source": [
    "## 3. 파일구조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f43312",
   "metadata": {},
   "source": [
    "### 가. 데이터파일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e24499",
   "metadata": {},
   "source": [
    "1) **블록(=페이지)**\n",
    "- 대부분의 DBMS에서는 I/O 블록단위로 이루어짐\n",
    "- 데이터를 읽고 쓸때의 논리적인 단위\n",
    "- SQL 성능을 좌우하는 가장 중요한 성능지표\n",
    "- 옵티마이저의 파단에 가장 큰 영향을 미치는 요소"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2765302",
   "metadata": {},
   "source": [
    "2) **익스텐트(Extent)**\n",
    "- 테이블스페이스로부터 공간을 할당하는 단위"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1596735",
   "metadata": {},
   "source": [
    "3) **세그먼트(Segment)**\n",
    "- 테이블, 인덱스, Undo 처럼 저장공간을 필요로하는 데이터베이스 오브젝트 (한개 이상의 익스텐트 사용)\n",
    "- 파티션은 오브젝트와 세그먼트가 1:M (파티션을 만들면 내부적으로 여러개의 세그먼트가 만들어짐)\n",
    "- 한 세그먼트에 할당된 엑스텐트가 여러 데이터파일에 흩어져 저장됨 (디스크 경합감소. I/O 분산효과)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a597f64",
   "metadata": {},
   "source": [
    "4) **테이블스페이스(Tablespace)**\n",
    "- 세그먼트를 담는 콘테이너로서 여러개의 데이터파일로 구성됨\n",
    "- 사용자는 데이터파일을 직접 선택할 수 없으므로 실제 파일을 선택하고 익스텐트를 할당하는것은 DBMS의 몫"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f229911",
   "metadata": {},
   "source": [
    "### 나. 임시파일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda789ea",
   "metadata": {},
   "source": [
    "- 대량의 정렬이나 해시 작업을 수행하다가 메모리 공간이 부족해지면 중간 결과집합을 저장하는 용도\n",
    "- 오라클에서는 임시 테이블스페이스를 여러개 생성해두고, 사용자마다 별도의 임시 테이블스페이스를 지정해 줄 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76abd996",
   "metadata": {},
   "source": [
    "### 다. 로그파일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92400cc5",
   "metadata": {},
   "source": [
    "- DB 버퍼 캐시에 가해지는 모든 변경사항을 기록하는 파일\n",
    "- 로그 기록은 Append 방식으로 이루어지기 때문에 상대적으로 매우 빠름\n",
    "- 빠른 커밋 지원"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994a96e4",
   "metadata": {},
   "source": [
    "### 로그파일\n",
    "#### 리두로그(오라클)\n",
    "- 트랜잭션의 데이터 유실 방지\n",
    "- 마지막 체크포인트이후 사고 발생 직전까지 수행되었던 트랜잭션을 Redo 로그를 이용해서 재현함 (캐시복구)\n",
    "- 최소 두개 이상의 파일로 구성하며 round-robin 방식 이용하여 사용\n",
    "\n",
    "#### 트랜잭션로그(SQL Server)\n",
    "- 데이터파일(데이터베이스)마다 트랜잭션 로그 파일이 하나씩 생성됨(ldf)\n",
    "- 가상로그파일이라고 불리는 더 작은 세그먼트 단위로 나뉨\n",
    "- 가상로그파일 개수가 너무 많아지지 않도록 옵션을 지정(로그파일을 넉넉한 크기로 만들어 자동 증가가 발생하지   \n",
    "않도록 하거나, 증가단위를 크게 지정)\n",
    "\n",
    "\n",
    "### Archved(=Offline) Redo 로그\n",
    "#### Archived Redo 로그\n",
    "- 오라클에서 온라인 리두로그가 재사용 되기 전에 다른 위치로 백업해둔 파일\n",
    "- 디스크가 꺠지는 등의 물리적인 저장매체 장애에 대해서 복구하기 위해 사용\n",
    "- SQL Server는 Archived Redo 로그에 대응되는 개념 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b4e59b",
   "metadata": {},
   "source": [
    "## 4. 메모리구조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b400fd1",
   "metadata": {},
   "source": [
    "### 시스템 공유 메모리영역\n",
    "### System Global Area(SGA) == Memory Pool\n",
    "- 여러 프로세스가 동시에 액세스할 수 있는 메모리 영역\n",
    "- 모든 DBMS는 공통적으로 사용하는 캐시 영역이 있음(DB 버퍼캐시, 공유풀, 로그 버퍼)\n",
    "- 그 외에 Large Poolm, Java Pool, 시스템 구조와 제어 구조를 캐싱하는 영역을 포함하고 있음\n",
    "- 여러 프로세스가 공유되기 때문에 내부적으로 Latch, 버퍼Lock, 라이브러리 캐시 Lock/Pin같은 액세스 직렬화 매커니즘 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfe6dec",
   "metadata": {},
   "source": [
    "### 프로세스 전용 메모리영역\n",
    "- 오라클은 프로세스 기반의 아키텍처로 서버 프로세스가 자신만의 전용 메모리 영역을 가짐 (Process Global Area(PGA))\n",
    "- 데이터를 정렬하고 세션과 커서 정보를 저장\n",
    "- 쓰레드기반의 아키텍처를 사용하는 SQL Server는 프로세스 전용 메모리 영역을 갖지 않는다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691d76f7",
   "metadata": {},
   "source": [
    "### 가. DB 버퍼캐시\n",
    "- 데이터파일로부터 읽어들인 데이터 블록을 담는 캐시영역\n",
    "- 사용자 프로세스는 서버 프로세스를 통해 DB 버퍼 캐시의 버퍼 블록을 동시에 액세스 (내부적으로 Buffer Lock을 통한 직렬화)\n",
    "- Direct Path Read 매커니즘이 작동하는 경우를 제외하면, 모든 블록 읽기는 버퍼 캐시를 통해 이루어짐\n",
    "- 디스크에서 읽을때도 버퍼캐시에 적재한 후 읽음\n",
    "- 변경된 블록(더티버퍼)은 주기적으로 DBWR 프로세스에 의해 데이터파일에 기록\n",
    "- 디스크 I/O는 물리적으로 액세스암이 움직이면서 헤드를 통해 이루어지는 반면, 메모리 I/O는 전기적신호에 불과하기 때문에   \n",
    "  디스크 I/O와 비교할수 없을 정도로 빠름."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9d8655",
   "metadata": {},
   "source": [
    "#### 1) 버퍼블록상태\n",
    "**Free Buffer**\n",
    "- 인스턴스 기둥호 아직 데이터가 읽혀지지 않아 비어 있는 상태이거나, 데이터파일과 서로 동기화 되어 언제든지 덮어써도 되는 상태\n",
    "\n",
    "**Dirty Buffer**\n",
    "- 버퍼가 캐시된 이후 변경이 발생하지만, 아직 디스크에 기록되지 않아 데이터파일 블록과 동기화가 필요한 버퍼 블록.\n",
    "- 이 버퍼 블록이 재사용 되려면 디스크에 먼저 기록되어야 하고 디스크에 기록된 순간 Free 버퍼로 변경\n",
    "\n",
    "**Pinned Buffer**\n",
    "- 읽기 또는 쓰기 작업이 현재 진행중인 버퍼 블록"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4843bf1",
   "metadata": {},
   "source": [
    "#### 2) LRU 알고리즘\n",
    "- 버퍼 캐시는 유한한 자원이므로 모든 데이터를 캐싱해 둘 수 없기 때문에 사용 빈도가 높은 데이터 블록 위주로  \n",
    "  버퍼 캐시가 구성 되도록 LRU 알고리즘을 사용\n",
    "- 모든 버퍼 블록헤더를 LRU 체인에 연결해 사용 빈도 순으로 위치를 옮기다가(Touch count가 높을수록 MRU)  \n",
    "  Free 버퍼가 필요해지면, 엑세스 빈도가 낮은(LRU) 쪽 데이터 블록부터 밀어내는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322b3fa8",
   "metadata": {},
   "source": [
    "### 나. 공유풀(shared pool)\n",
    "- 딕셔너리캐시와 라이브러리 캐시로 구성되며 버퍼 캐시처럼 LRU 알고리즘을 사용\n",
    "\n",
    "#### 1) 딕셔너리 캐시\n",
    "- 테이블, 인덱스같은 오브젝트는 물론 테이블스페이스, 데이터파일, 세그먼트, 익스텐트, 사용자, 제약사항과 같은 메타정보 저장\n",
    "\n",
    "#### 2) 라이브러리캐시\n",
    "- SQL 실행에 관련된 모든 객체에 대한 정보 관리\n",
    "- 서버 프로세스가 SQL을 작업할때 사용되는 작업공간\n",
    "- SQL에 대한 분석정보 및 실행계획 저장\n",
    "- 공유 SQL을 저장하기 위해 사용\n",
    "\n",
    "- 라이브러리 캐시는 캐싱된 SQL과 그 실행계획의 재사용성을 높이는 것이 수행 성능을 높이고 DBMS 부하를 최소화 하는 핵심원리임\n",
    "- 바인드변수 사용 및 기준에 맞는 SQL 작성으로 재사용성을 높여 줘야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f89ca0",
   "metadata": {},
   "source": [
    "### 다. 로그버퍼\n",
    "- Only Recovery를 위해 사용됨.\n",
    "- DB버퍼에 가해지는 모든 변경사항을 로그버퍼에 먼저 기록\n",
    "- **Physiolosical logging**\n",
    "    - physical logging과 logical logging의 장점을 결합한것으로 변경된 데이터에 대한 before/after 이미지를 저장하고  \n",
    "      opcode(명세서)를 기록하여 완벽한 복구를 보장\n",
    "- **page fix rule**\n",
    "    - 변경이 시작되는 시점부터 완료되는 시점까지 해당 블록을 보호해주는 아키텍처로 os에서 세마포어를 할당받아서  \n",
    "      세마포어가 해당 블록을 보호\n",
    "- **log a head**\n",
    "    - 데이터 변경작업시에 DBWR에 의한 블록 변경보다 로그를 먼저 기록하는 기법\n",
    "- **log force at commit**\n",
    "    - 커밋시 리두로그를 먼저 기록하는 기법, 기록하는 속도가 빠른 리두를 먼저 기록하게 하여 중간에 발생하는   \n",
    "      장애로부터 완벽한 복구를 보장하는 기법\n",
    "- **logical odering of redo**\n",
    "    - 로그를 기록할때 정해진 위치가 아닌 순서와 무관하게 기록하되, scn과 RBA를 이용하여 복구에 대한 순서를 결정하여 빠른 복구 보장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cb67f1",
   "metadata": {},
   "source": [
    "### 라. PGA(Process Global Area)\n",
    "- 오라클의 서버 프로세스는 자신만의 PGA 메모리 영역을 할당받아 이를 프로세스에 종속적인 고유 데이터를 저장하는 용도로 사용\n",
    "- PGA는 다른 프로세스와 공유되지 않은 독립적인 메모리 공간으로 똑같은 개수의 블록을 읽더라도 SGA 버퍼 캐시에서 읽는것보다 훨씬 빠름\n",
    "\n",
    "#### 1) UGA(User Global Area)\n",
    "- 각 세션을 위한 독립적인 공간\n",
    "- Dedicated Server : PGA에 UGA영역 할당\n",
    "- Shared Server: SGA의 Large Pool 또는 Shared Pool에 UGA 영역 할당\n",
    "\n",
    "#### 2) CGA(Call Global Area)\n",
    "- 오라클은 하나의 데이터베이스 Call을 넘어서 다음 Call까지 계속 참조되는 정보를 UGA에 담고, call이   \n",
    "  진행되는 동안 필요한 데이터는 CGA에 담는다\n",
    "- Parse Call, Execute Call, Fetch Call 마다 매번 할당 받음\n",
    "- Call이 진행되는동안 Recursive call이 발생하면 그 안에서도 Parse, Execute, Fetch 단계별로 CGA 할당\n",
    "- 할당된 공간은 Call이 끝나자마자 해제되어 PGA에 반환\n",
    "\n",
    "#### 3) Sort Area\n",
    "- 데이터 정렬을 위해 사용되며, 부족할때 마다 chunk 단위로 조금씩 할당됨\n",
    "- 세션마다 sort_area_size 파라미터로 설정가능\n",
    "- 9i 이상부터는 workarea_size_policy 파라미터를 auto로 설정하면 내부적으로 알아서 sort area를 할당해줌\n",
    "\n",
    "**DML : CGA 영역에 할당**  \n",
    "**SELECT : 수행중간단계에 필요한 sort area는 CGA에 할당, 최종 결과집합을 출력하기 직전 단계에서 필요한 sort area는 UGA에 할당**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0bfc31",
   "metadata": {},
   "source": [
    "## 5. 대기 이벤트\n",
    "- DBMS 내부에서 활동하는 수많은 프로세스간에서는 상호작용이 필요하며, 그 과정에서 다른 프로세스가 일을 마칠때까지 기다려야하는 상황이 발생\n",
    "- 그때마다 해당 프로세스는 자신이 일을 계속 진행할 수 있는 조건이 충족될때까지 수면(Sleep)상태로 대기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e86a27",
   "metadata": {},
   "source": [
    "- **Reponse Time** = \n",
    "    - Service Time + Wait Time     \n",
    "    - CPU Time + Queue Time \n",
    "    \n",
    "- 서비스시간(Service Time = CPU Time): 프로세스가 정상적으로 동작하며 일을 수행한 시간\n",
    "- 대기시간(Wait Time = Queue Time): 프로세스가 잠시 수행을 멈추고 대기한 시간\n",
    "- Response Time Analysis 방법론은 Cpu Time과 Wait Time을 각각 Break down 하면서 서버의 일량과 대기시간을 분석\n",
    "- Wait TIme은 각각 발생한 대기 이벤트를 분석해서 가장 시간을 많이 소비한 이벤트 중심으로 해결방안 모색"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad7ddb0",
   "metadata": {},
   "source": [
    "### 가. 라이브러리캐시 부하\n",
    "- 라이브러리 캐시에서 SQL 커서를 찾고 최적화 하는 과정에서 경합이 발생하여 나타난 대기이벤트\n",
    "    - latch : shared pool\n",
    "    - latch : library cache\n",
    "- 라이브러리 캐시와 관련해서 자주발생하는 대기 이벤트로, 수행중인 SQL이 참조하는 오브젝트에 다른 사용자가 DDL문장을 수행할 때 \n",
    "    - library cache lock\n",
    "    - library cache pin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f4d33b",
   "metadata": {},
   "source": [
    "### 나. 데이터베이스 call과 네트워크 부하\n",
    "- 애플리케이션과 네트워크 구간에서 소모된 시간에 의해 나타난 이벤트\n",
    "    - SQL*Net message from client : client로부터 다음 명령이 올떄까지 idle 상태로 기다릴때 발생   \n",
    "      (데이터베이스 경합과 관계없음)\n",
    "    - SQL*Net message to client : 메시지를 보냈는데 메시지를 받았다는 신호가 늦게 도착하는경우 이거나,\n",
    "      클라이언트가 너무 바쁠경우\n",
    "    - SQL*Net more data to client: 메시지를 보냈는데 메시지를 받았다는 신호가 늦게 도착하는 경우 이거나,\n",
    "      클라이언트가 너무 바쁠경우\n",
    "    - SQL*Net more data from client : 클라이언트로부터 더 받을 데이터가 있는데 지연이 발생한 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b2c48c",
   "metadata": {},
   "source": [
    "### 다. 디스크 부하\n",
    "- 디스크 I/O 발생할 때 나타나는 대기 이벤트\n",
    "    - db file sequential read : Single Block I/O call에 하나의 데이터 블록만 읽음.    \n",
    "      인덱스 블록을 읽을때 발생\n",
    "    - db file scattered read : Multi Block I/O. Table Full Scan 또는 Index Fast Full Scan시 나타남\n",
    "    - direct path read\n",
    "    - direct path write\n",
    "    - direct path write temp\n",
    "    - direct path read temp\n",
    "    - db file parallel read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623350b6",
   "metadata": {},
   "source": [
    "### 라. 버퍼캐시 경합\n",
    "- 버퍼캐시에서 블록을 읽는 과정에서 경합이 발생하여 나타나는 대기 이벤트\n",
    "    - latch : cache buffers chains\n",
    "    - latch : cache buffers lru chain\n",
    "    - buffers busy waits\n",
    "    - free buffer waits\n",
    "- 해소 방법은 I/O 부하 해소 방법과 비슷함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965e1d65",
   "metadata": {},
   "source": [
    "### 마. LOCK관련 대기이벤트 \n",
    "- Lock과 관련된 대기이벤트\n",
    "    - enq : TM - contention\n",
    "    - enq : TX - row lock contention\n",
    "    - enq : TX - index contention\n",
    "    - enq : TX - allocate ITL entry\n",
    "    - enq : TX contention\n",
    "    - latch free : 특정 자원에 대한 래치를 여러차례(2000번 가량) 요구했지만 해당 자원이 계속 사용중이어서  \n",
    "      잠시 대기 상태로 빠질때마다 발생\n",
    "- Lock은 사용자 데이터를 보호하는 반면, Latch는 SGA에 공유되어 있는 갖가지 자료구조를 보호할 목적으로 사용하는 가변운 LOCK\n",
    "- Latch도 일종의 Lock이지만 큐잉(Queueing) 매커니즘을 사용하지 않음\n",
    "- 특정자원에 액세스하려는 프로세스는 래치 획득에 성공할때까지 반복해서 시도하나, 우선권은 부여받지 못함  \n",
    "  (처음시도한 래치가 맨 나중에 래치획득에 성공할수도 있음)\n",
    "- 그외 대기이벤트\n",
    "    - log file sync\n",
    "    - checkpoint completed\n",
    "    - log file switch completion\n",
    "    - log buffer space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7c33d8",
   "metadata": {},
   "source": [
    "# 제2절 SQL 파싱 부하"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806b61f9",
   "metadata": {},
   "source": [
    "## 1. SQL 처리 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c049d0c",
   "metadata": {},
   "source": [
    "- 사용자는 구조화된 질의언어(SQL)를 통해 사용자가 원하는 결과집합을 정의\n",
    "- DBMS는 사용자의 SQL을 SQL옵티마이저를 통해 실행계획을 작성해줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6e8d51",
   "metadata": {},
   "source": [
    "### 가. SQL 파싱(Parsing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da4fdc4",
   "metadata": {},
   "source": [
    "- SQL을 실행하면 제일먼저 SQL 파서(parser)가 SQL 문장에 문법적 오류가 없는지 검사(Syntax 검사)\n",
    "- 문법적 오류가 없다면 의미상 오류가 없는지 검사(Semantic 검사, 오브젝트 존재유무등)\n",
    "- 검사를 다 마치면, 사용자가 발생한 SQL과 그 실행계획이 라이브러리캐시(프로시저캐시)에 캐싱되어 있는지 확인\n",
    "- 캐싱되어 있다면 소프트파싱, 캐싱되어있지 않다면 하드파싱\n",
    "\n",
    "**소프트파싱(Soft Parsing)** \n",
    "    - SQL과 실행계획을 캐시에서 찾아 곧바로 실행단계로 넘어가는 경우\n",
    "\n",
    "**하드파싱(Hard Parsing)**\n",
    "    - SQL과 실행계획을 캐시에서 찾지 못해 최적화 과정을 거치고 나서 실행단계로 넘어가는 경우\n",
    "    \n",
    "- 라이브러리캐시는 해시 구조로 관리됨\n",
    "    - SQL마다 해시값에 따라 여러 해시 버킷으로 나뉘여 저장되고, SQL을 찾을때는 SQL 문장을 해시 함수에 적용하여  \n",
    "      반환되는 해시값을 이용하여 해시 버킷을 탐색함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5f6959",
   "metadata": {},
   "source": [
    "### 나. 최적화(Optimization)\n",
    "- SQL 최적화를 담당하는 옵티마이저는 사용자가 요청한 SQL을 가장 빠르고 효율적으로 수행할 최적의(처리비용)  \n",
    "  처리경로를 선택해 주는 DBMS의 핵심\n",
    "  \n",
    "**최적화 과정**  \n",
    "- 예를들어 5개의 테이블을 조인한다면, 순서만 고려해도 5!(=120)개의 실행계획 평가\n",
    "- 120가지의 실행계획에 포함된 각 단계별 다양한 조인방식 고려\n",
    "- 테이블을 full scan 할지 인덱스를 사용할지, 어떤 인덱스를 어떤방식으로 스캔할지 고려\n",
    "    - 이와 갘이 무거운 작업이므로 이러한 힘든 과정을 거쳐 최적화된 SQL 실행계획을 한번만 쓰고 버린다면  \n",
    "      엄청난 비효율이 발생한다.\n",
    "    - 파싱과정을 거친 SQL과 실행계획이 여러 사용자가 공유해서 재사용할 수 있도록 공유메모리에 캐싱은 이유가 여기에 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968022ea",
   "metadata": {},
   "source": [
    "## 2. 캐싱된 SQL 공유"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b47821",
   "metadata": {},
   "source": [
    "### 가. 실행계획 공유 조건\n",
    "- SQL 수행절차\n",
    "    - 문법적 오류와 의미상 오류가 없는지 검사\n",
    "    - 해시 함수로붜 반환받은 해시 값으로 라이브러리 캐시 내 해시버킷 탐색\n",
    "    - 찾아간 해시버킷에 체인으로 연결된 엔트리를 차례로 스캔하면서 같은 SQL 문장 탐색\n",
    "    - SQL 문장을 찾으면 함께 저장된 실행계획을 가지고 바로 실행\n",
    "    - 찾아간 해시 버킷에서 SQL 문장을 찾지 못하면 최적화를 수행\n",
    "    - 최적화를 거친 SQL과 실행계획을 방금 탐색한 해시 버킷 체인에 연결\n",
    "    - 방금 최적화한 실행계획을 가지고 실행\n",
    "\n",
    "**중요**\n",
    "- 하드파싱을 반복하지 않고 캐싱된 버전을 찾아 재사용하려면 SQL을 먼저 찾아가야 하며, 캐시에서 SQL을 찾기위해 사용되는 키값은 SQL 문장 그자체\n",
    "  => 이 때문에 SQL 문장안의 작은 공백 하나로도 DBMS는 서로 다른 SQL 문장으로 인식할수 있으므로 주의 해야함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d853174",
   "metadata": {},
   "source": [
    "### 나. 실행계획이 공유하지 못하는 경우\n",
    "- 1. 공백 또는 줄바꿈\n",
    "- 2. 대문자 구분\n",
    "- 3. 주석(Comment)\n",
    "- 4. 테이블 Owner 명시\n",
    "- 5. 옵티마이저 힌트사용\n",
    "- 6. 조건절 비교값\n",
    "\n",
    "- 이러한 비효율을 줄이고 공유 가능한 형태로 SQL을 작성하려면 개발 초기에 SQL 작성표준을 정해서 이를 준수하도록 해야함\n",
    "- 6번처럼 조건절값을 문자열로 붙여가며 매번 다른 SQL로 실행되는 리터널 SQL의 경우, 한가한 시간이라면 문제에 대해서  \n",
    "느끼지 못하겠지만, 사용자가 동시에 몰리는 시간대에는 장애상황으로 발생할 수도 있으므로 바인드변수의 사용을 고려해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b8e4a",
   "metadata": {},
   "source": [
    "## 3. 바인드 변수 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf08f8f",
   "metadata": {},
   "source": [
    "### 가. 바인드 변수의 중요성 \n",
    "\n",
    "**바인드 변수를 사용했을떄의 효과**\n",
    "- SQL과 실행계획을 반복적으로 재사용함으로써 파싱 소요시간과 메모리 사용량을 줄여줌\n",
    "- 궁극적으로 시스템전반의 CPU와 메모리 사용률을 낮춰 데이터베이스 성능과 확장성을 높임\n",
    "\n",
    "**바인드 변수를 사용하지 않아도 되는 예외상황**\n",
    "- 배치프로그램이나 DW, OLAP등 정보계 시스템에서 사용되는 Long Runnung 쿼리\n",
    "    - 파싱 소요시간이 총 소요시간에서 차지하는 비중이 낮음\n",
    "    - 수행빈도가 낮아 하드파싱에 의한 라이브러리 캐시 부하 유발 가능성이 낮음\n",
    "    - 그러므로 상수조건절을 사용하여 옵티마이저가 컬럼히스토그램 정보를 활용할 수 있도록 유도하는것이 유리함\n",
    "- 조건절 컬럼의 값 종류(Distinct value)가 소수 일때\n",
    "    - 분포도가 좋지 않은 값은 옵티마이저가 컬럼히스토그램 정보를 활용할 수 있도록 유도.\n",
    "- 이러한 경우가 아니라면 OLTP 환경에서는 바인드 변수 사용을 권고함\n",
    "- 리터널 SQL을 자동으로 변수화 시켜주는 기능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa74a421",
   "metadata": {},
   "source": [
    "### 나. 바인드변수 사용시 주의사항\n",
    "- 칼럼의 분포가 균일할때는 바인드 변수 처리가 나쁘지 않음\n",
    "- 칼럼의 분포가 균일하지 않을때에는 실행 시점에 바인딩되는 값에 따라 쿼리 성능이 다르게 나타날 수 있으므로  \n",
    "  이럴때는 상수값을 사용하는것이 나을 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8b059c",
   "metadata": {},
   "source": [
    "### 다. 바인드 변수 부작용을 극복하기 위한 노력\n",
    "- 바인드변수 Peeking 기능 도입: 첫번째 바인드 변수값을 살짝 훔쳐보고 그 값에 대한 분포를 이용하여 실행계획 결정하는 기능\n",
    "- 이또한 처음 훔쳐본값에 따라 비활성화 시켜 사용하고 있음\n",
    "- 오라클은 11g부터는 적응적 커서공유(Adaptive Cusor Sharing)를 도입하여 칼럼 분포에 따라 다른 실행계획이  \n",
    "  사용되도록 처리하였지만 이또한 완전한 기능이 아니므로 주의해서 사용해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f61c1eb",
   "metadata": {},
   "source": [
    "## 4. Static SQL과 Dynamic SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276a7613",
   "metadata": {},
   "source": [
    "### 가. Static SQL\n",
    "- String형 변수에 담지 않고 코드 사이에 직절 기술한 SQL문 (Embedded SQL)\n",
    "- 개발언어 : PowerBuilder, PL/SQL, Pro*C, SQLJ\n",
    "- SQL문을 String 변수에 담지 않고 마치 예약된 키워드처럼 C/C++코드 사이에 섞어 기술\n",
    "- 구문분석, 유효 오브젝트 여부, 오브젝트 엑세스 권한등의 체크 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d381db7",
   "metadata": {},
   "source": [
    "### 나. Dynamic SQL\n",
    "- String 형 변수에 담아서 기술하는 sQL문\n",
    "- 조건에 따라 SQL이 동적으로 바뀔수 있으므로 syntax, semantics 체크 불가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951890dd",
   "metadata": {},
   "source": [
    "### 다. 바인드 변수의 중요성 재강조\n",
    "- Static을 사용하든 Dynamic SQL을 사용하든 옵티마이저는 SQL 문장 자체만을 인식할 뿐이므로 성능에 영향을 주지는 않는다.\n",
    "- 라이브러리 캐시 효율은 Static이냐 Dynamic의 차이가 아니라 바인드 변수의 사용여부에 초점을 맞춰야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52f2c75",
   "metadata": {},
   "source": [
    "## 5. 애플레키에션 커서 캐싱\n",
    "- 같은 SQL을 여러번 반복해서 수행해야할 때, 첫번째는 하드파싱이 일어나겠지만 이후부터는 라이브러리 캐시에 공유되 버전을 찾아 가볍게 실행한다.\n",
    "- 하지만 그렇다더라도 SQL문장의 문법적, 의미적 오류를 확인하고 해시함수로부터 반환된 해시값을 이용해서 캐시에서 실행계획을 찾고, 수행이 필요한 메모리를 할당받는 등의 작업이 매번 반복되면 비효율이 발생할 것이다.\n",
    "- 이러한 과정을 생략하고 빠르게 SQL을 수행하는 방법이 바로 \"**애플리케이션 커서 캐싱**\" 이다.\n",
    "- 개발언어마다 구현방식이 다르므로 이 기능을 활용하려면 API를 살펴봐야함.\n",
    "- 일반적으로 SQL을 반복 수행할 때에는 Parse Call 횟수가 Execute Call 횟수와 같지만 \n",
    "- 위의 결과는 Parse Call 한번만 발생했고, 이후 4,999번 수행할 때에도 Parse Call이 전혀 발생하지 않았음\n",
    "- JAVA에서 위의 기능을 구현하기 위한 방법 : 묵시적캐싱 옵션 사용(Implicit Caching)\n",
    "- Dynamic SQL을 사용하거나 Cursor Variable(=Ref Cursor)를 사용할 때는 커서를 자동으로 캐싱하는 효과가 사라짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c127510",
   "metadata": {},
   "source": [
    "# 제 3절. 데이터베이스 Call과 네트워크 부하"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427ca694",
   "metadata": {},
   "source": [
    "# 1. 데이터베이스 Call 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48015dc",
   "metadata": {},
   "source": [
    "## 가. SQL 커서에 대한 작업 요청에 따른 구분\n",
    "- Parse Call : SQL 파싱을 요청하는 Call\n",
    "- Execute Call : SQL 실행을 요청하는 Call\n",
    "- Fetch Call : SELECT 문의 결과 데이터 전송을 요청하는 Call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecaa0a6",
   "metadata": {},
   "source": [
    "## 나. Call 발생 위치에 따른 구분\n",
    "### 1) User Call\n",
    "- DBMS로부터 요청되는 Call\n",
    "- User Call이 많으면 성능이 좋을수 없으므로, DBMS 확장성을 높이려면 User Call을 최소화 하려는 노력이 중요함\n",
    "- User Call을 줄이기 위한 기술요소\n",
    "    - Loop 쿼리를 해소하고 집합적 사고를 통해 One SQL로 구현\n",
    "    - Array Processing : Array 단위 Fetch, Bulk Insert/Update/Delete\n",
    "    - 부분범위처리 원리 활용\n",
    "    - 효과적인 화면 페이지 처리\n",
    "    - 사용자 정의 함수/프로시저/트리거의 적절한 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495e97f5",
   "metadata": {},
   "source": [
    "### 2) Recusive Call\n",
    "- DBMS 내부에서 발생하는 Call\n",
    "- SQL 파싱과 최적화 과정에서 발생(데이터 딕셔너리조회, 사용자 정의함수/프로시저 내에서의 SQL 수행)\n",
    "- Recursive Call 최소화 방안\n",
    "    - 바인드 변수 사용하여 하드파싱 발생 횟수 감소\n",
    "    - 사용자 정의 함수/프로시저의 적절한 사용 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0255aaa7",
   "metadata": {},
   "source": [
    "# 2. 데이터베이스 Call과 성능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f9e2fb",
   "metadata": {},
   "source": [
    "## 가. One SQL 구현의 중요성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7888db0c",
   "metadata": {},
   "source": [
    "- 예를 들어 처리해야할 납부실적이 10만건이라고 하면, (array 단위 fetch 기능을 이용하지 않을때 Insert를 위한 Parse Call이 50만번, Execute call이 50만번으로 최대 110만 번의 데이터베이스 Call이 발생함\n",
    "- 이러한 프로그램을 아래와 같이 One SQL로 통합하면 1~2초내로 수행되는것을 확인할수 있는데, 이 원리는 110번 발생할수 있는 데이터베이스 Call을 단 2회(Parse Call 1회, Execute Call 1회)로 줄인데 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b5c44",
   "metadata": {},
   "source": [
    "## 나. 데이터베이스 Call과 시스템 확장성\n",
    "- 데이터베이스 Call은 개별 프로그램 수행속도 뿐 아니라 궁극적으로 시스템 전체의 확장성에도 영향을 미친다.\n",
    "- 예시) 인터넷 쇼핑몰에서 조회한 상품 5개를 선택한 후 위시리스트에 등록하는 프로그램일 때\n",
    "- 5번의 메소드를 호출하므로 Parse Call과 Execute Call 각각 5번씩 발생\n",
    "- 확장성을 고려하여 작성하였으므로 1번의 메소드를 호출하며 Parse Call과 Execute Call도 각각 1번씩만 호출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed20483",
   "metadata": {},
   "source": [
    "# 3. Array Processing 활용\n",
    "- Array Processing 기능을 활용하면 한번의 SQL(INSERT/UPDATE/DELETE) 수행으로 다량의 레코드를 동시 처리\n",
    "- 네트워크 Call 감소\n",
    "- SQL 수행시간 감소\n",
    "- CPU 사용량 감소"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49060820",
   "metadata": {},
   "source": [
    "- Insert 할 데이터를 계속 array에 담기만 하다가\n",
    "- 1000건이 쌓일때마다 한번씩 executeBatch를 수행\n",
    "- Select 결과집합을 Fetch할때도 1000건씩 하도록 조정하였다.  \n",
    "  **Call 횟수를 줄이는것이 성능개선에 도움이 되는것을 알 수 있다.**\n",
    "- 대용량 데이터의 처리에는 Array Processing이 필수\n",
    "- 효과를 극대화 하기위해 연속된 일련의 처리과정을 모두 Array 단위로 진행해야함(select, insert 모두)\n",
    "- 예시) PL/SQL을 이용한 데이터 Bulk로 1000건씩 Fetch해서 Bulk Insert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fe4bb8",
   "metadata": {},
   "source": [
    "# 4. Fetch Call 최소화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da08fc3",
   "metadata": {},
   "source": [
    "## 가. 부분범위처리 원리\n",
    "- 쿼리 결과 집합을 전송할때, 전체 데이터를 연속적으로 전송하지 않고 사용자로부터 Fetch Call이 있을때마다 일정량씩 나누어서 전송하는 것\n",
    "- 데이터를 클라이언트에게 전송할때 일정량씩 나누어서 전송\n",
    "- 오라클 : 내부적으로는 SDU, TDU 단위로 나누어서 전송  \n",
    "           array 사이즈를 작게 설정하면 하나의 네트워크 패킷에 담아 전송하겠지만, 크게 설정하면 여러개의 패킷으로 나누어 전송"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd78a94",
   "metadata": {},
   "source": [
    "## 나. ArraySize 조정에 의한 Fetch Call 감소 및 블록 I/O 감소 효과\n",
    "- 대량의 데이터파일을 전송한다면 arraysize 크게하여 fetch call 횟수를 줄여주는것이 유리\n",
    "- 반대로 적은량의 데이터만 fetch 하다가 멈추는 프로그램이라면 arraysize를 작게 설정하는것이 유리\n",
    "- arraysize를 증가시키면 네트워크 부하감소 및 서브프로세스가 읽어야할 블록 갯수 감소 효과\n",
    "- ArraySize를 키운다고 해서 Fetcah count와 블록 I/O가 같은 비율로 줄지 않음\n",
    "- ArraySize를 무작정 크게 설정한다고 좋은것이 아니며, 일정크기 이상이면 리소스만 낭비하는 결과를 초래할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef53efa",
   "metadata": {},
   "source": [
    "### 1) Oracle PL/SQL(커서를 열고 레코드를 Fetch)\n",
    "- 10g : 자동으로 100개씩 array Fetch가 일어남.\n",
    "\n",
    "### 2) JAVA(FetchSize를 100으로 설정했을때 데이터를 Fetch 해오는 매커니즘)\n",
    "- 최초 rs.next() 호출 시 한꺼번에 100건을 가져와서 클라이언트 Array 버퍼에 캐싱한다.\n",
    "- 이후 rs.next() 호출할 때는 데이터베이스 Call을 발생시키지 않고 Array 버퍼에서 읽는다.\n",
    "- 버퍼에 캐싱 돼 있던 데이터를 모두 소진한 후 101번째 rs.next() 호출 시 다시 100건을 가져온다.\n",
    "- 모든 결과집합을 다 읽을 때까지 2~3번 과정을 반복한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e68978c",
   "metadata": {},
   "source": [
    "# 5. 페이지 처리 활용\n",
    "- 페이지 처리를 하지 않을때 발생하는 부하요인\n",
    "    - 다량 발생하는 Fetch Call의 부하\n",
    "    - 대량의 결과 집합을 클라이언트에 전송하면서 발생하는 네트워크 부하\n",
    "    - 인덱스와 부분범위처리 원리를 이용해 각 페이지에 필요한 최소량만 I/O\n",
    "- 데이터를 소량씩 나누어 전송하므로 AP웹 서버 리소스 사용량 최소화\n",
    "- 결론적으로, 조회할 데이터가 일정량 이상이고 수행빈도가 높다면 필수적으로 페이지 처리 구현해야함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd08d97",
   "metadata": {},
   "source": [
    "# 6. 분산 쿼리\n",
    "- 분산 DB간 테이블 조인\n",
    "- 원격의 sal테이블을 전송받아 order 테이블과 NL 조인\n",
    "- 50만건이나 되는 데이터를 네트워크를 통해 전송받고 있어 성능저하의 원인이 됨.\n",
    "- 분산 DB간의 성능저하 해결방안\n",
    "- order_data에 조건에 해당하는 데이터만 원격으로 보내서 조인과 group by를 거친 결과 집합만 전송받음\n",
    "- 원격서버가 처리가능 하도록 driving_site 힌트 사용\n",
    "- 분산쿼리의 성능을 높이는 핵심은, 네트워크를 통한 데이터 전송량을 줄이는 데 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c722dc7",
   "metadata": {},
   "source": [
    "# 7. 사용자 정의 함수 / 프로시저의 특징과 성능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db08714",
   "metadata": {},
   "source": [
    "# 가. 사용자 정의 함수/프로시저의 특징\n",
    "- 가상머신과 같은 별도의 실행엔진을 통해 실행됨\n",
    "- 실행시마다 컨텍스트 스위칭이 일어나므로, 내장함수를 호출할때와 비교해서 성능이 상당히 떨어짐\n",
    "- 예시) 문자타입의 일자 데이터를 날짜 타입으로 변환해주는 사용자정의함수\n",
    "- to_char 함수를 바로 호출할때보다 훨씬 느림\n",
    "- 메인쿼리가 참조하는 사용자 정의 함수에 또 다른 쿼리문이 내장되어 있다면 수행 성능이 훨씬 나빠짐\n",
    "- 함수에 내장된 쿼리를 수행할 때마다 Execute Call, Fetch Call이 재귀적으로 일어남\n",
    "- Recusive Call이 반복적으로 일어남(User Call에 비해 성능부하가 미미하지만, 그 횟수가 무수히 반복되면 성능저하)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef0128c",
   "metadata": {},
   "source": [
    "## 나. 사용자 정의 함수/프로시저에 의한 성능 저하 해소 방안\n",
    "- 소량의 데이터를 조회할 때 사용\n",
    "- 부분범위 처리가 가능한 상황에서 제한적으로 사용\n",
    "- 가급적 함수를 풀어 조인 또는 스칼라 서브쿼리 형태로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a1663f",
   "metadata": {},
   "source": [
    "# 제4절. 데이터베이스 I/O원리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0cbbe1",
   "metadata": {},
   "source": [
    "## 1. 블록단위 I/O\n",
    "- 데이터 파일에서 DB 버퍼 캐시로 블록을 적재할 때\n",
    "- 데이터 파일에서 블록을 직접 읽고 쓸때\n",
    "- 버퍼 캐시에서 블록을 읽고 쓸때\n",
    "- 버퍼 캐시에서 변경된 블록을 다시 데이터 파일에 쓸때"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243b6b5c",
   "metadata": {},
   "source": [
    "## 2. 메모리 I/O vs. 디스크 I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1854d749",
   "metadata": {},
   "source": [
    "### 가. I/O 효율화 튜닝의 중요성\n",
    "- 디스크를 경우한 데이터 입출력은 디스크의 액세스 암(Arm)이 움직이면서 헤드를 통해 데이터를 읽고 쓰기 때문에 느림\n",
    "- 메모리를 통한 입출력은 전기적 신호에 불과하기 때문에 디스크를 통한 I/O에 대해 비교할수 없을정도로 빠름\n",
    "- 모든 DBMS는 읽고자 하는 블록을 먼저 버퍼 캐시에서 찾고, 없을경우에는 디스크에서 읽어 버퍼 캐시로 적재후 읽기/쓰기 작업을 수행\n",
    "- 이러한 이유로 모든 데이터를 메모리에 올려놓고 사용하면 좋겠지만 메모리는 물리적으로 한정된 자원\n",
    "- **결국 디스크 I/O를 최소화하고 버퍼 캐시 효율을 높이는 것이 데이터베이스 I/O 튜닝의 목표**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142464f7",
   "metadata": {},
   "source": [
    "### 나. 버퍼 캐시 히트율(Buffer Cache Hit Ratio)\n",
    "- 버퍼 캐시 효율을 측정하는 지표로써 전체 읽은 블록중 메모리 버퍼 캐시에서 찾은 비율   \n",
    "  BCHR = (버퍼 캐시에서 곧바로 찾은 블록 수 / 총 읽은 블록 수) x 100\n",
    "- BCHR은 주로 전체적인 관점에서 측정하지만, 개별 SQL에 대해서도 구해볼수 있으며, 이 비율이 낮은것이 SQL 성능을 떨어뜨리는 주범\n",
    "- Disk 항목이 디스크를 경유한 블록 수\n",
    "    - 총 읽은 블록 수 = 822\n",
    "    - 버퍼 캐시에서 곧바로 찾은 블록 수 = 822 - 18 = 804\n",
    "    - CHR = (822 - 18) / 822 = 97.8%\n",
    "- **논리적인 블록요청 횟수를 줄이고, 물리적으로 디스크에서 읽어야할 블록수를 줄이는것이 I/O 효율화 튜닝의 핵심 원리**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bf2e74",
   "metadata": {},
   "source": [
    "### 다. 네트워크, 파일시스템 캐시가 I/O 효율에 미치는 영향\n",
    "- 대용량의 데이터를 읽고 쓰는데 다양한 네트워크 기술이 사용됨에 따라 네트워크 속도도 SQL 성능에 크게 영향을 미친다.\n",
    "- RAC같은 클러스터링 환경에선 인스턴스 간에 캐시된 블록을 공유하므로 메모리 I/O의 성능에도 네트워크 속도가 지대한 영향을 미친다. \n",
    "- 같은양의 디스크 I/O가 발생하더라도 I/O 대기시간이 크게 차이 나는것은 디스크 경합 때문일수도 있지만, \n",
    "  OS에서 지원하는 파일시스템 버퍼 캐시와 SAN 캐시 때문일 수도 있다.\n",
    "- (SAN 캐시는 크다고 문제가 되지 않지만, 파일시스템 버퍼 캐시는 최소화 하여 데이터베이스 자체 캐시영역에 좀더 큰   \n",
    "  공간을 할당하는것이 더욱 효과적임)\n",
    "- **네트워크 문제든, 파일시스템 문제든 I/O 성능에 관한 가장 확실하고 근본적인 해결책은 논리적인블록 요청 횟수를 최소화 하는것**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de794e91",
   "metadata": {},
   "source": [
    "## 3. Sequential I/O vs. Random I/O\n",
    "- sequential 액세스는 논리적/물리적 순서를 따라 차례대로 읽어 나가는 방식\n",
    "    - 인덱스 리프 블록에 위치한 모든 레코드는 포인터를 논리적으로 연결되어 있고, 이 포인터를 따라 스캔하는 방식\n",
    "- Random 액세스는 레코드간 논리적, 물리적인 순서를 따르지 않고, 한건을 읽기 위해 한 블록씩 접근하는 방식\n",
    "- I/O 튜닝의 핵심 원리\n",
    "    - Sequential 액세스에 의한 선택 비중을 높인다.\n",
    "    - Random 액세스 발생량을 줄인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72734b8",
   "metadata": {},
   "source": [
    "### 가. Sequential 액세스에 의한 선택 비중 높이기\n",
    "- 읽는 총 건수 중에서 결과 집합으로 선택되는 비중을 높여야 함\n",
    "- 같은 결과를 얻기위해 얼마나 적은 레코드를 읽느냐로 효율성이 판단됨\n",
    "\n",
    "- good\n",
    "    - 전체 레코드 49,906건\n",
    "    - 선택 레코드 24,613건 (49%)\n",
    "    - 읽은 블록수 691 블록\n",
    "    - Table Full Scan 치고는 나쁘지 않음\n",
    "- bad    \n",
    "    - 전체 레코드 49,906건\n",
    "    - 선택 레코드 1건 (0.002%)\n",
    "    - 읽은 블록수 691 블록\n",
    "    - Table Full Scan 비효율 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faafa963",
   "metadata": {},
   "source": [
    "- 인덱스를 사용하고도 1개의 레코드를 읽기위해 76개 블록 액세스\n",
    "- 테이블 뿐 아니라, 인덱스를 sequential 액세스 방식으로 스캔할 때도 비효율 발생\n",
    "- 조건절에 사용된 컬럼과 연산자 형태, 인덱스 구성에 의해 효율성이 결정됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b4b0ed",
   "metadata": {},
   "source": [
    "### 나. Random 액세스 발생량 줄이기\n",
    "- Random 액세스 발생량을 낮추는 방법\n",
    "    - 인덱스로부터 만족하는 22,934건을 읽어 그 횟수만큼 테이블을 Random 액세스 수행하여 최종적으로 1건의 결과 추출\n",
    "    - 최종 선택된 것에 비해 너무 많은 Random 액세스 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cc564d",
   "metadata": {},
   "source": [
    "## 4. Single Block I/O vs.MultiBlock I/O\n",
    "- single Block I/O : 한번의 I/O Call에 하나의 데이터 블록만 읽어서 메모리에 적재하는 방식\n",
    "    - 인덱스를 통해 테이블을 액세스할때, 기본적으로 인덱스와 테이블 모두 이 방식 사용\n",
    "- Multi Block I/O: I/O Call이 필요한 시점에, 인접한 블록들을 같이 읽어 메모리에 적재하는 방식\n",
    "    - Table Full Scan 처럼 물리적으로 저장된 순서에 따라 읽을때 인접한 블록들을 같이 읽는것이 유리함\n",
    "    - 인접한 블록 : 하나의 익스텐트에 속한 블록"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89bbfd4",
   "metadata": {},
   "source": [
    "**Single Block I/O 방식**\n",
    "- 64번의 인덱스 블록을 디스크에서 읽으면서 64번의 I/O Call이 발생\n",
    "\n",
    "**MultiBlock I/O 방식**\n",
    "- 64개 블록을 디스크에서 읽었는데 I/O Call이 9번 발생\n",
    "- Oracle 10g부터는 Index Range Scan 또는 Index Full Scan일때도 Multiblock I/O 방식으로 읽는 경우가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c61dceb",
   "metadata": {},
   "source": [
    "## 5. I/O 효율화 원리\n",
    "- **논리적인 I/O 요청 횟수를 최소화 하는것이 I/O 효율화 튜닝의 핵심 원리**\n",
    "- I/O 때문에 성능이 낮게 측정될때, 하드웨어적인 방법을 통해 I/O 성능을 향상 시킬수도 있지만,  \n",
    "  SQL 튜닝을 통해 I/O 발생 횟수를 줄이는것이 근본적이고 확실한 해결 방법이다. \n",
    "- 애플리케이션 측면에서 이 I/O 효율화 원리\n",
    "    - 필요한 최소 블록만 읽도록 SQL 작성\n",
    "    - 최적의 옵티마이징 팩터 제공 \n",
    "    - 필요하다면, 옵티마이저 힌트를 사용하여 최적의 액세스 경로를 유도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce75098c",
   "metadata": {},
   "source": [
    "### 가. 필요한 최소 블록만 읽도록 SQL 작성\n",
    "- 비효율적인 액세스를 없애고 필요한 최소 블록만 액세스\n",
    "- 같은 테이블을 4번 액세스하여 처리하던 방식을 1번만 읽어서 처리할수 있도록 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8639fb7",
   "metadata": {},
   "source": [
    "### 나. 최적의 옵티마이징 팩터 제공\n",
    "- 전략적인 인덱스 구성\n",
    "    - 전략적인 인덱스 구성은 가장 기본적인 옵티마이징 팩터\n",
    "- DBMS가 제공하는 기능 활용\n",
    "    - 인덱스 외에도 DBMS가 제공하는 다양한 기능을 적극적으로 활용\n",
    "    - 인덱스, 파티션, 클러스터, 윈도우 함수 등을 적극 활용하여 옵티마이저가 최적의 선택을 할 수 있도록 한다. \n",
    "- 옵티마이저 모드 설정\n",
    "    - 옵티마이저모드(전체처리속도, 최초등담속도)와 그 외 옵티마이저 행동에 영향을 미치는 일부 파라미터를 변경해 주는것이 도움이 될 수 있다.\n",
    "- 통계정보\n",
    "    - 옵티마이저에게 정확한 정보를 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac70e92",
   "metadata": {},
   "source": [
    "### 다. 필요하다면, 옵티마이저 힌트를 사용해 최적의 액세스 경로로 유도\n",
    "- 최적의 옵티마이징 팩터를 제공했다면 가급적 옵티마이저에게 맡기는것이 바람직하지만,   \n",
    "  옵티마이저가 생각만큼 최적의 실행계획을 수립하지 못하는 경우 사용\n",
    "- 옵티마이저 힌트를 사용할 때 반드시 의도한 실행계획으로 수행되는지 확인해야 함\n",
    "- 여러가지로 옵티마이저 힌트 사용은 불가피함\n",
    "- 데이터베이스 애플리케이션 개발자라면 인덱스, 조인, 옵티마이저의 기본 원리를 이해 필요\n",
    "- 그것을 바탕으로 최적의 액세스 경로를 유도할 수 있는 능력을 필수적으로 갖춰야함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cdc8f0",
   "metadata": {},
   "source": [
    "# 2장. Lock과 트랜잭션 동시성 제어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d3032d",
   "metadata": {},
   "source": [
    "# 제 1절. Lock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7a60ed",
   "metadata": {},
   "source": [
    "# 1. Lock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39a5b4b",
   "metadata": {},
   "source": [
    "## 가. Lock이란?\n",
    "- 같은 자원을 액세스하려는 다중 트랜잭션 환경에서 데이터베이스의 일관성과 무결성을 유지하기 위해 트랜잭션의   \n",
    "  순차적 진행을 보장할 수 있는 직렬화(Serialization) 장치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdf0b06",
   "metadata": {},
   "source": [
    "## 나. 공유 Lock과 배타적 Lock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08dd12c",
   "metadata": {},
   "source": [
    "### 1) 공유 Lock\n",
    "- 공유(Shared) Lock은 데이터를 읽고자 할 때 사용\n",
    "- 다른 공유 Lock과는 호환되지만 배타적 Lock과는 호환되지 않음\n",
    "\n",
    "### 2) 배타적 lock\n",
    "- 배타적(Exclusive) Lock은 데이터를 변경하고자 할 때 사용되며, 트랜잭션이 완료될 때까지 유지\n",
    "- 해당 Lock이 해제될 때까지 다른 트랜잭션은 해당 Resource에 접근할 수 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c8b652",
   "metadata": {},
   "source": [
    "## 다. 블로킹과 교착상태\n",
    "### 1) 블로킹\n",
    "- Lock경합이 발생해 특정 세션이 작업을 진행하지 못하고 멈춰 선 상태\n",
    "- 공유 Lock과 배타적 Lock은 함께 설정될 수 없으므로 Blocking이 발생\n",
    "- Blocking을 해소 할 수 있는 방법은 COmmit(또는 Rollback)뿐이다.\n",
    "- Lock 경합이 발생하면 먼저 Lock이 완료될 때까지 후행 트랜잭션을 기다려야 한다. \n",
    "- Lock에 의한 성능 저하를 최소화 하는 방법\n",
    "    - 트랜잭션의 원자성을 훼손하지 않는 선에서 트랜잭션을 가능한 짧게 정의\n",
    "    - (Oracle은 데이터를 읽을 때 Shared Lock을 사용하지 않기 때문에 상대적으로 Lock 경합이 적음)\n",
    "    - 같은 데이터를 갱신하는 트랜잭션이 동시에 수행되지 않도록 설계 \n",
    "    - 주간에 대용량 갱신 작업이 불가피하다면, 블로킹 현상에 의해 사용자가 무한정 기다리지 않도록 적절한 프로그램 기법을 도입\n",
    "- 트랜잭션 격리성 수준(Isolation Level)를 불필요하게 상향 조정하지 않는다. \n",
    "- SQL문장이 가장 빠른ㄴ 시간 내에 처리를 완료하도록 하는 것이 Lock 튜닝의 기본이고 효과도 가장 좋다.\n",
    "\n",
    "### 2) 교착상태\n",
    "- 두 세션이 각각 Lock을 설정한 리소스를 서로 액세스하려고 마주보며 진행하는 상황, 둘 중 하나가 뒤로 물러나지 않으면 영영 풀릴 수 없다.\n",
    "- 여러 테이블을 액세스하면 발생하는 교착상태는 테이블 접근 순서를 같게 처리하여 회피 한다. \n",
    "- SQL Server라면 갱신(Update) Lock을 사용함으로써 교착상태 발생 가능성을 줄일 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff2f882",
   "metadata": {},
   "source": [
    "# 2. SQL Server Lock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ae81f2",
   "metadata": {},
   "source": [
    "## 가. Lock 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71d6451",
   "metadata": {},
   "source": [
    "### 1) 공유 Lock\n",
    "- SQL Server의 공유 Lock은 트랜잭션이나 쿼리 수행이 완료될 때까지 유지되는 것이 아니라 다음 레코드가 읽히면 곧바로 해제 된다. \n",
    "- Isolation Level을 변경하지 않고 트랜잭션 내에서 공유 Lock이 유지되도록 하려면 테이블 힌트로 지정하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c875c1",
   "metadata": {},
   "source": [
    "### 2) 배타적 Lcok\n",
    "- 데이터를 변경시 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb783ff9",
   "metadata": {},
   "source": [
    "### 3) 갱신 Lock\n",
    "- 만약 두 트랜잭션이 동시에 같은 고객에 대해서 Update를 수행시 두 트랜잭션 모두 처음에는 공유 Lock을 설정했다가 적립포인트를 변경하기  \n",
    "  직전에 배타적 Lock을 설정하려고 한다.\n",
    "- 이럴 경우 두 트랜잭션은 상대편 트랜잭션에 의한 공유 Lock이 해제되기만을 가디라는 교착상태에 빠지게 된다. \n",
    "- 이런 잠재적인 교착상태를 방지하려고 SQL Server는 갱신(Update)Lock을 사용할 수 있다.\n",
    "- 한 자원에 대한 갱신 Lock은 한 트랜잭션만 설정할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d26eb90",
   "metadata": {},
   "source": [
    "### 4) 의도 Lock\n",
    "- 특정 로우에 Lock을 설정하면 그와 동시에 상위 레벨 개체(페이지, 익스텐트, 테이블)에 내부적으로 의도(Intent)Lock이 설정된다.\n",
    "- Lock을 설정하려는 개체의 하위 레벨에서 선행 트랜잭션이 어떤 작업을 수행 중인지를 알리는 용도로 사용되며, 일조의 푯말(Flag)라고 할 수 있다.\n",
    "- 예를 들어, 구조를 변경하기 위해 테이블을 잠그려 할 때 그 하위의 모든 페이지나 익스텐트, 로우에 어떤 Lock이 설정돼 있는지 검사할 경우 \n",
    "  오래 소요 될 수 있으므로 해당 테이블에 어떤 모드의 의도 Lock이 설정돼 있는지만 보고도 작업을 진행할지 아니면 기다릴지를 결정할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6233e1",
   "metadata": {},
   "source": [
    "### 5) 스키마 Lock\n",
    "- Sch-S(Schema Stability) : SQL을 컴파일하면서 오브젝트 스키마를 참조할 때 발생하며, 읽는 스키마 정보가 수정되거나 삭제되지 못하도록 함\n",
    "- Sch-M(Schema Modification) : 테이블 구조를 변경하는 DDL문을 수행할 때 발생하며, 수정 중인 스키마 정보를 다른 세션이 참조하지 못하도록 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5340c21c",
   "metadata": {},
   "source": [
    "### 6) Bulk Update Lock\n",
    "- 테이블 Lock의 일종으로, 테이블에 데이터를 Bulk Copy할 때 발생한다.\n",
    "- 병렬 데이터 로딩(Bulk Insert나 bcp 작업을 동시 수행)을 허용하지만 일반적인 트랜잭션 작업은 허용되지 않는다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0b95b6",
   "metadata": {},
   "source": [
    "## 나. Lock 레벨과 Escalation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bd70fc",
   "metadata": {},
   "source": [
    "- 로우 레벨\n",
    "    - 변경하려는 로우(실제로는 RID)에만 Lock을 설정하는 것\n",
    "- 페이지 레벨\n",
    "    - 변경하려는 로우가 담긴 데이터 페이지(또는 인덱스 페이지)에 Lock을 설정하는 것\n",
    "    - 같은 페이지에 속한 로우는 진행 중인 변경 작업과 무관하더라도 모두 잠긴것과 같은 효과가 나타남\n",
    "- 익스텐트 레벨\n",
    "    - 익스텐트 전체가 잠김\n",
    "    - SQL Server의 경우, 하나의 익스텐트가 여덞 개 페이지로 구성되므로 8개 페이지에 속한 모든 로우가 잠긴 것과 같은 효과가 나타남\n",
    "- 테이블 레벨\n",
    "    - 테이블 전체 그리고 관련 인덱스까지 모두 잠김\n",
    "- 데이터베이스 레벨\n",
    "    - 데이터베이스 전체가 잠긴다.\n",
    "    - 보통 데이터베이스를 복구하거나 스키마를 변경할 때 일어 남"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46bf6f4",
   "metadata": {},
   "source": [
    "- 위 5가지 레벨 외에 인덱스 키에 로우 레벨 Lock을 거는 경우도 있음\n",
    "- Lock Escalation\n",
    "    - 관리할 Lock 리소스가 정해진 임계치를 넘으면 로우 레벨 락이 -> 페이지 -> 익스텐트 -> 테이블레벨 락으로 점검 확장되는 것을 의미\n",
    "- SQL Server, DB2 UDB 처럼 한정된 메모리 상에서 Lock 매니저를 통해 Lock 정보를 관리하는 DBMS에서 공통적으로 발생할 수 있는 현상\n",
    "- Locking 레벨이 낮을 수록 동시성은 좋지만 관리해야 할 Lock 개수가 증가하기 때문에 더 많은 리소스를 소비\n",
    "    - Locking 레벨이 높을 수록 적은 양의 Lock 리소스를 사용하지만 하나의 Lock으로 수많은 레코드를 한꺼번에 Locking하기 때문에 동시성은 나빠짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736e0f89",
   "metadata": {},
   "source": [
    "## 다. Lock 호환성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd53f037",
   "metadata": {},
   "source": [
    "- Intent Shared(IS) == IS, S, U, IX, SIX\n",
    "- Shared(S) == IS, S, U\n",
    "- Updated(U) == IS, S\n",
    "- Intent Exclusive(IX) == IS, IX\n",
    "- Shared with intent exclusive(SIX) == IS\n",
    "- EXclusive(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2395844",
   "metadata": {},
   "source": [
    "- 스키마 Lock 호환성\n",
    "    - Sch-S는 Sch-M을 제외한 모든 Lock과 호환\n",
    "    - Sch-M은 어떤 Lock과도 호환되지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c8bc7f",
   "metadata": {},
   "source": [
    "# 3. Oracle Lock\n",
    "- Oracle은 공유 리소스와 사용자 데이터를 보호할 목적으로 DML Lock, DDL Lock, 래치(Latch), 버퍼 Lock, 라이브러리 캐시  \n",
    "  Lock/Pin등 다양한 종류의 Lock을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa48b917",
   "metadata": {},
   "source": [
    "## 가. 로우 Lock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa7c781",
   "metadata": {},
   "source": [
    "- Oracle에서 로우 Lock은 항상 배타적이다.\n",
    "- INSERT, UPDATE, DELETE 문이나 SELECT...FOR UPDATE문을 수행한 트랜잭션에 의해 설정되면, 트랜잭션이 커밋 또는 롤백할 때까지   \n",
    "  다른 트랜잭션은 해당 로우를 변경할 수 없음\n",
    "- Oracle에서 읽는 과정에서는 어떤 Lock도 설정하지 않음으로 읽기와 갱신 작업은 서로 방해 하지 않음\n",
    "    - 읽으려는 데이터를 다른 트랜잭션이 갱신 중이더라도 기다리지 않음\n",
    "    - 갱신하려는 데이터를 다른 트랜잭션이 읽는 중이더라도 기다리지 않음(SELECT..FOR UPDATE 구문은 제외)\n",
    "    - 갱신하려는 데이터를 다른 트랜잭션이 갱신중이면 기다림\n",
    "- Oracle이 공유 Lock을 사용하지 않고도 일관성을 유지할 수 있는 것은 UNDO 데이터를 이용한 다중 버전 동시성 제어 매커니즘을 사용하기 때문.\n",
    "- Oracle은 별도의 Lock 매니저 없이 레코드의 속성으로서 로우 Lock을 구현했기 때문에 아무리 많은 레코드를 갱신하더라도 절대 Lock Escalation은 발생하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf8075b",
   "metadata": {},
   "source": [
    "## 나. 테이블 Lock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f596b7",
   "metadata": {},
   "source": [
    "- 한 트랜잭션이 로우 Lock을 얻는 순간, 해당 테이블에 대한 테이블 Lock도 동시에 얻어 현재 트랜잭션이 갱신중인 테이블에 대한 호환되지 않는  \n",
    "  DDL 오퍼레이션을 방지 한다.\n",
    "- 테이블 Lock 종류\n",
    "    - Row Share(RS)\n",
    "    - Row Exclusive(RX)\n",
    "    - Share(S)\n",
    "    - Share row Exclusive(SRX)\n",
    "    - Exclusive(X)\n",
    "- SELECT..FOR UPDATE 문을 수행할 때 RS 모드 테이블 Lock을 얻고, insert, update, delete 문을 수행할 때 RX 모드 테이블 Lock을 얻음\n",
    "- 일반적으로 DML 로우 Lock을 처음 얻는 순간 묵시적으로 테이블 Lock을 얻지만, 아래처럼 명령어를 이용해서도 가능\n",
    "- 테이블 Lock이라 하면, 테이블 전체에 Lock이 걸린다고 생각하기 쉬우나, Oracle의 테이블 Lock의 의미는, Lock을 획득한 선행 트랜잭션이 해당 테이블에서 현재 어떤 작업을 수행중인지를 알리는 일종의 푯말(Flag)이다.   \n",
    "  후행 트랜잭션은 어떤 테이블이 Lock이 설정돼 있는지만 보고도 그 테이블로의 진입 여부를 결정할 수 있다. \n",
    "- Oracle의 Lock 호환성\n",
    "    - NULL == NULL, RS, RX, S, SRX, X\n",
    "    - RS == NULL ,RS, RX, S, SRX\n",
    "    - RX == NULL, RS, RX\n",
    "    - S == NULL, RS, S\n",
    "    - SRX == NULL, RS\n",
    "    - X == NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5a0982",
   "metadata": {},
   "source": [
    "# 제 2절 트랜잭션\n",
    "- 트랜잭션(Transaction)은 업무 처리를 위한 논리적인 작업 단위이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c4e12c",
   "metadata": {},
   "source": [
    "## 1. 트랜잭션의 특징\n",
    "- 원자성(Atomicity)\n",
    "    - 트랜잭션은 더 이상 분해가 불가능한 업무의 최소단위이므로, 전부 처리되거나 아예 하나도 처리되지 않아야 함\n",
    "- 일관성(Consistency)\n",
    "    - 일관된 상태의 데이터베이스에서 하나의 트랜잭션을 성공적으로 완료하고 나면 그 데이터베이스는 여전히 일관된 상태여야 함.\n",
    "- 격리성(Isolation)\n",
    "    - 실행 중인 트랜잭션의 중간 결과를 다른 트랜잭션이 접근할 수 없음\n",
    "- 영속성(Durability)\n",
    "    - 트랜잭션이 일단 실행을 성공적으로 완료하면 그 결과는 데이터베이스에 영속적으로 저장."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6d0395",
   "metadata": {},
   "source": [
    "## 2. 트랜잭션 격리성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7ea0d7",
   "metadata": {},
   "source": [
    "## 가. 낮은 단계의 격리성 수준에서 발생할 수 있는 현상들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad1525",
   "metadata": {},
   "source": [
    "### 1) Dirty Read\n",
    "- 다른 트랜잭션에 의해 수정됐지만 아직 커밋되지 않음 데이터를 읽는 것을 의미\n",
    "- 변경 후 아직 커밋되지 않은 값을 읽었는데 변경을 가한 트랜잭션이 최종적으로 롤백된다면 그 값을 읽은 트랜잭션은 비일관된 상태에 놓이게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d079c366",
   "metadata": {},
   "source": [
    "### 2) Non-Repetable Read\n",
    "- 한 트랜잭션 내에서 같은 쿼리를 두 번 수행했는데, 그 사이에 다른 트랜잭션이 값을 수정 또는 삭제하는 바람에 두 쿼리에 결과가 다르게 나타나는 현상"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caceee9",
   "metadata": {},
   "source": [
    "### 3) Phantom Read\n",
    "- 한 트랜잭션 내에서 같은 쿼리를 두 번 수행했는데, 첫 번째 쿼리에서 없던 유령(Phantom) 레코드가 두 번째 쿼리에서 나타나는 현상\n",
    "- TX1 트랜잭션이 지역별고객과 연령대별 고객을 연속해서 집계하는 도중에 새로운 고객이 TX2 트랜잭션에 의해 등록\n",
    "- 그 결과, 지역별고객과 연령대별 고객 두 집계 테이블을 통해 총고객수를 조회하면 서로 결과 값이 다름"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b70b873",
   "metadata": {},
   "source": [
    "## 나. 트랜잭션 격리성 수준(Transaction Isolation Level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd577ee",
   "metadata": {},
   "source": [
    "- **Read Uncommitted** \n",
    "    - 트랜잭션에서 처리 중인 아직 커밋되지 않음 데이터를 다른 트랜잭션이 읽는 것을 허용\n",
    "    - Dirty Read, Non-Repeatable Read, Phantom Read\n",
    "- **Read Committed**\n",
    "    - 트랜잭션이 커밋되어 확정된 데이터만 다른 트랜잭션이 읽도록 허용함으로써 Dirty Read를 방지해줌.\n",
    "    - 커밋된 데이터만 읽더라도 Non-Repeatable Read와 Phantom Read 현상을 막지는 못함.\n",
    "    - Non-Repeatable Read, Phantom Read\n",
    "- **Repeatable Read**\n",
    "    - 트랜잭션 내에서 쿼리를 두 번 이상 수행할 때, 첫 번째 쿼리에 있던 레코드가 사라지거나 값이 바뀌는 현상을 방지해 줌\n",
    "    - 이는 트랜잭션 격리성 수준이 Phantom Read 현상을 막지는 못함.\n",
    "    - Phantom Read\n",
    "- **Serializable Read**\n",
    "    - 트랜잭션 내에서 쿼리를 두 번 이상 수행할 때, 첫 번째 쿼리에 있던 레코드가 사라지거나 값이 바뀌지 않음은 물론 새로운 레코드가  \n",
    "      나타나지도 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f7a0e8",
   "metadata": {},
   "source": [
    "- 모든 DBMS가 4가지 레벨을 다 지원하지 않음\n",
    "- SQL Server와 DB2는 4가지 레벨을 다 지원하지만 오라클은 Read Committed와 Serializable Read만 지원\n",
    "- 대부분의 DBMS는 Read Committed를 기본 트랜잭션 격리성 수준으로 사용\n",
    "- 다중 트랜잭션 환경에서 DBMS가 제공하는 기능을 이용해 동시성을 제어하려면 트랜잭션 시작 전에 명시적으로  \n",
    "  SET TRANSACTION 명령어를 수행하면 됨\n",
    "- 트랜잭션 격리성 수준을 Repeatable Read나 Serializable Read로 올리면 ISO에서 정한 기준을 만족해야 하며,  \n",
    "  대부분 DBMS가 이를 구현하기 위해 Locking 매커니즘에 의존한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12c3a20",
   "metadata": {},
   "source": [
    "# 제 3절. 동시성 제어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322bd42a",
   "metadata": {},
   "source": [
    "- DBMS는 다수의 사용자를 가정하며, 동시에 작동하는 다중 트랜잭션의 상호 간섭 작용에서 데이터베이스를 보호 할 수 있어야 하며, 이를 동시성 제어(Concurrency Control)이라 한다.\n",
    "- 동시성을 제어할 수 있도록 하기 위해 모든 DBMS가 공통적으로 Lock 기능을 제공\n",
    "- SET TRANSACTION 명령어를 이용해 트랜잭션 격리성 수준을 조정할 수 있는 기능도 제공.\n",
    "- SQL Server의 경우, 기본 트랜잭션 격리성 수준인 Read committed 상태에선 레코드를 읽고 다음 레코드로 이동하자 마자 공유 Lock을 해제하지만,   Repeatable Read로 올리면 트랜잭션을 커밋될 때까지 공유 Lock을 유지\n",
    "- 동시성과 일관성의 상관관계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1d5d61",
   "metadata": {},
   "source": [
    "## 1. 비관적 동시성 제어 vs. 낙관적 동시성 제어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d1da44",
   "metadata": {},
   "source": [
    "### 가. 비관적 동시성 제어 (Pessimistic concurrency Contorl)\n",
    "- 사용자들이 같은 데이터를 동시에 수정할 것이라고 가정\n",
    "- 데이터를 읽는 시점에 Lock을 걸고 트랜잭션이 완료될 때까지 이를 유지\n",
    "- select 시점에 Lock을 거는 비관적 동시성 제어는 자칫 시스템 동시성을 심각하게 떨어뜨릴 우려가 있음\n",
    "- 아래와 같이 wait 또는 nowait 옵션을 함께 사용하는 것이 바람직"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29b4979",
   "metadata": {},
   "source": [
    "### 나. 낙관적 동시성 제어(Optimistic concurrency control)\n",
    "- 사용자들이 같은 데이터를 동시에 수정하지 않을 것이라고 가정\n",
    "- 이런 이유로 데이터를 읽을 때는 Lock을 설정하지 않음\n",
    "- 대신 수정 시점에, 다른 사용자에 의해 값이 변경됐는지를 반드시 검사해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defc636e",
   "metadata": {},
   "source": [
    "## 2. 다중버전 동시성 제어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91b5329",
   "metadata": {},
   "source": [
    "### 가. 일반적인 Locking 메커니즘의 문제점\n",
    "- 동시성 제어의 목표는 동시에 실행되는 트랜잭션 수를 최대화하면서도 입력, 수정, 삭제 ,검색 시 데이터 무결성이 유지하는데 있다. \n",
    "- 읽기 작업에 공유 Lock을 사용하는 일반적인 Locking 매커니즘에서는 읽기 작업과 쓰기 작업이 서로 방해를 일으키기 때문에 종종 동시성에 문제가 발생\n",
    "- 데이터를 일관성에 문제가 생기는 경우도 있어 이를 해결하려면 Lock을 더 오랫동안 유지하거나 테이블 레벨 Lock을 사용해야 하므로 동시성 저하 발생\n",
    "- 비일관성 읽기 문제를 해결하기 위한 일반적인 해법은 트랜잭션 격리성 수준을 상향  \n",
    "  기본 트랜잭션 격리성 수준(Read comitted)에서는 값을 읽는 순간에만 공유 Lock을 걸었다가 다음 레코드로 이동할 떄 Lock을 해제함으로써 위와 같은 현상이 발생\n",
    "- 트랜잭션 격리성 수준을 Repeatable Read로 올리면 TX1 쿼리가 진행되는 동안 읽은 레코드는 공유 Lock이 계속 유지되며 심지어 쿼리가 끝나고 다음 쿼리가 진행되는 동안에도 유지된다.\n",
    "- 트랜잭션 격리성 수준을 올리면 일관성이 높아지지만, Lock이 더 오래 유지됨으로 인해 동시성 저하 시키고 교착상태가 발생할 가능성도 커짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa053e85",
   "metadata": {},
   "source": [
    "### 나. 다중버전 동시성 제어\n",
    "- ORACLE은 버전 3부터 다중버전 동시성 제어(Multiversion Concurrency Control, MVCC) 매커니즘을 사용\n",
    "- MS SQL Server 2005, IBM DB2 9.7버전 부터 동시성 매커니즘을 제공하기 시작\n",
    "- MVCC란?\n",
    "    - 데이터를 변경할 때마다 그 변경사항을 UNDO 영역에 저장\n",
    "    - 데이터를 읽다가 쿼리(또는 트랜잭션)시작 시점 이후에 변경된(변경이 진행중이거나 이미 커밋된)값을 발견하면, UNDO 영역에 저장된 정보를 이용해 쿼리(또는 트랜잭션)시작 시점의 일관성 있는 버전(CR Copy)를 생성하고 읽음\n",
    "    - 쿼리 도중 배타적 Lock이 걸린, 즉 변경이 진행 중인 레코드를 만나더라도 대기하지 않기 때문에 동시성 측면에 유리\n",
    "    - UNDO 블록 I/O, CR Copy 생성, CR 블록 캐싱 같은 부가적인 작업의 오버헤드 발생\n",
    "    - Oracle은 UNDO 데이터를 UNDO 세그먼트에 저장 혹, SQL Server는 tempdb에 저장\n",
    "    - MVCC는 문자수중과 트랜잭션 수준의 읽기 일관성이 존재"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c8d3ab",
   "metadata": {},
   "source": [
    "### 다. 문장수준 읽기 일관성\n",
    "- 다른 트랜잭션에 의해 데이터의 추가, 변경, 삭제가 발생하더라도 단일 SQL문 내에서 일관성 있게 값을 읽는것을 말함.\n",
    "- 위의 그림은 10023 시점에서 시작된 쿼리가 10023 시점 이후에 변경된 데이터 블록을 만났을 때,   \n",
    "  Rollback(=UNDO) 세그먼트에 저장된 정보를 이용해 10023 이전 시점으로 되돌리고서 값을 읽는 것을 표현\n",
    "- SQL Server에서 문장수준 읽기 일관성 모드로 DB를 운영하려면 아래 명령어를 수행."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a11d2b",
   "metadata": {},
   "source": [
    "### 라. 트랜잭션 수준 읽기 일관성\n",
    "- 트랜잭션 수준 읽기 일관성은, 다른 트랜잭션에 의해 데이터의 추가, 변경 삭제가 발생하더라도 트랜잭션 내에서 일관성 있게 값을 읽는 것\n",
    "- Read committed에서 완벽한 문장수준의 읽기 일관성을 보장하는 MVCC 매커니즘도 트랜잭션 수준의 읽기 일관성은 보장하지 않음\n",
    "- 일반적인 Locking 매커니즘도 트랜잭션 수준의 읽기 일관성은 보장하지 않음\n",
    "- 트랜잭션 수준으로 완벽한 읽기 일관성을 보장받으려면 격리성 수준을 Serializable Read로 올려주어야 함.\n",
    "- Isolation Level을 Serializable Read로 상향조정하면, 일관성 기준 시점은 트랜잭션 시작 시점이 된다.  \n",
    "  물론 트랜잭션이 진행되는 동안 자신이 발생시킨 변경사항은 그대로 읽음\n",
    "- UNDO 데이터를 활용함으로써 높은 수준의 동시성과 읽기 일관성을 유지하는 대신, 일반적인 Locking 매커니즘에 없는 SNAPSHOT TOO OLD 에러가 MVCC에서 발생\n",
    "- UNDO 영역에 저장된 UNDO 정보가 다른 트랜잭션에 의해 재사용돼 필요한 CR Copy을 생성할 수 없을 때 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e4758",
   "metadata": {},
   "source": [
    "- SNAPSHOT TOO OLD 발생 가능성을 줄이는 방법\n",
    "    - UNDO 영역의 크기를 증가\n",
    "    - 불필요한 커밋을 자주 수행하지 않음\n",
    "    - FETCH ACROSS COMMIT 형태의 프로그램 작성을 피해 다른 방식으로 구현\n",
    "    - ANSI 표준에 따르면 커밋 이전에 열려 있던 커서는 더는 FETCH 하면 안됨\n",
    "    - 트랜잭션이 몰리는 시간대에 오래 걸리는 쿼리가 같이 수행되지 않도록 조정\n",
    "    - 큰 테이블을 일정 범위로 나누어 읽고 단계적으로 실행할 수 있도록 코딩\n",
    "    - SNAPSHOT TOO OLE 발생 가능성을 줄일 뿐 아니라 문제가 발생시 특정 부분부터 다시 시작할 수 있음 -> 읽기 일관성에 문제가 없을때만 적용\n",
    "    - 오랜 시간에 걸쳐 같은 블록을 여러번 방문하난 NL Join 형태의 조인문 또는 인덱스를 경유한 테이블 액세스를 수반하는 프로그램이 있는지 체크\n",
    "    - 이를 회피할 수 있는 방법(조인 메소드 변경, FUll Table Scan등)을 찾음\n",
    "    - 소트 부하를 감수하더라도 order by 등을 강제로 삽입해 소트 연산이 발생하도록 함 \n",
    "    - 대량 업데이트 후에 곧바로 해당 테이블 또는 인덱스를 Full Scan 하도록 쿼리를 수행하는 것도 하나의 해결 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4464f62",
   "metadata": {},
   "source": [
    "# 제 3장. 옵티마이저 원리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2091c5",
   "metadata": {},
   "source": [
    "# 제 1절 옵티마이저 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ad9d65",
   "metadata": {},
   "source": [
    "## 1. 옵티마이저 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060beba6",
   "metadata": {},
   "source": [
    "## 가. 옵티마이저란? \n",
    "- SQL을 가장 빠르고 효율적으로 수행할 최적(최저비용)의 처리경로를 생성해 주는 DBMS 내부의 핵심엔진이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5228873b",
   "metadata": {},
   "source": [
    "### SQL 최적화 과정\n",
    "- 사용자가 던진 쿼리 수행을 위해, 후보군이 될만한 실행계획을 찾는다.\n",
    "- 오브젝트 통계 및 시스템 통계정보를 이용해 각 실행계획의 예상비용을 산정한다.\n",
    "- 각 실행계획을 비교해서 최적비용을 갖는 하나를 선택한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb90089",
   "metadata": {},
   "source": [
    "## 나. 옵티마이저 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b35304",
   "metadata": {},
   "source": [
    "### 1) 규칙기반 옵티마이저 (= Heuristic 옵티마이저)\n",
    "- 미리 정해 놓은 규칙에 따라 액세스 경로를 평가하고 실행계획을 선택한다.\n",
    "- 액세스 경로별 우선순위로서, 인덱스 구조, 연산자, 조건절 형태가 순위를 결정짓는 주요 원인이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b125d52f",
   "metadata": {},
   "source": [
    "### 2) 비용기반 옵티마이저\n",
    "- 테이블과 인덱스에 대한 여러 통계정보를 기초로 각 오퍼레이션 단계별 예상 비용을 산정하고, 이를 합산한 총비용이 가장 낮은 실행계획을 선택한다.\n",
    "- 쿼리를 수행하는데 소요되는 일량 또는 시간을 뜻함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59446032",
   "metadata": {},
   "source": [
    "### 3) 오브젝트 통계 항목\n",
    "- 레코드 개수\n",
    "- 블록 개수\n",
    "- 평균 행 길이\n",
    "- 칼럼 값의 수\n",
    "- 칼럼 값의 분포\n",
    "- 인덱스 높이\n",
    "- 클러스터링 팩터\n",
    "- 시스템 통계정보(CPU 속도, 디스크 I/O 속도 등)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75f69a4",
   "metadata": {},
   "source": [
    "### 4) 스스로 학습하는 옵티마이저 (Self-Learning Optimizer)\n",
    "- 예상치와 런타임 수행 결과를 비교하고, 예상치가 빗나갔을 때 실행계획을 조정하는 옵티마이저로 발전할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b77c957",
   "metadata": {},
   "source": [
    "## 다. SQL 최적화 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664bd6d8",
   "metadata": {},
   "source": [
    "- Parser : SQL 문장을 이루는 개별 구성요소를 분석하고 파싱해서 파싱 트리를 만든다. (Syntax(문법), Semantic(의미))\n",
    "- Query Transformer : 파싱된 SQL을 좀 더 일반적이고 표준적인 형태로 변환한다.\n",
    "- Estimator : 오브젝트 및 시스템 통계정보를 이용해 쿼리 수행 각 단계의 선택도, 카디널리티, 비용을 계산하고, 궁극적으로는 실행계획 전체에  \n",
    "  대한 총 비용을 계산해 낸다.\n",
    "- Plan Generator : 하나의 쿼리를 수행하는데 있어, 후보군이 될만한 실행계획들을 생성해 낸다.\n",
    "- Row-Source Generator : 옵티마이저가 생성한 실행계획을 SQL 엔진이 실제 실행할 수 있는 코드 형태로 포맷팅한다.\n",
    "- SQL Engine : SQL을 실행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd822e5",
   "metadata": {},
   "source": [
    "## 라. 최적화 목표 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bace8d",
   "metadata": {},
   "source": [
    "### 1) 전체 처리속도 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eb0c79",
   "metadata": {},
   "source": [
    "### 2) 최초 응답속도 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012b179b",
   "metadata": {},
   "source": [
    "# 4. 통계정보를 이용한 비용계산 원리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cde03cd",
   "metadata": {},
   "source": [
    "## 옵티마이저 통계유형\n",
    "- 테이블 통계 : 전체 레코드 수, 총 블록 수, 빈 블록 수, 한 행당 평균 크기 등\n",
    "- 인덱스 통계 : 인덱스 높이, 리프 블록 수, 클러스터링 팩터, 인덱스 래코드 수 등\n",
    "- 칼럼 통계 : 값의 수, 최저 값, 최고 값, 밀도, null값 개수, 칼럼 히스토그램 등\n",
    "- 시스템 통계 : CPU 속도, 평균적인 I/O 속도, 초당 I/O 처리량 등"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fee43e",
   "metadata": {},
   "source": [
    "## 가. 선택도\n",
    "- 특정 조건에 의해 선택될 것으로 예상되는 레코드 비율\n",
    "- 실행계획 수립 절차 : 선택도 -> 카디널리티 -> 비용 -> 액세스 방식, 조인 순서, 조인 방법 등 결정\n",
    "- 히스토그램이 있으면 그것으로 선택도를 산정하며, 단일 컬럼에 대해서는 비교적 정확한 값을 구한다. \n",
    "- 히스토그램이 없거나 있더라도 조건절에 바인드 변수를 사용하면 옵티마이저는 데이터 분포가 균일하다고 가정한 상태에서 선택도를 구한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f173cd0",
   "metadata": {},
   "source": [
    "## 나. 카디널리티\n",
    "- 특정 액세스 단계를 거치고 난 후 출력될 것으로 예상되는 결과 건수\n",
    "- 카디널리티 = 총 로우수 * 선택도 = num_rows / num_distinct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d381cf89",
   "metadata": {},
   "source": [
    "## 다. 히스토그램\n",
    "- 분포가 균일하지 않은 칼럼으로 조회할 때 효과를 발휘한다. \n",
    "- 도수분포 히스토그램 (Frequency number) : 1 : 1 (버킷 : 값)\n",
    "- 높이균형 히스토그램 (Height-Balance Histogram) : 1: M (버킷 : 값) AND M : M (버킷 : 값)\n",
    "    - 데이터 분포도 : 1 / (버킷 개수) * 100\n",
    "    - 빈도수 : (총 레코드 개수) / (버킷 개수)\n",
    "- 빈도 수가 많은 값 (popular value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3c4cef",
   "metadata": {},
   "source": [
    "## 라. 비용 : 예상 일량 또는 시간\n",
    "- I/O 비용 모델 : I/O 요청 횟수만을 쿼리 수행 비용으로 간주\n",
    "- CPU 비용 모델 : I/O 요청 횟수만을 쿼리 수행 + 시간 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45151fcf",
   "metadata": {},
   "source": [
    "## 인덱스를 경유한 테이블 액세스 비용 : Single Block I/O COUNT\n",
    "- blevel : 브랜치 레빌을 의미하며, 리프 블록에 도달하기 전에 읽게 될 브랜치 블록 개수임\n",
    "- 클러스터링 팩터\n",
    "    - 특정 칼럼을 기준으로 같은 값을 갖는 데이터가 서로 모여있는 정보  \n",
    "    - 인덱스를 경유해 테이블 전체 로우를 액세스 할 때 읽을 것으로 예상되는 논리적인 블록 개수로 계수화 함\n",
    "- 유효 인덱스 선택도 \n",
    "    - 전체 인덱스 레코드 중에서 조건절을 만족하는 레코드를 찾기 위해 스캔할 것으로 예상되는 비율\n",
    "    - 리프 블록에는 인덱스 레코드가 정렬된 상태로 저장되므로 이 비율이 곧 방문할 리프 블록 비율임\n",
    "- 유효 테이블 선택도\n",
    "    - 전체 레코드 중에서 인덱스 스캔을 완료하고 최종적으로 테이블을 방문할 것으로 예상되는 비율\n",
    "    - 클러스터링 팩터는 인덱스를 경유해 전체 로우를 액세스할 때 읽힐것으로 예상되는 테이블 블록 개수이므로\n",
    "      여기에 유효 테이블 선택도를 곱함으로써 조건절에 대해 읽힐 것으로 예상 되는 테이블 블록 갯수를 구할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5cb007",
   "metadata": {},
   "source": [
    "비용 = blevel                                 \n",
    "    -- 인덱스 수직적 탐색 비용\n",
    "+ (리프 블록 수 * 유효 인덱스 선택도)         \n",
    "    -- 인덱스 수평적 탐색 비용\n",
    "+ (클러스터링 팩터 * 유효 테이블 선택도)      \n",
    "    -- 테이블 Random 액세스 비용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e531e80",
   "metadata": {},
   "source": [
    "## Full Scan에 의한 테이블 액세스 비용 : Multiblock I/O COUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7afd1b7",
   "metadata": {},
   "source": [
    "# 5. 옵티마이저 힌트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d084e9",
   "metadata": {},
   "source": [
    "## 가.Oracle 힌트 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f66d41",
   "metadata": {},
   "source": [
    "### 1) 힌트 기술 방법 \n",
    "**SELECT  /*+ LEADING( E2, E1) USER_NL (E1) INDEX( E1 EMP_EMP_ID_PK) USE_MERGE(J) FULL(J) */**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbf0eb9",
   "metadata": {},
   "source": [
    "### 2) 힌트가 무시되는 경우\n",
    "- 문법적으로 안 맞게 힌트를 기술\n",
    "- 의미적으로 안 맞게 힌트를 기술 \n",
    "    - 서브쿼리에 unnest와 PUSH_SUBQ를 같이 기술한 경우 (unnest되지 않음 서브쿼리만이 push_subq 힌트의 적용 대상임)\n",
    "- 잘못된 참조 사용 : 잘못된 별칭\n",
    "- 논리적으로 불가능한 액세스 경로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2486c38e",
   "metadata": {},
   "source": [
    "### 버그\n",
    "- Oracle : 사용 인덱스 변경시 에러 미발생 (장점: 안정적, 단점: 성능)\n",
    "- SQL Server : 사용 인덱스 변경시 에러 발생 (장점: 성능, 단점: ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0c3019",
   "metadata": {},
   "source": [
    "## 나. SQL Server 힌트\n",
    "- 테이블 힌트 : 테이블명 다음에 WITH절을 통해 지정한다. (fastfirstrow, holdlock, nolock 등)\n",
    "- 조인 힌트 : FROM절에 지정하며, 두 테이블 간 조인 전략에 영향을 미친다. (loop, hash, merge, remote 등)\n",
    "- 쿼리 힌트 : 쿼리당 맨 마지막에 한번만 지정할 수 있는 쿼리 힌트는 아래와 같이(??) OPTION절을 이용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef01a82",
   "metadata": {},
   "source": [
    "# 제 2절 쿼리 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03b76a5",
   "metadata": {},
   "source": [
    "## 1. 쿼리 변환\n",
    "- 실행계획을 생성하고 비용을 계산하기에 앞서 사용자 SQL을 최적화에 유리한 형태로 재작성함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecb0d78",
   "metadata": {},
   "source": [
    "# 2. 방식\n",
    "- 휴리스틱(Heuristic) 쿼리 변환 : 일종의 규칙 기반의 최적화 기법 (불필요한 부분 제거)\n",
    "- 비용기반 쿼리 변환 : 변환된 쿼리의 비용이 더 낮을 때만 그것을 사용하고, 그렇지 않을 떄는 원본 쿼리 그대로 두고 최적화를 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4800e2",
   "metadata": {},
   "source": [
    "## 서브쿼리 Unnesting (SSU : SImple Subquery Unnesting)\n",
    "- 서브쿼리를 메인 쿼리와 같은 레벨로 풀어낸다면 다양한 액세스 경로와 조인 메소드를 평가 할 수 있다.\n",
    "- 옵티마이저는 많은 조인 테크닉을 가지기 때문에 조인 형태로 변환했을 때 더 나은 실행계획을 찾을 가능성이 높아진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a41f5c",
   "metadata": {},
   "source": [
    "## 서브 쿼리의 처리의 옵티마이저의 선택\n",
    "- 조인문으로 변환 후 최적화 (Subquery Unnesting == Subquery Flattening) (다양한 실행계획)\n",
    "- 서브쿼리를 Unnesting 하지 않고 원래대로 둔 상태에서 최적화 한다. (Filter) (제한적 실행계획)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fe9de1",
   "metadata": {},
   "source": [
    "## 서브쿼리 Unnesting\n",
    "- 최근 옵티마이저는 서브쿼리르 Unnesting 했을 때 쿼리 수행 비용이 더 낮은지를 비교해 보고 적용 여부를 판단하는 쪽으로 발전하고 있다.\n",
    "- unnest : 서브쿼리를 Unnesting 함으로써 조인방식으로 최적화하도록 유도한다.\n",
    "- no_unnest : 서브쿼리를 그대로 둔 상태에서 필터 방식으로 최적화를 유도한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ee4412",
   "metadata": {},
   "source": [
    "## 서브쿼리가 M쪽 집합이거나 Nonunique 인덱스 일 때\n",
    "- PK/Unique 제약 또는 Unique 인덱스가 없는 서브쿼리 쪽 테이블이 먼저 드라이빙 된다면, 먼저 Sort unique 오퍼레이션을 수행함으로써 1쪽 집합으로 만든 다음에 조인한다.\n",
    "- 메인 쿼리 쪽 테이블이 드라이빙된다면 세미 조인방식으로 조인한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cf24d0",
   "metadata": {},
   "source": [
    "# 3. 뷰 Merging\n",
    "- 위 같은 단순한 뷰는 Merging하더라도 성능이 나빠지지 않는다.\n",
    "- 복잡합 연산을 포함하는 뷰는 Merging하면 오히려 성능이 더 나빠질 수 도있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71ca789",
   "metadata": {},
   "source": [
    "## 뷰 Merging이 불가능한 경우\n",
    "- 집합 연산자 (union, union all, intersect, minus)\n",
    "- connect by절\n",
    "- rownum pseudo 칼럼\n",
    "- select-list에 집계 함수(avg, count, max, min, sum) 사용\n",
    "- 분석 함수(Analytic Function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86eeb6a",
   "metadata": {},
   "source": [
    "# 4. 조건절 Pushing\n",
    "- 옵티마이저가 뷰를 처리함에 있어 1차적으로 뷰 Merging을 고려하지만, 조건절 Pushing을 시도할 수도 있다.\n",
    "- 조건절(Predicate) Pushdown : 쿼리 블록 밖에 있는 조건절을 쿼리 블록 안쪽으로 밀어 넣는 것을 말함\n",
    "- 조건절(Prediate) Pullup : 쿼리 블록 안에 있는 조건절을 쿼리 블록밖으로 내오는 것을 말하며, 그것을 다시 다른 쿼리 블록에 PushDown 하는 데 사용함\n",
    "- 조인 조건(Join Predicate) Pushdown : NL Join 수행 중에 드라이빙 테이블에서 읽은 값을 건건히 Inner 쪽(=right side) 뷰 쿼리 블록 안으로 밀어 넣는 것을 말함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c153715",
   "metadata": {},
   "source": [
    "## 가. 조건절(Predicate) Pushdown\n",
    "- 쿼리 블록 밖에 있는 조건절을 쿼리 블록 안쪽으로 밀어 넣는 것을 말함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dc5fd8",
   "metadata": {},
   "source": [
    "## 나. 조건절(Predicate) Pullup\n",
    "- 안쪽에 있는 조건들을 바깥 쪽으로 끄집어 내는 것을 말함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b33fb5",
   "metadata": {},
   "source": [
    "## 다. 조인 조건(Join Predicate) Pushdown\n",
    "- 조인 조건절을 뷰 쿼리 블록 안으로 밀어 넣는 것 (NL JOIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f273648",
   "metadata": {},
   "source": [
    "# 5. 조건절 이행\n",
    "- (A = B) 이고 (B = C) 이면 (A = C)이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7725f17",
   "metadata": {},
   "source": [
    "# 6. 불필요한 조인 제거\n",
    "- PK/FK 존재시 조인제거(Join Elimination) 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aea2d0d",
   "metadata": {},
   "source": [
    "# 7. OR 조건을 Union으로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cce139a",
   "metadata": {},
   "source": [
    "# 8. 기타 쿼리 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f2f749",
   "metadata": {},
   "source": [
    "## 가. 집합연산을 조인으로 변환\n",
    "- Intersect나 Minus값은 집합(Set) 연산을 조인 형태로 변환하는 것을 말한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788f1e26",
   "metadata": {},
   "source": [
    "## 나. 조인 칼럼에 IS NOT NULL 조건 추가 \n",
    "- NULL 조인시 실패하기 때문에 필터 조건을 추가하여 불필요한 테이블 액세스 및 조인 시도를 줄일 수 있어 쿼리 성능 향상에 도움이 된다.\n",
    "- FTS: Oracle의 경우 null값 비중이 5% 이상일 때 내부적으로 추가해준다.\n",
    "- Single Column Index Scan: 싱글 컬럼일때는 널 값을 가지고 있지 않기 때문에 조인 칼럼에 IS NOT NULL 조건 추가 불필요\n",
    "- Multi Column Index Scan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed47a582",
   "metadata": {},
   "source": [
    "## 다. 필터 조건 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53295b64",
   "metadata": {},
   "source": [
    "# 4장. 인덱스와 조인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bcbd87",
   "metadata": {},
   "source": [
    "# 5장. 고급 SQL 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38c951d",
   "metadata": {},
   "source": [
    "## 제 1절 고급 SQL 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdba716c",
   "metadata": {},
   "source": [
    "# 1. CASE문 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce9fad1",
   "metadata": {},
   "source": [
    "# 2. 데이터 복제 기법 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fee3483",
   "metadata": {},
   "source": [
    "# 3. Union All을 활용한 M:M 관계의 조인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acfacd0",
   "metadata": {},
   "source": [
    "# 4. 페이징 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54137d5f",
   "metadata": {},
   "source": [
    "## 가. 일반적인 페이징 처리용 SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95636ab",
   "metadata": {},
   "source": [
    "## 나. 뒤쪽 페이지까지 자주 조회할 때"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554d6241",
   "metadata": {},
   "source": [
    "## 다. Union All 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4f294c",
   "metadata": {},
   "source": [
    "# 5. 윈도우 함수 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98f6938",
   "metadata": {},
   "source": [
    "# 6. With 구문 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93182934",
   "metadata": {},
   "source": [
    "# 제 2절 소트 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798d0cbd",
   "metadata": {},
   "source": [
    "# 1. 소트와 성능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eaca76",
   "metadata": {},
   "source": [
    "## 가. 메모리 소트와 디스크 소트\n",
    "- 메모리 소트 : 전체 데이터의 정렬 작업을 할당받은 소트 영역 내에서 완료하는 것을 말함\n",
    "- 디스크 소트 : 할당받은 소트 영역 내에서 정렬을 완료하지 못해 디스크 공간까지 사용하는 것을 말함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26b3330",
   "metadata": {},
   "source": [
    "## 나. 소트를 발생시키는 오퍼레이션"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b185dda",
   "metadata": {},
   "source": [
    "### 1) Sort Aggregate\n",
    "- 전체 로우를 대상으로 집계를 수행할 때 나타남\n",
    "- 실제 소트가 발생하진 않는다. \n",
    "- SQL Server 실행계획엔 'Stream Aggregate'라고 표시됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a3965e",
   "metadata": {},
   "source": [
    "### 3) Sort Order By\n",
    "- 정렬된 결과집합을 얻고자 할 때 나타남"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b3e9f9",
   "metadata": {},
   "source": [
    "### 4) Sort Unique\n",
    "- 선택된 결과집합에서 중복 레코드를 제거하고자 할 때 나타남\n",
    "- Union 연산자나 Distinct 연산자를 사용할 때가 대표적임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e9e9f0",
   "metadata": {},
   "source": [
    "### 5) Sort Join\n",
    "- Sort Merge Join을 수행할 때 나타남"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5637752",
   "metadata": {},
   "source": [
    "### 6) Window Sort\n",
    "- 윈도우 함수를 수행할 때 나타남"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147cd407",
   "metadata": {},
   "source": [
    "## 다. 소트 튜닝 요약\n",
    "- 소트 오퍼레이션은 메모리 집약적, CPU 집약적, 데이터량이 많을 때는 디스크 I/O까지 발생시킴\n",
    "- 특히, 부분범위처리를 할 수 없게 만듬\n",
    "- 될 수 있으면 소트가 발생하지 않도록 쿼리 작성해야 하고,\n",
    "- 소트가 불가피하다면 메모리 내에서 수행을 완료할 수 있도록 해야 함\n",
    "- 데이터 모델 측면에서의 검토\n",
    "- 소트가 발생하지 않도록 SQL 작성\n",
    "- 인덱스를 이용한 소트 연산 대체\n",
    "- 소트 영역을 적게 사용하도록 SQL 작성\n",
    "- 소트 영역 크기 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c876c37b",
   "metadata": {},
   "source": [
    "# 2. 데이터 모델 측면에서의 검토\n",
    "- 자주 사용되는 데이터 액세스 패턴을 고려하지 않은 채 물리 설계를 진행하거나,\n",
    "- M:M 관계의 테이블을 해소하지 않아 핵심 프로그램이 항상 소트 오퍼레이션을 수반하는 경우 등."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7c91be",
   "metadata": {},
   "source": [
    "# 3. 소트가 발생하지 않도록 SQL 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a72bc",
   "metadata": {},
   "source": [
    "## 가. Union을 Union All로 대체"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6d6001",
   "metadata": {},
   "source": [
    "## 나. Distinct를 Exists 서브쿼리로 대체"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3dc6b2",
   "metadata": {},
   "source": [
    "## 다. 불필요한 Count 연산 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87523f6b",
   "metadata": {},
   "source": [
    "# 4. 인덱스를 이용한 소트 연산 대체"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c59cbe",
   "metadata": {},
   "source": [
    "## 가. Sort Order By 대체"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d19f28",
   "metadata": {},
   "source": [
    "## 나. Sort Group By 대체"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ea3632",
   "metadata": {},
   "source": [
    "## 다. 인덱스를 활용한 Min, Max 구하기\n",
    "- 인덱스가 항상 정렬 상태를 유지한다는 특징을 이용하여 Min, Max 값 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb88bd5",
   "metadata": {},
   "source": [
    "# 5. 소트 영역을 적게 사용하도록 SQL 작성\n",
    "- 소트 연산이 불가피하다면 메모리 내에서 처리되게 하려고 노력해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033f98fd",
   "metadata": {},
   "source": [
    "## 가. 소트 완료 후 데이터 가공"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622ef292",
   "metadata": {},
   "source": [
    "## 나. Top-N 쿼리\n",
    "- Top-N 쿼리 형태로 작성하면 소트 연산(=값 비교) 횟수와 소트 영역 사용량을 최소화할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b92714",
   "metadata": {},
   "source": [
    "# 6. 소트 영역 크기 조정\n",
    "- SQL Server에서는 소트 영역을 수동으로 조정하지 않음.\n",
    "- Oracle 8i : sort_area_size 파라미터로 조정함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b46e2ea",
   "metadata": {},
   "source": [
    "# 제 3절. DML 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746ae78c",
   "metadata": {},
   "source": [
    "# 1. 인덱스 유지 비용\n",
    "- 테이블 데이터 변경 -> 관련 인덱스 변경 발생\n",
    "- 변경할 인덱스 레코드를 찾아가는 비용 + Redo, Undo를 생성하는 비용\n",
    "- Update 수행시, 테이블 레코드는 직접 변경하지만 인덱스 레코드는 정렬 상태를 유지하기 위해\n",
    "    - Delete & Insert 방식으로 처리됨. Undo 레코드도 2개씩 기록됨\n",
    "    - 따라서 변경 컬럼과 관련된 인덱스 개수에 따라 Update 성능이 좌우됨\n",
    "- Insert나 Delete 문일 때는 인덱스 모두에 변경을 가하므로 총 인덱스 개수에 따라 성능이 크게 달라짐.\n",
    "\n",
    "- 인덱스 개수가 DML 성능에 큰 영향을 미치므로 대량의 데이터를 입력/수정/삭제할 때는 인덱스를 모두 Drop하거나 Unusable 상태로 변경한 다음 작업하는 것이 빠를 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b224771",
   "metadata": {},
   "source": [
    "# 2. Insert 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239205be",
   "metadata": {},
   "source": [
    "## 가. Oracle Insert 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95a83f5",
   "metadata": {},
   "source": [
    "### Direct Path Insert\n",
    "- 일반적인 힙 구조 테이블에서의 데이터 입력 방법\n",
    "- 데이터 입력시 빈 공간을 가진 블록리스트를 관리하는 Freelist로 부터 블록을 할당받아 무작위로 값을 입력\n",
    "- Freelist에서 할당받은 블록을 버퍼 캐시에서 찾아보고, 없으면 데이터 파일에서 읽어 캐시에 적재한 후 데이터를 삽입\n",
    "- 대량의 데이터 입력시 위 방식은 비효율적인\n",
    "- Direct Path Insert : Freelist를 거치지 않고 HWM 바깥 영역에, 버퍼 캐시를 거치지 않고 데이터 파일에 곧바로 입력하는 방식. Undo 데이터를 쌓지 않음\n",
    "- Direct Path Insert 방식으로 데이터를 입력하는 방법\n",
    "    - Insert select 문장에 /*+append */ 힌트 사용\n",
    "    - 병렬 모드로 insert\n",
    "    - direct 옵션을 지정하고 SQL*Loader(sqlldr)로 데이터를 로드\n",
    "    - CTAS(create table ... as select) 문장을 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae35eac",
   "metadata": {},
   "source": [
    "### nologging 모드 insert \n",
    "- 테이블 속성을 nologging으로 바꿔주면 Redo 로그까지 최소화(데이터 딕셔너리 변경사항만 로깅)되므로 더 빠르게 insert 할 수 있음\n",
    "- Direct Path Insert 일 때만 작동.\n",
    "- 주의) Direct Path Insert 방식으로 데이터 입력시 Exclusive 모드 테이블 Lock이 걸리므로,\n",
    "    - 작업이 수행되는 동안 해당 테이블에 DML 수행 불가.\n",
    "    - nologging 상태에서 입력한 데이터는 장애 발생시 복구 불가.\n",
    "    - 그러므로 insert 후 바로 백업 실시 or 언제든 재생 가능한 데이터를 insert할 때만 사용해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d118f0",
   "metadata": {},
   "source": [
    "## 나. SQL Server Insert 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c037dc",
   "metadata": {},
   "source": [
    "### 최소 로깅(minimal nologging)\n",
    "- 최소 로깅 기능을 사용하려면, 데이터베이스의 복구 모델(Recovery model)이 'Bulk-logged' 또는 'Simple'로 설정돼 있어야 함.\n",
    "    1) 파일 데이터를 읽어 DB로 로딩하는 Bulk Insert 구문을 사용할 때, With 옵션에 TABLOCK 힌트를 추가\n",
    "    2) 복구 모델이 'Bulk-logged' 또는 'Simple'로 설정된 상태에서 select into 사용\n",
    "    3) SQL Server 2008 버전부터 힙(Heap) 테이블에 Insert할 때 TABLOCK 힌트를 사용. \n",
    "- B*Tree 구조 테이블(클러스터형 인덱스)에 Insert할 떄도 최소 로깅 가능.\n",
    "- 전제 조건은 소스 데이터를 목표 테이블 정렬(클러스터형 인덱스 정렬 키) 순으로 정렬해야 한다는 점.\n",
    "- 필요한 다른 조건\n",
    "    - 비어있는 B*Tree 구조에서 TABLOCK 힌트 사용\n",
    "    - 비어있는 B*Tree 구조에서 TF-610을 활성화\n",
    "    - 비어 있지 않은 B*Tree 구조에서 TF-610을 활성화하고, 새로운 키 범위만 입력\n",
    "- TABLOCK 힌트가 반드시 필요하지 않으므로 입력하는 값 범위가 중복되지 않는다면 동시 Insert도 가능함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6b38b9",
   "metadata": {},
   "source": [
    "# 3. Update 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b8ece2",
   "metadata": {},
   "source": [
    "## 가. Truncate & Insert 방식 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f7c8d",
   "metadata": {},
   "source": [
    "- 대량의 데이터변경시 오랜 시간이 걸릴 수 있음\n",
    "- 테이블 데이터 갱신 작업\n",
    "- 인덱스 데이터 갱신\n",
    "- 버퍼 캐시에 없는 블록인 경우 디스크에서 읽어 버퍼 캐시에 적재 후 갱신\n",
    "- Redo, Undo 정보 생성\n",
    "- 블록에 빈 공간 없으면 새 블록 할당(Row Migration 발생)\n",
    "- Update문을 이용하는 것보다 아래 방식으로 처리하는 것이 더 빠를 수 있음\n",
    "    - 1. 대상테이블의 데이터로 temp 테이블 생성\n",
    "    - 2. 대상테이블의 제약조건 및 인덱스 삭제\n",
    "    - 3. 대상테이블 truncate\n",
    "    - 4. temp 테이블에 있는 원본 데이터를 update 할 값으로 수정하여 대상테이블에 insert \n",
    "    - 5. 대상테이블에 제약조건 및 인덱스 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a902b30",
   "metadata": {},
   "source": [
    "## 나. 조인을 내포한 Update 튜닝\n",
    "- 조인을 내포한 Update 문 수행시 Update 자체 성능보다 조인 과정에서 발생하는 비효율 때문에 성능이 느려지는 경우가 더 많음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa6b013",
   "metadata": {},
   "source": [
    "### 전통적인 방식의 Update문"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0305a5",
   "metadata": {},
   "source": [
    "### SQL Server 확장 Update문 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed9418b",
   "metadata": {},
   "source": [
    "### Oracle 수정 가능 조인 뷰 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3df90ee",
   "metadata": {},
   "source": [
    "### Oracle Merge문 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685abbc7",
   "metadata": {},
   "source": [
    "# 제 4절. 파티션 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3053aad",
   "metadata": {},
   "source": [
    "# 1. 파티션 개요\n",
    "- 파티셔닝은 테이블 또는 인덱스 데이터를 파티션 단위로 나누어 저장하는 것을 말한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951d1f56",
   "metadata": {},
   "source": [
    "# 2. 파티션의 유형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b6c538",
   "metadata": {},
   "source": [
    "## Range 파티셔닝\n",
    "- 파티션 키 값의 범위(Range)로 분할\n",
    "- 파티셔닝의 가장 일반적인 형태이며, 주로 날짜 칼럼을 기준으로 함 예) 판매 데이터를 월별로 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882f7e27",
   "metadata": {},
   "source": [
    "## Hash 파티셔닝\n",
    "- 파티션 키 값에 해시 함수를 적용하고, 거기서 변환된 값으로 파티션 매핑\n",
    "- 데이터가 모든 파티션에 고르게 분산되도록 DBMS가 관리\n",
    "    - 각 로우의 저장 위치 예측 불가\n",
    "- 파티션 키의 데이터 분포가 고른 칼럼이어야 효과적\n",
    "    - 예) 고객번호, 주문일련번호 등\n",
    "- 병렬처리 시 성능효과 극대화\n",
    "- DML 경합 분산에 효과적"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbae5173",
   "metadata": {},
   "source": [
    "## List 파티셔닝\n",
    "- 불연속적인 값의 목록을 각 파티션에 지정\n",
    "- 순서와 상관없이, 사용자가 미리 정한 그룹핑 기준에 따라 데이터를 분할 저장\n",
    "    - 예) 판매 데이터를 지역별로 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa6e052",
   "metadata": {},
   "source": [
    "## Composite 파티셔닝\n",
    "- Range나 List 파티션 내에 또 다른 서브 파티션(Range, Hash, List) 구성\n",
    "    - Range + List 또는 List + Hash 등\n",
    "- Range나 List 파티션이 갖는 이점 + 각 서브 파티션 구성의 이점"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e80284",
   "metadata": {},
   "source": [
    "# 3. 파티션 Pruning\n",
    "- 파티션 Pruning은 옵티마이져가 SQL의 대상 테이블과 조건절을 분석하여 불필요한 파티션을 액세스 대상에서 제외하는 기능을 말한다.\n",
    "- 기본 파티션 Pruning에는 정적 Pruning과 동적 Pruning이 있고, DBMS별로 서브쿼리 Pruning, 조인 필터 Pruning 같은 고급 Pruning 기법을 사용한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d204e8",
   "metadata": {},
   "source": [
    "## 가. 정적(Static) 파티션 Pruning\n",
    "- 액세스할 파티션을 컴파일 시점에 미리 결정하며, 파티션 키 칼럼을 상수 조건으로 조회하는 경우에 작동한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4856be04",
   "metadata": {},
   "source": [
    "## 나. 동적(Dynamic) 파티션 Pruning\n",
    "- 액세스할 파티션을 실행 시점에 결정하며, 파티션 키 칼럼을 바인드 변수로 조회하는 경우가 대표적\n",
    "- NL Join할 떄도 Inner 테이블이 조인 칼럼 기준으로 파티셔닝 돼 있으면 동적 Pruning이 작동한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d70aacf",
   "metadata": {},
   "source": [
    "# 4. 인덱스 파티셔닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba838532",
   "metadata": {},
   "source": [
    "## 가. Local 파티션 인덱스 vs. Global 파티션 인덱스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eaef76",
   "metadata": {},
   "source": [
    "### Local 파티션 인덱스\n",
    "- 테이블 파티션과 1:1로 대응되도록 파티셔닝한 인덱스\n",
    "- 인덱스 파티션 키를 사용자가 따로 지정하지 않으며, 테이블과 1:1 관계를 유지하도록 DBMS가 자동으로 관리해 줌\n",
    "- SQL Server에선 '정렬된(aligned) 파티션 인덱스'라고 부름"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e315fdde",
   "metadata": {},
   "source": [
    "### Global 파티션 인덱스\n",
    "- 테이블 파티션과 독립적인 구성을 갖도록 파티셔닝한 인덱스 \n",
    "- SQL Server에선 '정렬되지 않은(un-aligned) 파티션 인덱스'라고 부름"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9795130",
   "metadata": {},
   "source": [
    "## 나. Prefixed 파티션 인덱스 vs. NonPrefixed 파티션 인덱스\n",
    "- 인덱스 파티션 키 칼럼이 인덱스 구성상 왼쪽 선두 컬럼에 위치하는지에 따른 구분이다\n",
    "\n",
    "\n",
    "- Prefixed\n",
    "    - 파티션 인덱스를 생성할 때, 파티션 키 칼럼을 인덱스 키 칼럼 왼쪽 선두에 두는 것을 말한다.\n",
    "- Non-prefixed\n",
    "    - 파티션 인덱스를 생성할 때, 파티션 키 칼럼을 인덱스 키 칼럼 왼쪽 선두에 두지 않는 것을 말한다.\n",
    "    - 파티션 키가 인덱스 칼럼에 아예 속하지 않을 때도 여기에 속한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f585f9",
   "metadata": {},
   "source": [
    "### 비파티션까지 포함에 인덱스를 총 5가지 유형으로 구분할 수 있다\n",
    "- Local Prefixed 파티션 인덱스 \n",
    "- Local NonPrefixed 파티션 인덱스\n",
    "- Global Prefixed 파티션 인덱스\n",
    "- Global NonPrefixed 파티션 인덱스\n",
    "- NonPartitioned(비파티션) 인덱스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55bbc9e",
   "metadata": {},
   "source": [
    "## 다. 인덱스 파티셔닝 가이드\n",
    "- 인덱스 파티션은 파티션 테이블과 마찬가지로 성능, 관리 평의성, 가용성, 확장성 등을 제공한다. \n",
    "- 테이블에 종속적인 Local 파티션, 테이블과 독립적인 Global 파티션 모두 가능하지만, 관리적인 측면에서는 Local 인덱스가 훨씬 유용하다.\n",
    "- 테이블 파티션에 대한 Drop, Exchange, Split 등의 작업 시 Global 인덱스는 Unusable 상태가 되기 때문이다. \n",
    "- 인덱스를 다시 사용할 수 있게 하려면 인덱스를 Rebuild 하거나 재생성해 주어야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a56d197",
   "metadata": {},
   "source": [
    "### 비파티션\n",
    "- 파티션 키 칼럼이 조건절에 누락되면 여러 인덱스 파티션을 액세스해야 하므로 비효율적. 특히, OLTP 환경에서 성능에 미치는 영향이 크므로 비파티셔닝 전략이 유용할 수 있음.\n",
    "- NL Join에서 파티션 키에 대한 넓은 범위검색 조건을 가지고 Inner 테이블 액세스 용도로 인덱스 파티션이 사용된다면 비효율적 -> 비파티션 인덱스 사용을 고려\n",
    "- 파티션 인덱스를 이용하면 sort order by 대체 효과 상실. 소트 연산을 대체함으로써 부분범위 처리를 활용하고자 할 땐 비파티셔닝 전략이 유용\n",
    "- 테이블 파티션 이동, 삭제 등의 작업 시 unusable 되므로 적용 시 주의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0471131",
   "metadata": {},
   "source": [
    "### Global Prefixed\n",
    "- 인덱스 경합 분산에 효과적\n",
    "- 여러 Local 인덱스 파티션을 액세스하는 것이 비효율적일 때 대안으로 활용 가능\n",
    "- 테이블 파티션 이동, 삭제 등의 작업 시 unusable 되므로 적용 시 주의 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df91b23",
   "metadata": {},
   "source": [
    "### Local Prefixed\n",
    "- 관리적 측면에서 유용 : 테이블 파티션에 대한 추가, 삭제 등의 작업이 빈번할 때\n",
    "- 이력성 데이터를 주로 관리하는 DB 환경에 효과적\n",
    "- 파티션 키 칼럼이 '=' 조건으로 사용될 때 유용\n",
    "- 파티셔닝 칼럼에 대한 검색 조건이 없으면 인덱스 선두 컬럼이 조건절에 누락된 것이므로 정상적인 사용이 불가\n",
    "- 파티션 키 칼럼이 Like, Between, 부등호 같은 범위검색 조건일때 불리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ec558b",
   "metadata": {},
   "source": [
    "### Local NonPrefixed\n",
    "- 관리적 측면에서 유용 : 테이블 파티션에 대한 추가, 삭제 등의 작업이 빈번할 때 \n",
    "- 이력성 데이터를 주로 관리하는 DB 환경에 효과적\n",
    "- 파티션 키 칼럼이 조건절에 사용될 때 유용\n",
    "- 파티셔닝 칼럼에 대한 검색 조건이 없으면 인덱스 파티션 전체를 액세스하는 비효율이 발생할 수 있으므로 주의 \n",
    "- 파티션 키 칼럼이 범위검색 조건으로 자주 사용된다면 Local Prefixed 보다 Local NonPrefixed가 유리. 그렇더라도 좁은 범위검색이어야함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d545e8",
   "metadata": {},
   "source": [
    "# 제 5절. 배치 프로그램 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72893288",
   "metadata": {},
   "source": [
    "# 1. 배치 프로그램 튜닝 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f472434e",
   "metadata": {},
   "source": [
    "## 가. 배치 프로그램이란\n",
    "- 일련의 작업들을 하나의 작업 단위로 묶어 연속적으로 일괄 처리하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c903e4",
   "metadata": {},
   "source": [
    "- 사용자와의 상호작용 없이\n",
    "- 대량의 데이터를 처리하는\n",
    "- 일련의 작업들을 묶어\n",
    "- 정기적으로 반복 수행하거나\n",
    "- 정해진 규칙에 따라 자동으로 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d2a3ba",
   "metadata": {},
   "source": [
    "- 정기 배치 : 정해진 시점(주로 야간)에 실행\n",
    "- 이벤트성 배치 : 사용자의 명시적인 요규가 있을 때마다 실행\n",
    "- On-Demand 배치 : 사용자의 명시적인 요구가 있을 때마다 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e9ef3f",
   "metadata": {},
   "source": [
    "## 나. 배치 환경의 변화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d87dab",
   "metadata": {},
   "source": [
    "### 과거\n",
    "- 일 또는 월 배치 작업 위주\n",
    "- 야간에 생성된 데이터를 주간 업무시간에 활용\n",
    "- 온라인과 배치 프로그램의 구분이 비교적 명확\n",
    "\n",
    "### 현재\n",
    "- 시간 배치 작업의 비중이 증가\n",
    "- 분 배치 작업이 일부 존재\n",
    "- On-Demand 배치를 제한적이나마 허용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf33868",
   "metadata": {},
   "source": [
    "## 다. 성능 개선 목표 설정\n",
    "- 배치 목표에 따라 성능개선이 틀려진다. \n",
    "- 온라인 프로그램은 경우에 따라 전체 처리속도 최적화나 최초 응답속도 최적화를 목표로 선택하지만,\n",
    "- 배치 프로그램은 항상 전체 처리속도 최적화를 목표로 설정해야 한다.\n",
    "- 개별 프로그램 차원에서도 그렇지만 야간에 수행되는 전체 배치 프로그램에 대한 목표도 마찬가지다. \n",
    "- 개별 서비스 또는 프로그램을 가장 빠른 속도로 최적화하더라도 전체 배치 프로그램 수행시간을 단축시키지 못하면 무의미하다.\n",
    "- 여러 부서의 배치가 있다면 서로 겹치지 않게 자원을 쓸수 있게 하면 시간을 단축 시킬 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd9a6d",
   "metadata": {},
   "source": [
    "## 라. 배치 프로그램 구현 패턴과 튜닝 방안"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9ecf61",
   "metadata": {},
   "source": [
    "### 절차형으로 작성된 프로그램\n",
    "- 애플리케이션 커서를 열고, 루프 내에서 또 다른 SQL이나 서브 프로시저를 호출하면서 같은 처리를 반복하는 형태\n",
    "- 병목을 일으키는 SQL을 찾아 I/O 튜닝: 인덱스를 재구성하고 액세스 경로 최적화\n",
    "- 프로그램 Parallel 활용 : 메인 SQL 읽은 데이터 범위를 달리하여 프로그램을 동시에 활용\n",
    "- Array Processing을 활용\n",
    "- One SQL 위주로 프로그램을 다시 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84dbfbb",
   "metadata": {},
   "source": [
    "### One SQL 위주 프로그램\n",
    "- One SQl로 구성하거나, 집합적으로 정의된 여러 SQL을 단계적으로 실행\n",
    "- 병목을 일으키는 오퍼레이션을 찾아 I/O 튜닝\n",
    "- Index scan 보다는 full table scan 방식으로 처리\n",
    "- NL join 보다는 Hash Join으로 처리\n",
    "- 임시 테이블 활용\n",
    "- 파티셔닝 활용\n",
    "- 병렬처리 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5a9cf1",
   "metadata": {},
   "source": [
    "# 2. 병렬 처리 활용\n",
    "- SQL문이 수행해야 할 작업 범위를 여러 개의 작은 단위로 나누어 여러 프로세스가 동시에 처리한느 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07533e89",
   "metadata": {},
   "source": [
    "## 가. Query Coordinator와 병렬 서버 프로세스\n",
    "- Query Coordinator는 병렬 SQL문을 발행한 세션을 말하며, 병렬 서버 프로세스는 실제 작업을 수행하는 개별 세션들을 말한다. \n",
    "- 병럴 SQL이 시작되면 QC는 사용자가 지정한 병렬도(DOP)와 오퍼레이션 종류에 따라 하나 또는 두 개의 병렬 서버 집합을 할당\n",
    "- 우선 서버 풀로부터 필요한 만큼 서버 프로세스를 확보하고, 부족분은 새로 생성한다. \n",
    "- QC는 각 병렬 서버에게 작업을 할당한다. 작업을 지시하고 일이 잘 진행되는지 관리감독하는 작업반장 역할이다. \n",
    "- 병렬로 처리하도록 사용자가 지시하지 않은 테이블은 QC가 직접 처리한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9741fb",
   "metadata": {},
   "source": [
    "## 나. Intra-Operation Parallelism과 Inter-Operation Parallelism\n",
    "- 서로 배타적인 범위를 독립적으로 동시에 처리하는 것을 'Intra-Operation Parallelism'이라고 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e09798d",
   "metadata": {},
   "source": [
    "## 다. 테이블 큐 \n",
    "- 쿼리 서버 집합 간(P -> P) 또는 QC와 쿼리 서버 집합 간(P->S, S->P) 데이터 전송을 위해 연결된 파이프 라인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef4b541",
   "metadata": {},
   "source": [
    "### 생산자 / 소비자 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1a44d8",
   "metadata": {},
   "source": [
    "### 병렬 실행계획에서 생산자와 소비자 식별"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ea43b",
   "metadata": {},
   "source": [
    "## 라. IN-OUT 오퍼레이션"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce5dc60",
   "metadata": {},
   "source": [
    "- S->P, P->S, P->P는 프로세스 간 통신이 발생한다. \n",
    "- PCWP와 PCWC는 프로세스 간 통신이 발생하지 않으며, 각 병렬 서버가 독립적으로 여러 스텝을 처리할 떄 나타난다. \n",
    "- 하위 스텝의 출력 값이 상위 스템의 입력값을 사용된다. \n",
    "- P->P, P->S, PCWP, PCWC는 병렬 오퍼레이션인 바면 S->P는 직렬(Serial) 오퍼레이션이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6adf2c",
   "metadata": {},
   "source": [
    "## 마. 데이터 재분배"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6723ab6",
   "metadata": {},
   "source": [
    "### RANGE\n",
    "- order by 또는 sort group by를 병렬로 처리할 때 사용된다. \n",
    "- 정렬 작업을 맡은 두 번째 서버 집합의 프로세스마다 처리 범위를 지정하고 나서, 데이터를 읽는 첫 번쨰 서버 집합이 두 번째 서버 집합의 정해진 프로스세에게 \"정렬 키 값에 따라\" 분배하는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6151cfb",
   "metadata": {},
   "source": [
    "### HASH\n",
    "- 조인이나 hash group by를 병렬로 처리할 때 사용된다. \n",
    "- 조인 키나 group by 키 값을 해시 함수에 적용하고 리턴된 값에 따라 데이터를 분배하는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1962a2",
   "metadata": {},
   "source": [
    "### BROADCAST\n",
    "- QC 또는 첫 번째 서버 집합에 속한 프로세스들이 각각 읽은 데이터를 두 번째 서버 집합에 속한 \"모든\" 병렬 프로세스에게 전송하는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5b90d7",
   "metadata": {},
   "source": [
    "### KEY\n",
    "- 특정 칼럼들 기준으로 테이블 또는 인덱스를 파티셔닝할 때 사용하는 분배 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67139260",
   "metadata": {},
   "source": [
    "### ROUND-ROBIN\n",
    "- 파티션 키, 정렬 키, 해시 함수 등에 의존하지 않고 반대편 병렬 서버에 무작위로 데이터를 분배할 때 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc2a55c",
   "metadata": {},
   "source": [
    "## 바. pq_distribute 힌트 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ddd470",
   "metadata": {},
   "source": [
    "### 1) pq_distribute 힌트의 용도\n",
    "- 조인되는 양쪽 테이블의 파티션 구성, 데이터 크기 등에 따라 병렬 조인을 수행하는 옵티마이저의 선택이 달라질 수 있다.\n",
    "- 대개 옵티마이저의 선택이 최적이라고 할 수 있지만 가끔 그렇지 못한 경우가 있다\n",
    "- 그럴 때 pq_distribute 힌트를 사용함으로써 옵티마이저의 선택을 무시하고 사용자가 직접 조인을 위한 데이터 분배 방식을 결정할 수 있다.\n",
    "- 옵티마이저가 파티션된 테이블을 적절히 활용하지 못하고 동적 재분할을 시도할 때\n",
    "- 기존 파티션 키를 무시하고 다른 키 값으로 동적 재분할하고 싶을때\n",
    "- 통계정보가 부정확하거나 통계정보를 제공하기 어려운 상황에 실행계획을 고정시키고자 할 떄\n",
    "- 기타 여러 가지 이유로 데이터 분배 방식을 변경하고자 할 때\n",
    "- 병렬 방식으로 조인을 수행하기 위해서는 프로세스들이 서로 \"독립적으로\" 작업할 수 있도록 사전 준비작업이 필요하다\n",
    "- 병렬 쿼리는 '분할 & 정복(Divide & Conquer)원리'에 기초한다. \n",
    "- 그 중에서도 병렬 조인을 위해서는 '분배 & 조인(Distribute & Join) 원리'가 작동함을 이해하는 것이 매우 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d443f8e7",
   "metadata": {},
   "source": [
    "### /*+ pq_distribute(inner, none, none) */   \n",
    "- Full-Partition Wise Join으로 유도할 때 사용\n",
    "\n",
    "### /*+ pq_distribute(inner, partition, none) */   \n",
    "- Partial-Partition Wise Join으로 유도할 떄 사용하며, inner 테이블을 inner 테이블 파티션 기준에 따라 파티셔닝하라는 뜻이다.\n",
    "\n",
    "### /*+ pq_distribute(inner, none, partition) */  \n",
    "- Partial-Partition Wise Join으로 유도할 떄 사용하며, outer 테이블을 inner 테이블 파티션 기준에 따라 파티셔닝하라는 뜻이다.\n",
    "\n",
    "### /*+ pq_distribute(inner, hash, hash) */  \n",
    "- 조인 키 칼럼을 해시 함수에 적용하고 거기서 반환된 값을 기준으로 양쪽 테이블을 동적으로 파티셔닝하라는 뜻\n",
    " \n",
    "### /*+ pq_distribute(inner, broadcast, none) */  \n",
    "- outer 테이블을 Broadcast 하라는 뜻\n",
    "\n",
    "### /*+ pq_distribute(inner, none, broadcast) */ \n",
    "- inner 테이블을 Brodcast 하라는 뜻"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cf65a9",
   "metadata": {},
   "source": [
    "## 사. 병렬 처리 시 주의사항\n",
    "- 병렬 쿼리를 과도하게 사용하면 시스템을 마비시킬 수 있다.\n",
    "- 동시 사용자 수가 적은 애플리케이션 환경에서 직렬로 처리할 때보다 성능 개선 효과가 확실할 때\n",
    "- OLTP성 시스템 환경이더라도 작업을 빨리 완료함으로써 직렬로 처리할 때보다 오히려 전체적인 시스템 리소스 사용률을 감소히킬 수 있을 떄"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473e11c2",
   "metadata": {},
   "source": [
    "sds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69691f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27cbf588",
   "metadata": {},
   "source": [
    "# SQL 고급 활용 및 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367cef90",
   "metadata": {},
   "source": [
    "# 제 1장 아키텍처 기반 튜닝 원리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee8842e",
   "metadata": {},
   "source": [
    "# 제1절 데이터베이스 아키텍처"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08a9a55",
   "metadata": {},
   "source": [
    "## 1. 아키텍처 개관"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561ea934",
   "metadata": {},
   "source": [
    "### 가. ORACLE 아키텍처"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2b2b82",
   "metadata": {},
   "source": [
    "- 데이터베이스 : 물리적인 디스크에 저장된 데이터집합 (데이터파일, 리두로그파일, 컨트롤파일)\n",
    "- 인스턴스 : 공유메모리(SGA)와 이를 엑세스하는 프로세스 집합\n",
    "\n",
    "#### 하나의 인스턴스는 하나의 데이터베이스를 액세스(Single)\n",
    "#### 여러개의 인스턴스는 하나의 데이터베이스를 엑세스(RAC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15d2f5e",
   "metadata": {},
   "source": [
    "### 나. SQL Server 아키텍처"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baf45f1",
   "metadata": {},
   "source": [
    "- 하나의 인스턴스당 최고 32,767개의 데이터베이스를 정의해서 사용\n",
    "- 기본적으로 시스템데이터베이스가 만들어지면, 사용자데이터베이스를 추가하여 생성하는 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6997b8a4",
   "metadata": {},
   "source": [
    "- 시스템데이터베이스 : mster, model, msdb, tempdb 등\n",
    "- 사용자데이터베이스 : 데이터파일(mdf), 트랜잭션로그파일(ldf), 보조데이터파일(ndf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8240afb7",
   "metadata": {},
   "source": [
    "## 2. 프로세스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cdd279",
   "metadata": {},
   "source": [
    "- 서버프로세스 : 전면에 나서 사용자가 던지는 각종 명령을 처리\n",
    "- 백그라운드프로세스 : 뒤에서 묵묵히 주어진 역할을 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbd5d1e",
   "metadata": {},
   "source": [
    "### 가. 서버프로세스(Server Process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000c9d4c",
   "metadata": {},
   "source": [
    "- 사용자 프로세스와 통신하면서 사용자의 각종 명령어 처리\n",
    "- ORACLE : 서버프로세스\n",
    "- SQL Server : Worker thread\n",
    "\n",
    "#### 처리절차\n",
    "- 사용자의 요청\n",
    "- SQL 파싱\n",
    "- 커서를 열어서 SQL을 실행하면서 블록 READ\n",
    "- 읽은 데이터를 정렬하여 요청한 결과집합을 만들어 네트워크를 통해 전송"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90ec961",
   "metadata": {},
   "source": [
    "#### 클라이언트가 서버프로세스와 연결하는 방식(예 오라클)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68278031",
   "metadata": {},
   "source": [
    "#### 전용서버 방식(Dedicated Server)\n",
    "- 클라이언트 세션과 서버프로세스가 1:1 로 매핑\n",
    "- 오라클의 가장 일반적인 방식\n",
    "- 클라이언트 요청에 의해 리스너 프로세스는 dedicated server 생성\n",
    "- 새로운 dedicated server 프로세스는 리스너에 의해 커넥션 권한을 상속받음\n",
    "- 데이터베이스와 물리적인 커넥션을 맺음\n",
    "\n",
    "\n",
    "1. (User)     연결요청                       ==> (Listener)\n",
    "2. (Listnenr) 프로세스 생성 및 연결요청 상속 ==> (Server)\n",
    "3. (Server)   RESEND 패킷 전송               ==> (User)\n",
    "4. (User)     연결 후 작업 요청              ==> (Server)\n",
    "5. (Server)   처리 후 결과 전송              ==> (User)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcf5fea",
   "metadata": {},
   "source": [
    "#### 공유서버 방식(Shared Server)\n",
    "- 클라이언트 세션과 서버프로세스가 1:N로 매핑\n",
    "- 클라이언트 요청에 의해 리스너 프로세스는 현재 사용가능한 dispatcher pool 탐색확인\n",
    "- 리스너는 사용가능한 dispatcher 커넥션 정보를 클라이언트에 되돌려줌\n",
    "- 클라이언트는 리스너 접속을 끝내고 바로 dispatcher로 접속\n",
    "\n",
    "1. (User) 연결요청 ==> (Listener)\n",
    "2. (Listener) 가용한 Dispatcher 포트번호 전송 ==> (User)\n",
    "3. (User) 연결 후 작업 요청 ==> (Dispatcher)\n",
    "4. (Dispatcher) 요청등록 ==> (SGA Request Queue)\n",
    "5. (SGA Request Queue) 요청접수 ==> (Server)\n",
    "6. (Server) 결과 등록 ==> (SGA Reponcse Queue)\n",
    "7. (SGA Reponcse Queue) 결과수렴 ==> (Dispatcher)\n",
    "8. (Dispatcher) 결과 전송 ==> (User)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f18350e",
   "metadata": {},
   "source": [
    "### 나. 백그라운드프로세스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d228ce",
   "metadata": {},
   "source": [
    "####              오라클                 ==                       SQL SERVER\n",
    "**SMON(System Monitor) == Databese cleanup / Shrinking Thread**\n",
    "- 장애가 발생한 시스템을 재기동할 때 인스턴스 복구를 수행하고, 임시 세그먼트와 익스텐트를 모니터링한다.\n",
    "\n",
    "**PMON(Process Monitor) == Open data Services(OPS)**\n",
    "- 이상이 생긴 프로세스가 사용하던 리소스를 복구한다.\n",
    "\n",
    "**DBWn(Database Writers) == Lazywriter Thread**\n",
    "- 버퍼 캐시에 있는 더티 버퍼를 데이터 파일에 기록\n",
    "\n",
    "**LGWR(Log Writer) == Log writer Thread**\n",
    "- 로그 버퍼 엔트리를 redo 로그 파일에 기록한다.\n",
    "\n",
    "**ARCn(Archiver) == N/A**\n",
    "- 꽉찬 리두로그가 덮어 쓰여지기 전에 archive로그 디렉토리로 백업한다.\n",
    "\n",
    "**CKPT(Checkpoint) == Database Checkpoint Thread**\n",
    "- checkpoint 프로세스는 이전의 checkpoint가 일어났던 마지막 시점 이후의 데이터베이스 변경 사항을 데이터파일에 기록하도록  \n",
    "트리거링하고, 기록이 완료되면 현재 어디까지 기록했는지를 컨트롤 파일과 데이터 파일 헤더에 기록한다.\n",
    "- 좀더 자세히 설명하면 write Ahead Logging 방식을 사용하는 DBMS는 리두로그에 기록해 둔 버퍼 브록에 대한 변경사항 중\n",
    "현재 어디까지를 데이터 파일에 기록했는지 체크 포인트정보를 관리해야 한다.\n",
    "- 이는 버퍼캐시와 데이터 파일이 동기화된 시점을 가리키며, 장애가 발생하면 마지막 체크포인트 이후 로그 데이터만 디스크에 \n",
    "기록함으로써 인스턴스를 복구할 수 있도록 하는 용도로 사용된다.\n",
    "- 이 정보를 갱신하는 주기가 길수록 장애 발생시 인스턴스 복구 시간도 길어진다.\n",
    "\n",
    "**RECO(Recoverer) == Distributed Transaction Coordinator(DTC)**\n",
    "- 분산 트랜잭션 과정에 발생한 문제를 해결한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0698c6cd",
   "metadata": {},
   "source": [
    "## 3. 파일구조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f43312",
   "metadata": {},
   "source": [
    "### 가. 데이터파일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e24499",
   "metadata": {},
   "source": [
    "1) **블록(=페이지)**\n",
    "- 대부분의 DBMS에서는 I/O 블록단위로 이루어짐\n",
    "- 데이터를 읽고 쓸때의 논리적인 단위\n",
    "- SQL 성능을 좌우하는 가장 중요한 성능지표\n",
    "- 옵티마이저의 파단에 가장 큰 영향을 미치는 요소"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2765302",
   "metadata": {},
   "source": [
    "2) **익스텐트(Extent)**\n",
    "- 테이블스페이스로부터 공간을 할당하는 단위"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1596735",
   "metadata": {},
   "source": [
    "3) **세그먼트(Segment)**\n",
    "- 테이블, 인덱스, Undo 처럼 저장공간을 필요로하는 데이터베이스 오브젝트 (한개 이상의 익스텐트 사용)\n",
    "- 파티션은 오브젝트와 세그먼트가 1:M (파티션을 만들면 내부적으로 여러개의 세그먼트가 만들어짐)\n",
    "- 한 세그먼트에 할당된 엑스텐트가 여러 데이터파일에 흩어져 저장됨 (디스크 경합감소. I/O 분산효과)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a597f64",
   "metadata": {},
   "source": [
    "4) **테이블스페이스(Tablespace)**\n",
    "- 세그먼트를 담는 콘테이너로서 여러개의 데이터파일로 구성됨\n",
    "- 사용자는 데이터파일을 직접 선택할 수 없으므로 실제 파일을 선택하고 익스텐트를 할당하는것은 DBMS의 몫"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f229911",
   "metadata": {},
   "source": [
    "### 나. 임시파일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda789ea",
   "metadata": {},
   "source": [
    "- 대량의 정렬이나 해시 작업을 수행하다가 메모리 공간이 부족해지면 중간 결과집합을 저장하는 용도\n",
    "- 오라클에서는 임시 테이블스페이스를 여러개 생성해두고, 사용자마다 별도의 임시 테이블스페이스를 지정해 줄 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76abd996",
   "metadata": {},
   "source": [
    "### 다. 로그파일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92400cc5",
   "metadata": {},
   "source": [
    "- DB 버퍼 캐시에 가해지는 모든 변경사항을 기록하는 파일\n",
    "- 로그 기록은 Append 방식으로 이루어지기 때문에 상대적으로 매우 빠름\n",
    "- 빠른 커밋 지원"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994a96e4",
   "metadata": {},
   "source": [
    "### 로그파일\n",
    "#### 리두로그(오라클)\n",
    "- 트랜잭션의 데이터 유실 방지\n",
    "- 마지막 체크포인트이후 사고 발생 직전까지 수행되었던 트랜잭션을 Redo 로그를 이용해서 재현함 (캐시복구)\n",
    "- 최소 두개 이상의 파일로 구성하며 round-robin 방식 이용하여 사용\n",
    "\n",
    "#### 트랜잭션로그(SQL Server)\n",
    "- 데이터파일(데이터베이스)마다 트랜잭션 로그 파일이 하나씩 생성됨(ldf)\n",
    "- 가상로그파일이라고 불리는 더 작은 세그먼트 단위로 나뉨\n",
    "- 가상로그파일 개수가 너무 많아지지 않도록 옵션을 지정(로그파일을 넉넉한 크기로 만들어 자동 증가가 발생하지   \n",
    "않도록 하거나, 증가단위를 크게 지정)\n",
    "\n",
    "\n",
    "### Archved(=Offline) Redo 로그\n",
    "#### Archived Redo 로그\n",
    "- 오라클에서 온라인 리두로그가 재사용 되기 전에 다른 위치로 백업해둔 파일\n",
    "- 디스크가 꺠지는 등의 물리적인 저장매체 장애에 대해서 복구하기 위해 사용\n",
    "- SQL Server는 Archived Redo 로그에 대응되는 개념 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b4e59b",
   "metadata": {},
   "source": [
    "## 4. 메모리구조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b400fd1",
   "metadata": {},
   "source": [
    "### 시스템 공유 메모리영역\n",
    "### System Global Area(SGA) == Memory Pool\n",
    "- 여러 프로세스가 동시에 액세스할 수 있는 메모리 영역\n",
    "- 모든 DBMS는 공통적으로 사용하는 캐시 영역이 있음(DB 버퍼캐시, 공유풀, 로그 버퍼)\n",
    "- 그 외에 Large Poolm, Java Pool, 시스템 구조와 제어 구조를 캐싱하는 영역을 포함하고 있음\n",
    "- 여러 프로세스가 공유되기 때문에 내부적으로 Latch, 버퍼Lock, 라이브러리 캐시 Lock/Pin같은 액세스 직렬화 매커니즘 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfe6dec",
   "metadata": {},
   "source": [
    "### 프로세스 전용 메모리영역\n",
    "- 오라클은 프로세스 기반의 아키텍처로 서버 프로세스가 자신만의 전용 메모리 영역을 가짐 (Process Global Area(PGA))\n",
    "- 데이터를 정렬하고 세션과 커서 정보를 저장\n",
    "- 쓰레드기반의 아키텍처를 사용하는 SQL Server는 프로세스 전용 메모리 영역을 갖지 않는다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691d76f7",
   "metadata": {},
   "source": [
    "### 가. DB 버퍼캐시\n",
    "- 데이터파일로부터 읽어들인 데이터 블록을 담는 캐시영역\n",
    "- 사용자 프로세스는 서버 프로세스를 통해 DB 버퍼 캐시의 버퍼 블록을 동시에 액세스 (내부적으로 Buffer Lock을 통한 직렬화)\n",
    "- Direct Path Read 매커니즘이 작동하는 경우를 제외하면, 모든 블록 읽기는 버퍼 캐시를 통해 이루어짐\n",
    "- 디스크에서 읽을때도 버퍼캐시에 적재한 후 읽음\n",
    "- 변경된 블록(더티버퍼)은 주기적으로 DBWR 프로세스에 의해 데이터파일에 기록\n",
    "- 디스크 I/O는 물리적으로 액세스암이 움직이면서 헤드를 통해 이루어지는 반면, 메모리 I/O는 전기적신호에 불과하기 때문에   \n",
    "  디스크 I/O와 비교할수 없을 정도로 빠름."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9d8655",
   "metadata": {},
   "source": [
    "#### 1) 버퍼블록상태\n",
    "**Free Buffer**\n",
    "- 인스턴스 기둥호 아직 데이터가 읽혀지지 않아 비어 있는 상태이거나, 데이터파일과 서로 동기화 되어 언제든지 덮어써도 되는 상태\n",
    "\n",
    "**Dirty Buffer**\n",
    "- 버퍼가 캐시된 이후 변경이 발생하지만, 아직 디스크에 기록되지 않아 데이터파일 블록과 동기화가 필요한 버퍼 블록.\n",
    "- 이 버퍼 블록이 재사용 되려면 디스크에 먼저 기록되어야 하고 디스크에 기록된 순간 Free 버퍼로 변경\n",
    "\n",
    "**Pinned Buffer**\n",
    "- 읽기 또는 쓰기 작업이 현재 진행중인 버퍼 블록"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4843bf1",
   "metadata": {},
   "source": [
    "#### 2) LRU 알고리즘\n",
    "- 버퍼 캐시는 유한한 자원이므로 모든 데이터를 캐싱해 둘 수 없기 때문에 사용 빈도가 높은 데이터 블록 위주로  \n",
    "  버퍼 캐시가 구성 되도록 LRU 알고리즘을 사용\n",
    "- 모든 버퍼 블록헤더를 LRU 체인에 연결해 사용 빈도 순으로 위치를 옮기다가(Touch count가 높을수록 MRU)  \n",
    "  Free 버퍼가 필요해지면, 엑세스 빈도가 낮은(LRU) 쪽 데이터 블록부터 밀어내는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322b3fa8",
   "metadata": {},
   "source": [
    "### 나. 공유풀(shared pool)\n",
    "- 딕셔너리캐시와 라이브러리 캐시로 구성되며 버퍼 캐시처럼 LRU 알고리즘을 사용\n",
    "\n",
    "#### 1) 딕셔너리 캐시\n",
    "- 테이블, 인덱스같은 오브젝트는 물론 테이블스페이스, 데이터파일, 세그먼트, 익스텐트, 사용자, 제약사항과 같은 메타정보 저장\n",
    "\n",
    "#### 2) 라이브러리캐시\n",
    "- SQL 실행에 관련된 모든 객체에 대한 정보 관리\n",
    "- 서버 프로세스가 SQL을 작업할때 사용되는 작업공간\n",
    "- SQL에 대한 분석정보 및 실행계획 저장\n",
    "- 공유 SQL을 저장하기 위해 사용\n",
    "\n",
    "- 라이브러리 캐시는 캐싱된 SQL과 그 실행계획의 재사용성을 높이는 것이 수행 성능을 높이고 DBMS 부하를 최소화 하는 핵심원리임\n",
    "- 바인드변수 사용 및 기준에 맞는 SQL 작성으로 재사용성을 높여 줘야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f89ca0",
   "metadata": {},
   "source": [
    "### 다. 로그버퍼\n",
    "- Only Recovery를 위해 사용됨.\n",
    "- DB버퍼에 가해지는 모든 변경사항을 로그버퍼에 먼저 기록\n",
    "- **Physiolosical logging**\n",
    "    - physical logging과 logical logging의 장점을 결합한것으로 변경된 데이터에 대한 before/after 이미지를 저장하고  \n",
    "      opcode(명세서)를 기록하여 완벽한 복구를 보장\n",
    "- **page fix rule**\n",
    "    - 변경이 시작되는 시점부터 완료되는 시점까지 해당 블록을 보호해주는 아키텍처로 os에서 세마포어를 할당받아서  \n",
    "      세마포어가 해당 블록을 보호\n",
    "- **log a head**\n",
    "    - 데이터 변경작업시에 DBWR에 의한 블록 변경보다 로그를 먼저 기록하는 기법\n",
    "- **log force at commit**\n",
    "    - 커밋시 리두로그를 먼저 기록하는 기법, 기록하는 속도가 빠른 리두를 먼저 기록하게 하여 중간에 발생하는   \n",
    "      장애로부터 완벽한 복구를 보장하는 기법\n",
    "- **logical odering of redo**\n",
    "    - 로그를 기록할때 정해진 위치가 아닌 순서와 무관하게 기록하되, scn과 RBA를 이용하여 복구에 대한 순서를 결정하여 빠른 복구 보장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cb67f1",
   "metadata": {},
   "source": [
    "### 라. PGA(Process Global Area)\n",
    "- 오라클의 서버 프로세스는 자신만의 PGA 메모리 영역을 할당받아 이를 프로세스에 종속적인 고유 데이터를 저장하는 용도로 사용\n",
    "- PGA는 다른 프로세스와 공유되지 않은 독립적인 메모리 공간으로 똑같은 개수의 블록을 읽더라도 SGA 버퍼 캐시에서 읽는것보다 훨씬 빠름\n",
    "\n",
    "#### 1) UGA(User Global Area)\n",
    "- 각 세션을 위한 독립적인 공간\n",
    "- Dedicated Server : PGA에 UGA영역 할당\n",
    "- Shared Server: SGA의 Large Pool 또는 Shared Pool에 UGA 영역 할당\n",
    "\n",
    "#### 2) CGA(Call Global Area)\n",
    "- 오라클은 하나의 데이터베이스 Call을 넘어서 다음 Call까지 계속 참조되는 정보를 UGA에 담고, call이   \n",
    "  진행되는 동안 필요한 데이터는 CGA에 담는다\n",
    "- Parse Call, Execute Call, Fetch Call 마다 매번 할당 받음\n",
    "- Call이 진행되는동안 Recursive call이 발생하면 그 안에서도 Parse, Execute, Fetch 단계별로 CGA 할당\n",
    "- 할당된 공간은 Call이 끝나자마자 해제되어 PGA에 반환\n",
    "\n",
    "#### 3) Sort Area\n",
    "- 데이터 정렬을 위해 사용되며, 부족할때 마다 chunk 단위로 조금씩 할당됨\n",
    "- 세션마다 sort_area_size 파라미터로 설정가능\n",
    "- 9i 이상부터는 workarea_size_policy 파라미터를 auto로 설정하면 내부적으로 알아서 sort area를 할당해줌\n",
    "\n",
    "**DML : CGA 영역에 할당**  \n",
    "**SELECT : 수행중간단계에 필요한 sort area는 CGA에 할당, 최종 결과집합을 출력하기 직전 단계에서 필요한 sort area는 UGA에 할당**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0bfc31",
   "metadata": {},
   "source": [
    "## 5. 대기 이벤트\n",
    "- DBMS 내부에서 활동하는 수많은 프로세스간에서는 상호작용이 필요하며, 그 과정에서 다른 프로세스가 일을 마칠때까지 기다려야하는 상황이 발생\n",
    "- 그때마다 해당 프로세스는 자신이 일을 계속 진행할 수 있는 조건이 충족될때까지 수면(Sleep)상태로 대기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e86a27",
   "metadata": {},
   "source": [
    "- **Reponse Time** = \n",
    "    - Service Time + Wait Time     \n",
    "    - CPU Time + Queue Time \n",
    "    \n",
    "- 서비스시간(Service Time = CPU Time): 프로세스가 정상적으로 동작하며 일을 수행한 시간\n",
    "- 대기시간(Wait Time = Queue Time): 프로세스가 잠시 수행을 멈추고 대기한 시간\n",
    "- Response Time Analysis 방법론은 Cpu Time과 Wait Time을 각각 Break down 하면서 서버의 일량과 대기시간을 분석\n",
    "- Wait TIme은 각각 발생한 대기 이벤트를 분석해서 가장 시간을 많이 소비한 이벤트 중심으로 해결방안 모색"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad7ddb0",
   "metadata": {},
   "source": [
    "### 가. 라이브러리캐시 부하\n",
    "- 라이브러리 캐시에서 SQL 커서를 찾고 최적화 하는 과정에서 경합이 발생하여 나타난 대기이벤트\n",
    "    - latch : shared pool\n",
    "    - latch : library cache\n",
    "- 라이브러리 캐시와 관련해서 자주발생하는 대기 이벤트로, 수행중인 SQL이 참조하는 오브젝트에 다른 사용자가 DDL문장을 수행할 때 \n",
    "    - library cache lock\n",
    "    - library cache pin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f4d33b",
   "metadata": {},
   "source": [
    "### 나. 데이터베이스 call과 네트워크 부하\n",
    "- 애플리케이션과 네트워크 구간에서 소모된 시간에 의해 나타난 이벤트\n",
    "    - SQL*Net message from client : client로부터 다음 명령이 올떄까지 idle 상태로 기다릴때 발생   \n",
    "      (데이터베이스 경합과 관계없음)\n",
    "    - SQL*Net message to client : 메시지를 보냈는데 메시지를 받았다는 신호가 늦게 도착하는경우 이거나,\n",
    "      클라이언트가 너무 바쁠경우\n",
    "    - SQL*Net more data to client: 메시지를 보냈는데 메시지를 받았다는 신호가 늦게 도착하는 경우 이거나,\n",
    "      클라이언트가 너무 바쁠경우\n",
    "    - SQL*Net more data from client : 클라이언트로부터 더 받을 데이터가 있는데 지연이 발생한 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b2c48c",
   "metadata": {},
   "source": [
    "### 다. 디스크 부하\n",
    "- 디스크 I/O 발생할 때 나타나는 대기 이벤트\n",
    "    - db file sequential read : Single Block I/O call에 하나의 데이터 블록만 읽음.    \n",
    "      인덱스 블록을 읽을때 발생\n",
    "    - db file scattered read : Multi Block I/O. Table Full Scan 또는 Index Fast Full Scan시 나타남\n",
    "    - direct path read\n",
    "    - direct path write\n",
    "    - direct path write temp\n",
    "    - direct path read temp\n",
    "    - db file parallel read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623350b6",
   "metadata": {},
   "source": [
    "### 라. 버퍼캐시 경합\n",
    "- 버퍼캐시에서 블록을 읽는 과정에서 경합이 발생하여 나타나는 대기 이벤트\n",
    "    - latch : cache buffers chains\n",
    "    - latch : cache buffers lru chain\n",
    "    - buffers busy waits\n",
    "    - free buffer waits\n",
    "- 해소 방법은 I/O 부하 해소 방법과 비슷함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965e1d65",
   "metadata": {},
   "source": [
    "### 마. LOCK관련 대기이벤트 \n",
    "- Lock과 관련된 대기이벤트\n",
    "    - enq : TM - contention\n",
    "    - enq : TX - row lock contention\n",
    "    - enq : TX - index contention\n",
    "    - enq : TX - allocate ITL entry\n",
    "    - enq : TX contention\n",
    "    - latch free : 특정 자원에 대한 래치를 여러차례(2000번 가량) 요구했지만 해당 자원이 계속 사용중이어서  \n",
    "      잠시 대기 상태로 빠질때마다 발생\n",
    "- Lock은 사용자 데이터를 보호하는 반면, Latch는 SGA에 공유되어 있는 갖가지 자료구조를 보호할 목적으로 사용하는 가변운 LOCK\n",
    "- Latch도 일종의 Lock이지만 큐잉(Queueing) 매커니즘을 사용하지 않음\n",
    "- 특정자원에 액세스하려는 프로세스는 래치 획득에 성공할때까지 반복해서 시도하나, 우선권은 부여받지 못함  \n",
    "  (처음시도한 래치가 맨 나중에 래치획득에 성공할수도 있음)\n",
    "- 그외 대기이벤트\n",
    "    - log file sync\n",
    "    - checkpoint completed\n",
    "    - log file switch completion\n",
    "    - log buffer space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7c33d8",
   "metadata": {},
   "source": [
    "# 제2절 SQL 파싱 부하"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806b61f9",
   "metadata": {},
   "source": [
    "## 1. SQL 처리 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c049d0c",
   "metadata": {},
   "source": [
    "- 사용자는 구조화된 질의언어(SQL)를 통해 사용자가 원하는 결과집합을 정의\n",
    "- DBMS는 사용자의 SQL을 SQL옵티마이저를 통해 실행계획을 작성해줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6e8d51",
   "metadata": {},
   "source": [
    "### 가. SQL 파싱(Parsing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da4fdc4",
   "metadata": {},
   "source": [
    "- SQL을 실행하면 제일먼저 SQL 파서(parser)가 SQL 문장에 문법적 오류가 없는지 검사(Syntax 검사)\n",
    "- 문법적 오류가 없다면 의미상 오류가 없는지 검사(Semantic 검사, 오브젝트 존재유무등)\n",
    "- 검사를 다 마치면, 사용자가 발생한 SQL과 그 실행계획이 라이브러리캐시(프로시저캐시)에 캐싱되어 있는지 확인\n",
    "- 캐싱되어 있다면 소프트파싱, 캐싱되어있지 않다면 하드파싱\n",
    "\n",
    "**소프트파싱(Soft Parsing)** \n",
    "    - SQL과 실행계획을 캐시에서 찾아 곧바로 실행단계로 넘어가는 경우\n",
    "\n",
    "**하드파싱(Hard Parsing)**\n",
    "    - SQL과 실행계획을 캐시에서 찾지 못해 최적화 과정을 거치고 나서 실행단계로 넘어가는 경우\n",
    "    \n",
    "- 라이브러리캐시는 해시 구조로 관리됨\n",
    "    - SQL마다 해시값에 따라 여러 해시 버킷으로 나뉘여 저장되고, SQL을 찾을때는 SQL 문장을 해시 함수에 적용하여  \n",
    "      반환되는 해시값을 이용하여 해시 버킷을 탐색함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5f6959",
   "metadata": {},
   "source": [
    "### 나. 최적화(Optimization)\n",
    "- SQL 최적화를 담당하는 옵티마이저는 사용자가 요청한 SQL을 가장 빠르고 효율적으로 수행할 최적의(처리비용)  \n",
    "  처리경로를 선택해 주는 DBMS의 핵심\n",
    "  \n",
    "**최적화 과정**  \n",
    "- 예를들어 5개의 테이블을 조인한다면, 순서만 고려해도 5!(=120)개의 실행계획 평가\n",
    "- 120가지의 실행계획에 포함된 각 단계별 다양한 조인방식 고려\n",
    "- 테이블을 full scan 할지 인덱스를 사용할지, 어떤 인덱스를 어떤방식으로 스캔할지 고려\n",
    "    - 이와 갘이 무거운 작업이므로 이러한 힘든 과정을 거쳐 최적화된 SQL 실행계획을 한번만 쓰고 버린다면  \n",
    "      엄청난 비효율이 발생한다.\n",
    "    - 파싱과정을 거친 SQL과 실행계획이 여러 사용자가 공유해서 재사용할 수 있도록 공유메모리에 캐싱은 이유가 여기에 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968022ea",
   "metadata": {},
   "source": [
    "## 2. 캐싱된 SQL 공유"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b47821",
   "metadata": {},
   "source": [
    "### 가. 실행계획 공유 조건\n",
    "- SQL 수행절차\n",
    "    - 문법적 오류와 의미상 오류가 없는지 검사\n",
    "    - 해시 함수로붜 반환받은 해시 값으로 라이브러리 캐시 내 해시버킷 탐색\n",
    "    - 찾아간 해시버킷에 체인으로 연결된 엔트리를 차례로 스캔하면서 같은 SQL 문장 탐색\n",
    "    - SQL 문장을 찾으면 함께 저장된 실행계획을 가지고 바로 실행\n",
    "    - 찾아간 해시 버킷에서 SQL 문장을 찾지 못하면 최적화를 수행\n",
    "    - 최적화를 거친 SQL과 실행계획을 방금 탐색한 해시 버킷 체인에 연결\n",
    "    - 방금 최적화한 실행계획을 가지고 실행\n",
    "\n",
    "**중요**\n",
    "- 하드파싱을 반복하지 않고 캐싱된 버전을 찾아 재사용하려면 SQL을 먼저 찾아가야 하며, 캐시에서 SQL을 찾기위해 사용되는 키값은 SQL 문장 그자체\n",
    "  => 이 때문에 SQL 문장안의 작은 공백 하나로도 DBMS는 서로 다른 SQL 문장으로 인식할수 있으므로 주의 해야함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d853174",
   "metadata": {},
   "source": [
    "### 나. 실행계획이 공유하지 못하는 경우\n",
    "- 1. 공백 또는 줄바꿈\n",
    "- 2. 대문자 구분\n",
    "- 3. 주석(Comment)\n",
    "- 4. 테이블 Owner 명시\n",
    "- 5. 옵티마이저 힌트사용\n",
    "- 6. 조건절 비교값\n",
    "\n",
    "- 이러한 비효율을 줄이고 공유 가능한 형태로 SQL을 작성하려면 개발 초기에 SQL 작성표준을 정해서 이를 준수하도록 해야함\n",
    "- 6번처럼 조건절값을 문자열로 붙여가며 매번 다른 SQL로 실행되는 리터널 SQL의 경우, 한가한 시간이라면 문제에 대해서  \n",
    "느끼지 못하겠지만, 사용자가 동시에 몰리는 시간대에는 장애상황으로 발생할 수도 있으므로 바인드변수의 사용을 고려해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b8e4a",
   "metadata": {},
   "source": [
    "## 3. 바인드 변수 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf08f8f",
   "metadata": {},
   "source": [
    "### 가. 바인드 변수의 중요성 \n",
    "\n",
    "**바인드 변수를 사용했을떄의 효과**\n",
    "- SQL과 실행계획을 반복적으로 재사용함으로써 파싱 소요시간과 메모리 사용량을 줄여줌\n",
    "- 궁극적으로 시스템전반의 CPU와 메모리 사용률을 낮춰 데이터베이스 성능과 확장성을 높임\n",
    "\n",
    "**바인드 변수를 사용하지 않아도 되는 예외상황**\n",
    "- 배치프로그램이나 DW, OLAP등 정보계 시스템에서 사용되는 Long Runnung 쿼리\n",
    "    - 파싱 소요시간이 총 소요시간에서 차지하는 비중이 낮음\n",
    "    - 수행빈도가 낮아 하드파싱에 의한 라이브러리 캐시 부하 유발 가능성이 낮음\n",
    "    - 그러므로 상수조건절을 사용하여 옵티마이저가 컬럼히스토그램 정보를 활용할 수 있도록 유도하는것이 유리함\n",
    "- 조건절 컬럼의 값 종류(Distinct value)가 소수 일때\n",
    "    - 분포도가 좋지 않은 값은 옵티마이저가 컬럼히스토그램 정보를 활용할 수 있도록 유도.\n",
    "- 이러한 경우가 아니라면 OLTP 환경에서는 바인드 변수 사용을 권고함\n",
    "- 리터널 SQL을 자동으로 변수화 시켜주는 기능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa74a421",
   "metadata": {},
   "source": [
    "### 나. 바인드변수 사용시 주의사항\n",
    "- 칼럼의 분포가 균일할때는 바인드 변수 처리가 나쁘지 않음\n",
    "- 칼럼의 분포가 균일하지 않을때에는 실행 시점에 바인딩되는 값에 따라 쿼리 성능이 다르게 나타날 수 있으므로  \n",
    "  이럴때는 상수값을 사용하는것이 나을 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8b059c",
   "metadata": {},
   "source": [
    "### 다. 바인드 변수 부작용을 극복하기 위한 노력\n",
    "- 바인드변수 Peeking 기능 도입: 첫번째 바인드 변수값을 살짝 훔쳐보고 그 값에 대한 분포를 이용하여 실행계획 결정하는 기능\n",
    "- 이또한 처음 훔쳐본값에 따라 비활성화 시켜 사용하고 있음\n",
    "- 오라클은 11g부터는 적응적 커서공유(Adaptive Cusor Sharing)를 도입하여 칼럼 분포에 따라 다른 실행계획이  \n",
    "  사용되도록 처리하였지만 이또한 완전한 기능이 아니므로 주의해서 사용해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f61c1eb",
   "metadata": {},
   "source": [
    "## 4. Static SQL과 Dynamic SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276a7613",
   "metadata": {},
   "source": [
    "### 가. Static SQL\n",
    "- String형 변수에 담지 않고 코드 사이에 직절 기술한 SQL문 (Embedded SQL)\n",
    "- 개발언어 : PowerBuilder, PL/SQL, Pro*C, SQLJ\n",
    "- SQL문을 String 변수에 담지 않고 마치 예약된 키워드처럼 C/C++코드 사이에 섞어 기술\n",
    "- 구문분석, 유효 오브젝트 여부, 오브젝트 엑세스 권한등의 체크 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d381db7",
   "metadata": {},
   "source": [
    "### 나. Dynamic SQL\n",
    "- String 형 변수에 담아서 기술하는 sQL문\n",
    "- 조건에 따라 SQL이 동적으로 바뀔수 있으므로 syntax, semantics 체크 불가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951890dd",
   "metadata": {},
   "source": [
    "### 다. 바인드 변수의 중요성 재강조\n",
    "- Static을 사용하든 Dynamic SQL을 사용하든 옵티마이저는 SQL 문장 자체만을 인식할 뿐이므로 성능에 영향을 주지는 않는다.\n",
    "- 라이브러리 캐시 효율은 Static이냐 Dynamic의 차이가 아니라 바인드 변수의 사용여부에 초점을 맞춰야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52f2c75",
   "metadata": {},
   "source": [
    "## 5. 애플레키에션 커서 캐싱\n",
    "- 같은 SQL을 여러번 반복해서 수행해야할 때, 첫번째는 하드파싱이 일어나겠지만 이후부터는 라이브러리 캐시에 공유되 버전을 찾아 가볍게 실행한다.\n",
    "- 하지만 그렇다더라도 SQL문장의 문법적, 의미적 오류를 확인하고 해시함수로부터 반환된 해시값을 이용해서 캐시에서 실행계획을 찾고, 수행이 필요한 메모리를 할당받는 등의 작업이 매번 반복되면 비효율이 발생할 것이다.\n",
    "- 이러한 과정을 생략하고 빠르게 SQL을 수행하는 방법이 바로 \"**애플리케이션 커서 캐싱**\" 이다.\n",
    "- 개발언어마다 구현방식이 다르므로 이 기능을 활용하려면 API를 살펴봐야함.\n",
    "- 일반적으로 SQL을 반복 수행할 때에는 Parse Call 횟수가 Execute Call 횟수와 같지만 \n",
    "- 위의 결과는 Parse Call 한번만 발생했고, 이후 4,999번 수행할 때에도 Parse Call이 전혀 발생하지 않았음\n",
    "- JAVA에서 위의 기능을 구현하기 위한 방법 : 묵시적캐싱 옵션 사용(Implicit Caching)\n",
    "- Dynamic SQL을 사용하거나 Cursor Variable(=Ref Cursor)를 사용할 때는 커서를 자동으로 캐싱하는 효과가 사라짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c127510",
   "metadata": {},
   "source": [
    "# 제 3절. 데이터베이스 Call과 네트워크 부하"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427ca694",
   "metadata": {},
   "source": [
    "# 1. 데이터베이스 Call 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48015dc",
   "metadata": {},
   "source": [
    "## 가. SQL 커서에 대한 작업 요청에 따른 구분\n",
    "- Parse Call : SQL 파싱을 요청하는 Call\n",
    "- Execute Call : SQL 실행을 요청하는 Call\n",
    "- Fetch Call : SELECT 문의 결과 데이터 전송을 요청하는 Call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecaa0a6",
   "metadata": {},
   "source": [
    "## 나. Call 발생 위치에 따른 구분\n",
    "### 1) User Call\n",
    "- DBMS로부터 요청되는 Call\n",
    "- User Call이 많으면 성능이 좋을수 없으므로, DBMS 확장성을 높이려면 User Call을 최소화 하려는 노력이 중요함\n",
    "- User Call을 줄이기 위한 기술요소\n",
    "    - Loop 쿼리를 해소하고 집합적 사고를 통해 One SQL로 구현\n",
    "    - Array Processing : Array 단위 Fetch, Bulk Insert/Update/Delete\n",
    "    - 부분범위처리 원리 활용\n",
    "    - 효과적인 화면 페이지 처리\n",
    "    - 사용자 정의 함수/프로시저/트리거의 적절한 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495e97f5",
   "metadata": {},
   "source": [
    "### 2) Recusive Call\n",
    "- DBMS 내부에서 발생하는 Call\n",
    "- SQL 파싱과 최적화 과정에서 발생(데이터 딕셔너리조회, 사용자 정의함수/프로시저 내에서의 SQL 수행)\n",
    "- Recursive Call 최소화 방안\n",
    "    - 바인드 변수 사용하여 하드파싱 발생 횟수 감소\n",
    "    - 사용자 정의 함수/프로시저의 적절한 사용 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0255aaa7",
   "metadata": {},
   "source": [
    "# 2. 데이터베이스 Call과 성능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f9e2fb",
   "metadata": {},
   "source": [
    "## 가. One SQL 구현의 중요성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7888db0c",
   "metadata": {},
   "source": [
    "- 예를 들어 처리해야할 납부실적이 10만건이라고 하면, (array 단위 fetch 기능을 이용하지 않을때 Insert를 위한 Parse Call이 50만번, Execute call이 50만번으로 최대 110만 번의 데이터베이스 Call이 발생함\n",
    "- 이러한 프로그램을 아래와 같이 One SQL로 통합하면 1~2초내로 수행되는것을 확인할수 있는데, 이 원리는 110번 발생할수 있는 데이터베이스 Call을 단 2회(Parse Call 1회, Execute Call 1회)로 줄인데 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b5c44",
   "metadata": {},
   "source": [
    "## 나. 데이터베이스 Call과 시스템 확장성\n",
    "- 데이터베이스 Call은 개별 프로그램 수행속도 뿐 아니라 궁극적으로 시스템 전체의 확장성에도 영향을 미친다.\n",
    "- 예시) 인터넷 쇼핑몰에서 조회한 상품 5개를 선택한 후 위시리스트에 등록하는 프로그램일 때\n",
    "- 5번의 메소드를 호출하므로 Parse Call과 Execute Call 각각 5번씩 발생\n",
    "- 확장성을 고려하여 작성하였으므로 1번의 메소드를 호출하며 Parse Call과 Execute Call도 각각 1번씩만 호출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed20483",
   "metadata": {},
   "source": [
    "# 3. Array Processing 활용\n",
    "- Array Processing 기능을 활용하면 한번의 SQL(INSERT/UPDATE/DELETE) 수행으로 다량의 레코드를 동시 처리\n",
    "- 네트워크 Call 감소\n",
    "- SQL 수행시간 감소\n",
    "- CPU 사용량 감소"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49060820",
   "metadata": {},
   "source": [
    "- Insert 할 데이터를 계속 array에 담기만 하다가\n",
    "- 1000건이 쌓일때마다 한번씩 executeBatch를 수행\n",
    "- Select 결과집합을 Fetch할때도 1000건씩 하도록 조정하였다.  \n",
    "  **Call 횟수를 줄이는것이 성능개선에 도움이 되는것을 알 수 있다.**\n",
    "- 대용량 데이터의 처리에는 Array Processing이 필수\n",
    "- 효과를 극대화 하기위해 연속된 일련의 처리과정을 모두 Array 단위로 진행해야함(select, insert 모두)\n",
    "- 예시) PL/SQL을 이용한 데이터 Bulk로 1000건씩 Fetch해서 Bulk Insert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fe4bb8",
   "metadata": {},
   "source": [
    "# 4. Fetch Call 최소화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da08fc3",
   "metadata": {},
   "source": [
    "## 가. 부분범위처리 원리\n",
    "- 쿼리 결과 집합을 전송할때, 전체 데이터를 연속적으로 전송하지 않고 사용자로부터 Fetch Call이 있을때마다 일정량씩 나누어서 전송하는 것\n",
    "- 데이터를 클라이언트에게 전송할때 일정량씩 나누어서 전송\n",
    "- 오라클 : 내부적으로는 SDU, TDU 단위로 나누어서 전송  \n",
    "           array 사이즈를 작게 설정하면 하나의 네트워크 패킷에 담아 전송하겠지만, 크게 설정하면 여러개의 패킷으로 나누어 전송"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd78a94",
   "metadata": {},
   "source": [
    "## 나. ArraySize 조정에 의한 Fetch Call 감소 및 블록 I/O 감소 효과\n",
    "- 대량의 데이터파일을 전송한다면 arraysize 크게하여 fetch call 횟수를 줄여주는것이 유리\n",
    "- 반대로 적은량의 데이터만 fetch 하다가 멈추는 프로그램이라면 arraysize를 작게 설정하는것이 유리\n",
    "- arraysize를 증가시키면 네트워크 부하감소 및 서브프로세스가 읽어야할 블록 갯수 감소 효과\n",
    "- ArraySize를 키운다고 해서 Fetcah count와 블록 I/O가 같은 비율로 줄지 않음\n",
    "- ArraySize를 무작정 크게 설정한다고 좋은것이 아니며, 일정크기 이상이면 리소스만 낭비하는 결과를 초래할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef53efa",
   "metadata": {},
   "source": [
    "### 1) Oracle PL/SQL(커서를 열고 레코드를 Fetch)\n",
    "- 10g : 자동으로 100개씩 array Fetch가 일어남.\n",
    "\n",
    "### 2) JAVA(FetchSize를 100으로 설정했을때 데이터를 Fetch 해오는 매커니즘)\n",
    "- 최초 rs.next() 호출 시 한꺼번에 100건을 가져와서 클라이언트 Array 버퍼에 캐싱한다.\n",
    "- 이후 rs.next() 호출할 때는 데이터베이스 Call을 발생시키지 않고 Array 버퍼에서 읽는다.\n",
    "- 버퍼에 캐싱 돼 있던 데이터를 모두 소진한 후 101번째 rs.next() 호출 시 다시 100건을 가져온다.\n",
    "- 모든 결과집합을 다 읽을 때까지 2~3번 과정을 반복한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e68978c",
   "metadata": {},
   "source": [
    "# 5. 페이지 처리 활용\n",
    "- 페이지 처리를 하지 않을때 발생하는 부하요인\n",
    "    - 다량 발생하는 Fetch Call의 부하\n",
    "    - 대량의 결과 집합을 클라이언트에 전송하면서 발생하는 네트워크 부하\n",
    "    - 인덱스와 부분범위처리 원리를 이용해 각 페이지에 필요한 최소량만 I/O\n",
    "- 데이터를 소량씩 나누어 전송하므로 AP웹 서버 리소스 사용량 최소화\n",
    "- 결론적으로, 조회할 데이터가 일정량 이상이고 수행빈도가 높다면 필수적으로 페이지 처리 구현해야함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd08d97",
   "metadata": {},
   "source": [
    "# 6. 분산 쿼리\n",
    "- 분산 DB간 테이블 조인\n",
    "- 원격의 sal테이블을 전송받아 order 테이블과 NL 조인\n",
    "- 50만건이나 되는 데이터를 네트워크를 통해 전송받고 있어 성능저하의 원인이 됨.\n",
    "- 분산 DB간의 성능저하 해결방안\n",
    "- order_data에 조건에 해당하는 데이터만 원격으로 보내서 조인과 group by를 거친 결과 집합만 전송받음\n",
    "- 원격서버가 처리가능 하도록 driving_site 힌트 사용\n",
    "- 분산쿼리의 성능을 높이는 핵심은, 네트워크를 통한 데이터 전송량을 줄이는 데 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c722dc7",
   "metadata": {},
   "source": [
    "# 7. 사용자 정의 함수 / 프로시저의 특징과 성능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db08714",
   "metadata": {},
   "source": [
    "# 가. 사용자 정의 함수/프로시저의 특징\n",
    "- 가상머신과 같은 별도의 실행엔진을 통해 실행됨\n",
    "- 실행시마다 컨텍스트 스위칭이 일어나므로, 내장함수를 호출할때와 비교해서 성능이 상당히 떨어짐\n",
    "- 예시) 문자타입의 일자 데이터를 날짜 타입으로 변환해주는 사용자정의함수\n",
    "- to_char 함수를 바로 호출할때보다 훨씬 느림\n",
    "- 메인쿼리가 참조하는 사용자 정의 함수에 또 다른 쿼리문이 내장되어 있다면 수행 성능이 훨씬 나빠짐\n",
    "- 함수에 내장된 쿼리를 수행할 때마다 Execute Call, Fetch Call이 재귀적으로 일어남\n",
    "- Recusive Call이 반복적으로 일어남(User Call에 비해 성능부하가 미미하지만, 그 횟수가 무수히 반복되면 성능저하)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef0128c",
   "metadata": {},
   "source": [
    "## 나. 사용자 정의 함수/프로시저에 의한 성능 저하 해소 방안\n",
    "- 소량의 데이터를 조회할 때 사용\n",
    "- 부분범위 처리가 가능한 상황에서 제한적으로 사용\n",
    "- 가급적 함수를 풀어 조인 또는 스칼라 서브쿼리 형태로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a1663f",
   "metadata": {},
   "source": [
    "# 제4절. 데이터베이스 I/O원리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0cbbe1",
   "metadata": {},
   "source": [
    "## 1. 블록단위 I/O\n",
    "- 데이터 파일에서 DB 버퍼 캐시로 블록을 적재할 때\n",
    "- 데이터 파일에서 블록을 직접 읽고 쓸때\n",
    "- 버퍼 캐시에서 블록을 읽고 쓸때\n",
    "- 버퍼 캐시에서 변경된 블록을 다시 데이터 파일에 쓸때"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243b6b5c",
   "metadata": {},
   "source": [
    "## 2. 메모리 I/O vs. 디스크 I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1854d749",
   "metadata": {},
   "source": [
    "### 가. I/O 효율화 튜닝의 중요성\n",
    "- 디스크를 경우한 데이터 입출력은 디스크의 액세스 암(Arm)이 움직이면서 헤드를 통해 데이터를 읽고 쓰기 때문에 느림\n",
    "- 메모리를 통한 입출력은 전기적 신호에 불과하기 때문에 디스크를 통한 I/O에 대해 비교할수 없을정도로 빠름\n",
    "- 모든 DBMS는 읽고자 하는 블록을 먼저 버퍼 캐시에서 찾고, 없을경우에는 디스크에서 읽어 버퍼 캐시로 적재후 읽기/쓰기 작업을 수행\n",
    "- 이러한 이유로 모든 데이터를 메모리에 올려놓고 사용하면 좋겠지만 메모리는 물리적으로 한정된 자원\n",
    "- **결국 디스크 I/O를 최소화하고 버퍼 캐시 효율을 높이는 것이 데이터베이스 I/O 튜닝의 목표**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142464f7",
   "metadata": {},
   "source": [
    "### 나. 버퍼 캐시 히트율(Buffer Cache Hit Ratio)\n",
    "- 버퍼 캐시 효율을 측정하는 지표로써 전체 읽은 블록중 메모리 버퍼 캐시에서 찾은 비율   \n",
    "  BCHR = (버퍼 캐시에서 곧바로 찾은 블록 수 / 총 읽은 블록 수) x 100\n",
    "- BCHR은 주로 전체적인 관점에서 측정하지만, 개별 SQL에 대해서도 구해볼수 있으며, 이 비율이 낮은것이 SQL 성능을 떨어뜨리는 주범\n",
    "- Disk 항목이 디스크를 경유한 블록 수\n",
    "    - 총 읽은 블록 수 = 822\n",
    "    - 버퍼 캐시에서 곧바로 찾은 블록 수 = 822 - 18 = 804\n",
    "    - CHR = (822 - 18) / 822 = 97.8%\n",
    "- **논리적인 블록요청 횟수를 줄이고, 물리적으로 디스크에서 읽어야할 블록수를 줄이는것이 I/O 효율화 튜닝의 핵심 원리**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bf2e74",
   "metadata": {},
   "source": [
    "### 다. 네트워크, 파일시스템 캐시가 I/O 효율에 미치는 영향\n",
    "- 대용량의 데이터를 읽고 쓰는데 다양한 네트워크 기술이 사용됨에 따라 네트워크 속도도 SQL 성능에 크게 영향을 미친다.\n",
    "- RAC같은 클러스터링 환경에선 인스턴스 간에 캐시된 블록을 공유하므로 메모리 I/O의 성능에도 네트워크 속도가 지대한 영향을 미친다. \n",
    "- 같은양의 디스크 I/O가 발생하더라도 I/O 대기시간이 크게 차이 나는것은 디스크 경합 때문일수도 있지만, \n",
    "  OS에서 지원하는 파일시스템 버퍼 캐시와 SAN 캐시 때문일 수도 있다.\n",
    "- (SAN 캐시는 크다고 문제가 되지 않지만, 파일시스템 버퍼 캐시는 최소화 하여 데이터베이스 자체 캐시영역에 좀더 큰   \n",
    "  공간을 할당하는것이 더욱 효과적임)\n",
    "- **네트워크 문제든, 파일시스템 문제든 I/O 성능에 관한 가장 확실하고 근본적인 해결책은 논리적인블록 요청 횟수를 최소화 하는것**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de794e91",
   "metadata": {},
   "source": [
    "## 3. Sequential I/O vs. Random I/O\n",
    "- sequential 액세스는 논리적/물리적 순서를 따라 차례대로 읽어 나가는 방식\n",
    "    - 인덱스 리프 블록에 위치한 모든 레코드는 포인터를 논리적으로 연결되어 있고, 이 포인터를 따라 스캔하는 방식\n",
    "- Random 액세스는 레코드간 논리적, 물리적인 순서를 따르지 않고, 한건을 읽기 위해 한 블록씩 접근하는 방식\n",
    "- I/O 튜닝의 핵심 원리\n",
    "    - Sequential 액세스에 의한 선택 비중을 높인다.\n",
    "    - Random 액세스 발생량을 줄인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72734b8",
   "metadata": {},
   "source": [
    "### 가. Sequential 액세스에 의한 선택 비중 높이기\n",
    "- 읽는 총 건수 중에서 결과 집합으로 선택되는 비중을 높여야 함\n",
    "- 같은 결과를 얻기위해 얼마나 적은 레코드를 읽느냐로 효율성이 판단됨\n",
    "\n",
    "- good\n",
    "    - 전체 레코드 49,906건\n",
    "    - 선택 레코드 24,613건 (49%)\n",
    "    - 읽은 블록수 691 블록\n",
    "    - Table Full Scan 치고는 나쁘지 않음\n",
    "- bad    \n",
    "    - 전체 레코드 49,906건\n",
    "    - 선택 레코드 1건 (0.002%)\n",
    "    - 읽은 블록수 691 블록\n",
    "    - Table Full Scan 비효율 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faafa963",
   "metadata": {},
   "source": [
    "- 인덱스를 사용하고도 1개의 레코드를 읽기위해 76개 블록 액세스\n",
    "- 테이블 뿐 아니라, 인덱스를 sequential 액세스 방식으로 스캔할 때도 비효율 발생\n",
    "- 조건절에 사용된 컬럼과 연산자 형태, 인덱스 구성에 의해 효율성이 결정됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b4b0ed",
   "metadata": {},
   "source": [
    "### 나. Random 액세스 발생량 줄이기\n",
    "- Random 액세스 발생량을 낮추는 방법\n",
    "    - 인덱스로부터 만족하는 22,934건을 읽어 그 횟수만큼 테이블을 Random 액세스 수행하여 최종적으로 1건의 결과 추출\n",
    "    - 최종 선택된 것에 비해 너무 많은 Random 액세스 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cc564d",
   "metadata": {},
   "source": [
    "## 4. Single Block I/O vs.MultiBlock I/O\n",
    "- single Block I/O : 한번의 I/O Call에 하나의 데이터 블록만 읽어서 메모리에 적재하는 방식\n",
    "    - 인덱스를 통해 테이블을 액세스할때, 기본적으로 인덱스와 테이블 모두 이 방식 사용\n",
    "- Multi Block I/O: I/O Call이 필요한 시점에, 인접한 블록들을 같이 읽어 메모리에 적재하는 방식\n",
    "    - Table Full Scan 처럼 물리적으로 저장된 순서에 따라 읽을때 인접한 블록들을 같이 읽는것이 유리함\n",
    "    - 인접한 블록 : 하나의 익스텐트에 속한 블록"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89bbfd4",
   "metadata": {},
   "source": [
    "**Single Block I/O 방식**\n",
    "- 64번의 인덱스 블록을 디스크에서 읽으면서 64번의 I/O Call이 발생\n",
    "\n",
    "**MultiBlock I/O 방식**\n",
    "- 64개 블록을 디스크에서 읽었는데 I/O Call이 9번 발생\n",
    "- Oracle 10g부터는 Index Range Scan 또는 Index Full Scan일때도 Multiblock I/O 방식으로 읽는 경우가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c61dceb",
   "metadata": {},
   "source": [
    "## 5. I/O 효율화 원리\n",
    "- **논리적인 I/O 요청 횟수를 최소화 하는것이 I/O 효율화 튜닝의 핵심 원리**\n",
    "- I/O 때문에 성능이 낮게 측정될때, 하드웨어적인 방법을 통해 I/O 성능을 향상 시킬수도 있지만,  \n",
    "  SQL 튜닝을 통해 I/O 발생 횟수를 줄이는것이 근본적이고 확실한 해결 방법이다. \n",
    "- 애플리케이션 측면에서 이 I/O 효율화 원리\n",
    "    - 필요한 최소 블록만 읽도록 SQL 작성\n",
    "    - 최적의 옵티마이징 팩터 제공 \n",
    "    - 필요하다면, 옵티마이저 힌트를 사용하여 최적의 액세스 경로를 유도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce75098c",
   "metadata": {},
   "source": [
    "### 가. 필요한 최소 블록만 읽도록 SQL 작성\n",
    "- 비효율적인 액세스를 없애고 필요한 최소 블록만 액세스\n",
    "- 같은 테이블을 4번 액세스하여 처리하던 방식을 1번만 읽어서 처리할수 있도록 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8639fb7",
   "metadata": {},
   "source": [
    "### 나. 최적의 옵티마이징 팩터 제공\n",
    "- 전략적인 인덱스 구성\n",
    "    - 전략적인 인덱스 구성은 가장 기본적인 옵티마이징 팩터\n",
    "- DBMS가 제공하는 기능 활용\n",
    "    - 인덱스 외에도 DBMS가 제공하는 다양한 기능을 적극적으로 활용\n",
    "    - 인덱스, 파티션, 클러스터, 윈도우 함수 등을 적극 활용하여 옵티마이저가 최적의 선택을 할 수 있도록 한다. \n",
    "- 옵티마이저 모드 설정\n",
    "    - 옵티마이저모드(전체처리속도, 최초등담속도)와 그 외 옵티마이저 행동에 영향을 미치는 일부 파라미터를 변경해 주는것이 도움이 될 수 있다.\n",
    "- 통계정보\n",
    "    - 옵티마이저에게 정확한 정보를 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac70e92",
   "metadata": {},
   "source": [
    "### 다. 필요하다면, 옵티마이저 힌트를 사용해 최적의 액세스 경로로 유도\n",
    "- 최적의 옵티마이징 팩터를 제공했다면 가급적 옵티마이저에게 맡기는것이 바람직하지만,   \n",
    "  옵티마이저가 생각만큼 최적의 실행계획을 수립하지 못하는 경우 사용\n",
    "- 옵티마이저 힌트를 사용할 때 반드시 의도한 실행계획으로 수행되는지 확인해야 함\n",
    "- 여러가지로 옵티마이저 힌트 사용은 불가피함\n",
    "- 데이터베이스 애플리케이션 개발자라면 인덱스, 조인, 옵티마이저의 기본 원리를 이해 필요\n",
    "- 그것을 바탕으로 최적의 액세스 경로를 유도할 수 있는 능력을 필수적으로 갖춰야함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cdc8f0",
   "metadata": {},
   "source": [
    "# 2장. Lock과 트랜잭션 동시성 제어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d3032d",
   "metadata": {},
   "source": [
    "# 제 1절. Lock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7a60ed",
   "metadata": {},
   "source": [
    "# 1. Lock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39a5b4b",
   "metadata": {},
   "source": [
    "## 가. Lock이란?\n",
    "- 같은 자원을 액세스하려는 다중 트랜잭션 환경에서 데이터베이스의 일관성과 무결성을 유지하기 위해 트랜잭션의   \n",
    "  순차적 진행을 보장할 수 있는 직렬화(Serialization) 장치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdf0b06",
   "metadata": {},
   "source": [
    "## 나. 공유 Lock과 배타적 Lock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08dd12c",
   "metadata": {},
   "source": [
    "### 1) 공유 Lock\n",
    "- 공유(Shared) Lock은 데이터를 읽고자 할 때 사용\n",
    "- 다른 공유 Lock과는 호환되지만 배타적 Lock과는 호환되지 않음\n",
    "\n",
    "### 2) 배타적 lock\n",
    "- 배타적(Exclusive) Lock은 데이터를 변경하고자 할 때 사용되며, 트랜잭션이 완료될 때까지 유지\n",
    "- 해당 Lock이 해제될 때까지 다른 트랜잭션은 해당 Resource에 접근할 수 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c8b652",
   "metadata": {},
   "source": [
    "## 다. 블로킹과 교착상태\n",
    "### 1) 블로킹\n",
    "- Lock경합이 발생해 특정 세션이 작업을 진행하지 못하고 멈춰 선 상태\n",
    "- 공유 Lock과 배타적 Lock은 함께 설정될 수 없으므로 Blocking이 발생\n",
    "- Blocking을 해소 할 수 있는 방법은 COmmit(또는 Rollback)뿐이다.\n",
    "- Lock 경합이 발생하면 먼저 Lock이 완료될 때까지 후행 트랜잭션을 기다려야 한다. \n",
    "- Lock에 의한 성능 저하를 최소화 하는 방법\n",
    "    - 트랜잭션의 원자성을 훼손하지 않는 선에서 트랜잭션을 가능한 짧게 정의\n",
    "    - (Oracle은 데이터를 읽을 때 Shared Lock을 사용하지 않기 때문에 상대적으로 Lock 경합이 적음)\n",
    "    - 같은 데이터를 갱신하는 트랜잭션이 동시에 수행되지 않도록 설계 \n",
    "    - 주간에 대용량 갱신 작업이 불가피하다면, 블로킹 현상에 의해 사용자가 무한정 기다리지 않도록 적절한 프로그램 기법을 도입\n",
    "- 트랜잭션 격리성 수준(Isolation Level)를 불필요하게 상향 조정하지 않는다. \n",
    "- SQL문장이 가장 빠른ㄴ 시간 내에 처리를 완료하도록 하는 것이 Lock 튜닝의 기본이고 효과도 가장 좋다.\n",
    "\n",
    "### 2) 교착상태\n",
    "- 두 세션이 각각 Lock을 설정한 리소스를 서로 액세스하려고 마주보며 진행하는 상황, 둘 중 하나가 뒤로 물러나지 않으면 영영 풀릴 수 없다.\n",
    "- 여러 테이블을 액세스하면 발생하는 교착상태는 테이블 접근 순서를 같게 처리하여 회피 한다. \n",
    "- SQL Server라면 갱신(Update) Lock을 사용함으로써 교착상태 발생 가능성을 줄일 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff2f882",
   "metadata": {},
   "source": [
    "# 2. SQL Server Lock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ae81f2",
   "metadata": {},
   "source": [
    "## 가. Lock 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71d6451",
   "metadata": {},
   "source": [
    "### 1) 공유 Lock\n",
    "- SQL Server의 공유 Lock은 트랜잭션이나 쿼리 수행이 완료될 때까지 유지되는 것이 아니라 다음 레코드가 읽히면 곧바로 해제 된다. \n",
    "- Isolation Level을 변경하지 않고 트랜잭션 내에서 공유 Lock이 유지되도록 하려면 테이블 힌트로 지정하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c875c1",
   "metadata": {},
   "source": [
    "### 2) 배타적 Lcok\n",
    "- 데이터를 변경시 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb783ff9",
   "metadata": {},
   "source": [
    "### 3) 갱신 Lock\n",
    "- 만약 두 트랜잭션이 동시에 같은 고객에 대해서 Update를 수행시 두 트랜잭션 모두 처음에는 공유 Lock을 설정했다가 적립포인트를 변경하기  \n",
    "  직전에 배타적 Lock을 설정하려고 한다.\n",
    "- 이럴 경우 두 트랜잭션은 상대편 트랜잭션에 의한 공유 Lock이 해제되기만을 가디라는 교착상태에 빠지게 된다. \n",
    "- 이런 잠재적인 교착상태를 방지하려고 SQL Server는 갱신(Update)Lock을 사용할 수 있다.\n",
    "- 한 자원에 대한 갱신 Lock은 한 트랜잭션만 설정할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d26eb90",
   "metadata": {},
   "source": [
    "### 4) 의도 Lock\n",
    "- 특정 로우에 Lock을 설정하면 그와 동시에 상위 레벨 개체(페이지, 익스텐트, 테이블)에 내부적으로 의도(Intent)Lock이 설정된다.\n",
    "- Lock을 설정하려는 개체의 하위 레벨에서 선행 트랜잭션이 어떤 작업을 수행 중인지를 알리는 용도로 사용되며, 일조의 푯말(Flag)라고 할 수 있다.\n",
    "- 예를 들어, 구조를 변경하기 위해 테이블을 잠그려 할 때 그 하위의 모든 페이지나 익스텐트, 로우에 어떤 Lock이 설정돼 있는지 검사할 경우 \n",
    "  오래 소요 될 수 있으므로 해당 테이블에 어떤 모드의 의도 Lock이 설정돼 있는지만 보고도 작업을 진행할지 아니면 기다릴지를 결정할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6233e1",
   "metadata": {},
   "source": [
    "### 5) 스키마 Lock\n",
    "- Sch-S(Schema Stability) : SQL을 컴파일하면서 오브젝트 스키마를 참조할 때 발생하며, 읽는 스키마 정보가 수정되거나 삭제되지 못하도록 함\n",
    "- Sch-M(Schema Modification) : 테이블 구조를 변경하는 DDL문을 수행할 때 발생하며, 수정 중인 스키마 정보를 다른 세션이 참조하지 못하도록 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5340c21c",
   "metadata": {},
   "source": [
    "### 6) Bulk Update Lock\n",
    "- 테이블 Lock의 일종으로, 테이블에 데이터를 Bulk Copy할 때 발생한다.\n",
    "- 병렬 데이터 로딩(Bulk Insert나 bcp 작업을 동시 수행)을 허용하지만 일반적인 트랜잭션 작업은 허용되지 않는다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0b95b6",
   "metadata": {},
   "source": [
    "## 나. Lock 레벨과 Escalation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bd70fc",
   "metadata": {},
   "source": [
    "- 로우 레벨\n",
    "    - 변경하려는 로우(실제로는 RID)에만 Lock을 설정하는 것\n",
    "- 페이지 레벨\n",
    "    - 변경하려는 로우가 담긴 데이터 페이지(또는 인덱스 페이지)에 Lock을 설정하는 것\n",
    "    - 같은 페이지에 속한 로우는 진행 중인 변경 작업과 무관하더라도 모두 잠긴것과 같은 효과가 나타남\n",
    "- 익스텐트 레벨\n",
    "    - 익스텐트 전체가 잠김\n",
    "    - SQL Server의 경우, 하나의 익스텐트가 여덞 개 페이지로 구성되므로 8개 페이지에 속한 모든 로우가 잠긴 것과 같은 효과가 나타남\n",
    "- 테이블 레벨\n",
    "    - 테이블 전체 그리고 관련 인덱스까지 모두 잠김\n",
    "- 데이터베이스 레벨\n",
    "    - 데이터베이스 전체가 잠긴다.\n",
    "    - 보통 데이터베이스를 복구하거나 스키마를 변경할 때 일어 남"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46bf6f4",
   "metadata": {},
   "source": [
    "- 위 5가지 레벨 외에 인덱스 키에 로우 레벨 Lock을 거는 경우도 있음\n",
    "- Lock Escalation\n",
    "    - 관리할 Lock 리소스가 정해진 임계치를 넘으면 로우 레벨 락이 -> 페이지 -> 익스텐트 -> 테이블레벨 락으로 점검 확장되는 것을 의미\n",
    "- SQL Server, DB2 UDB 처럼 한정된 메모리 상에서 Lock 매니저를 통해 Lock 정보를 관리하는 DBMS에서 공통적으로 발생할 수 있는 현상\n",
    "- Locking 레벨이 낮을 수록 동시성은 좋지만 관리해야 할 Lock 개수가 증가하기 때문에 더 많은 리소스를 소비\n",
    "    - Locking 레벨이 높을 수록 적은 양의 Lock 리소스를 사용하지만 하나의 Lock으로 수많은 레코드를 한꺼번에 Locking하기 때문에 동시성은 나빠짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736e0f89",
   "metadata": {},
   "source": [
    "## 다. Lock 호환성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd53f037",
   "metadata": {},
   "source": [
    "- Intent Shared(IS) == IS, S, U, IX, SIX\n",
    "- Shared(S) == IS, S, U\n",
    "- Updated(U) == IS, S\n",
    "- Intent Exclusive(IX) == IS, IX\n",
    "- Shared with intent exclusive(SIX) == IS\n",
    "- EXclusive(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2395844",
   "metadata": {},
   "source": [
    "- 스키마 Lock 호환성\n",
    "    - Sch-S는 Sch-M을 제외한 모든 Lock과 호환\n",
    "    - Sch-M은 어떤 Lock과도 호환되지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c8bc7f",
   "metadata": {},
   "source": [
    "# 3. Oracle Lock\n",
    "- Oracle은 공유 리소스와 사용자 데이터를 보호할 목적으로 DML Lock, DDL Lock, 래치(Latch), 버퍼 Lock, 라이브러리 캐시  \n",
    "  Lock/Pin등 다양한 종류의 Lock을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa48b917",
   "metadata": {},
   "source": [
    "## 가. 로우 Lock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa7c781",
   "metadata": {},
   "source": [
    "- Oracle에서 로우 Lock은 항상 배타적이다.\n",
    "- INSERT, UPDATE, DELETE 문이나 SELECT...FOR UPDATE문을 수행한 트랜잭션에 의해 설정되면, 트랜잭션이 커밋 또는 롤백할 때까지   \n",
    "  다른 트랜잭션은 해당 로우를 변경할 수 없음\n",
    "- Oracle에서 읽는 과정에서는 어떤 Lock도 설정하지 않음으로 읽기와 갱신 작업은 서로 방해 하지 않음\n",
    "    - 읽으려는 데이터를 다른 트랜잭션이 갱신 중이더라도 기다리지 않음\n",
    "    - 갱신하려는 데이터를 다른 트랜잭션이 읽는 중이더라도 기다리지 않음(SELECT..FOR UPDATE 구문은 제외)\n",
    "    - 갱신하려는 데이터를 다른 트랜잭션이 갱신중이면 기다림\n",
    "- Oracle이 공유 Lock을 사용하지 않고도 일관성을 유지할 수 있는 것은 UNDO 데이터를 이용한 다중 버전 동시성 제어 매커니즘을 사용하기 때문.\n",
    "- Oracle은 별도의 Lock 매니저 없이 레코드의 속성으로서 로우 Lock을 구현했기 때문에 아무리 많은 레코드를 갱신하더라도 절대 Lock Escalation은 발생하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf8075b",
   "metadata": {},
   "source": [
    "## 나. 테이블 Lock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f596b7",
   "metadata": {},
   "source": [
    "- 한 트랜잭션이 로우 Lock을 얻는 순간, 해당 테이블에 대한 테이블 Lock도 동시에 얻어 현재 트랜잭션이 갱신중인 테이블에 대한 호환되지 않는  \n",
    "  DDL 오퍼레이션을 방지 한다.\n",
    "- 테이블 Lock 종류\n",
    "    - Row Share(RS)\n",
    "    - Row Exclusive(RX)\n",
    "    - Share(S)\n",
    "    - Share row Exclusive(SRX)\n",
    "    - Exclusive(X)\n",
    "- SELECT..FOR UPDATE 문을 수행할 때 RS 모드 테이블 Lock을 얻고, insert, update, delete 문을 수행할 때 RX 모드 테이블 Lock을 얻음\n",
    "- 일반적으로 DML 로우 Lock을 처음 얻는 순간 묵시적으로 테이블 Lock을 얻지만, 아래처럼 명령어를 이용해서도 가능\n",
    "- 테이블 Lock이라 하면, 테이블 전체에 Lock이 걸린다고 생각하기 쉬우나, Oracle의 테이블 Lock의 의미는, Lock을 획득한 선행 트랜잭션이 해당 테이블에서 현재 어떤 작업을 수행중인지를 알리는 일종의 푯말(Flag)이다.   \n",
    "  후행 트랜잭션은 어떤 테이블이 Lock이 설정돼 있는지만 보고도 그 테이블로의 진입 여부를 결정할 수 있다. \n",
    "- Oracle의 Lock 호환성\n",
    "    - NULL == NULL, RS, RX, S, SRX, X\n",
    "    - RS == NULL ,RS, RX, S, SRX\n",
    "    - RX == NULL, RS, RX\n",
    "    - S == NULL, RS, S\n",
    "    - SRX == NULL, RS\n",
    "    - X == NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5a0982",
   "metadata": {},
   "source": [
    "# 제 2절 트랜잭션\n",
    "- 트랜잭션(Transaction)은 업무 처리를 위한 논리적인 작업 단위이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c4e12c",
   "metadata": {},
   "source": [
    "## 1. 트랜잭션의 특징\n",
    "- 원자성(Atomicity)\n",
    "    - 트랜잭션은 더 이상 분해가 불가능한 업무의 최소단위이므로, 전부 처리되거나 아예 하나도 처리되지 않아야 함\n",
    "- 일관성(Consistency)\n",
    "    - 일관된 상태의 데이터베이스에서 하나의 트랜잭션을 성공적으로 완료하고 나면 그 데이터베이스는 여전히 일관된 상태여야 함.\n",
    "- 격리성(Isolation)\n",
    "    - 실행 중인 트랜잭션의 중간 결과를 다른 트랜잭션이 접근할 수 없음\n",
    "- 영속성(Durability)\n",
    "    - 트랜잭션이 일단 실행을 성공적으로 완료하면 그 결과는 데이터베이스에 영속적으로 저장."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6d0395",
   "metadata": {},
   "source": [
    "## 2. 트랜잭션 격리성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7ea0d7",
   "metadata": {},
   "source": [
    "## 가. 낮은 단계의 격리성 수준에서 발생할 수 있는 현상들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad1525",
   "metadata": {},
   "source": [
    "### 1) Dirty Read\n",
    "- 다른 트랜잭션에 의해 수정됐지만 아직 커밋되지 않음 데이터를 읽는 것을 의미\n",
    "- 변경 후 아직 커밋되지 않은 값을 읽었는데 변경을 가한 트랜잭션이 최종적으로 롤백된다면 그 값을 읽은 트랜잭션은 비일관된 상태에 놓이게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d079c366",
   "metadata": {},
   "source": [
    "### 2) Non-Repetable Read\n",
    "- 한 트랜잭션 내에서 같은 쿼리를 두 번 수행했는데, 그 사이에 다른 트랜잭션이 값을 수정 또는 삭제하는 바람에 두 쿼리에 결과가 다르게 나타나는 현상"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caceee9",
   "metadata": {},
   "source": [
    "### 3) Phantom Read\n",
    "- 한 트랜잭션 내에서 같은 쿼리를 두 번 수행했는데, 첫 번째 쿼리에서 없던 유령(Phantom) 레코드가 두 번째 쿼리에서 나타나는 현상\n",
    "- TX1 트랜잭션이 지역별고객과 연령대별 고객을 연속해서 집계하는 도중에 새로운 고객이 TX2 트랜잭션에 의해 등록\n",
    "- 그 결과, 지역별고객과 연령대별 고객 두 집계 테이블을 통해 총고객수를 조회하면 서로 결과 값이 다름"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b70b873",
   "metadata": {},
   "source": [
    "## 나. 트랜잭션 격리성 수준(Transaction Isolation Level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd577ee",
   "metadata": {},
   "source": [
    "- **Read Uncommitted** \n",
    "    - 트랜잭션에서 처리 중인 아직 커밋되지 않음 데이터를 다른 트랜잭션이 읽는 것을 허용\n",
    "    - Dirty Read, Non-Repeatable Read, Phantom Read\n",
    "- **Read Committed**\n",
    "    - 트랜잭션이 커밋되어 확정된 데이터만 다른 트랜잭션이 읽도록 허용함으로써 Dirty Read를 방지해줌.\n",
    "    - 커밋된 데이터만 읽더라도 Non-Repeatable Read와 Phantom Read 현상을 막지는 못함.\n",
    "    - Non-Repeatable Read, Phantom Read\n",
    "- **Repeatable Read**\n",
    "    - 트랜잭션 내에서 쿼리를 두 번 이상 수행할 때, 첫 번째 쿼리에 있던 레코드가 사라지거나 값이 바뀌는 현상을 방지해 줌\n",
    "    - 이는 트랜잭션 격리성 수준이 Phantom Read 현상을 막지는 못함.\n",
    "    - Phantom Read\n",
    "- **Serializable Read**\n",
    "    - 트랜잭션 내에서 쿼리를 두 번 이상 수행할 때, 첫 번째 쿼리에 있던 레코드가 사라지거나 값이 바뀌지 않음은 물론 새로운 레코드가  \n",
    "      나타나지도 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f7a0e8",
   "metadata": {},
   "source": [
    "- 모든 DBMS가 4가지 레벨을 다 지원하지 않음\n",
    "- SQL Server와 DB2는 4가지 레벨을 다 지원하지만 오라클은 Read Committed와 Serializable Read만 지원\n",
    "- 대부분의 DBMS는 Read Committed를 기본 트랜잭션 격리성 수준으로 사용\n",
    "- 다중 트랜잭션 환경에서 DBMS가 제공하는 기능을 이용해 동시성을 제어하려면 트랜잭션 시작 전에 명시적으로  \n",
    "  SET TRANSACTION 명령어를 수행하면 됨\n",
    "- 트랜잭션 격리성 수준을 Repeatable Read나 Serializable Read로 올리면 ISO에서 정한 기준을 만족해야 하며,  \n",
    "  대부분 DBMS가 이를 구현하기 위해 Locking 매커니즘에 의존한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12c3a20",
   "metadata": {},
   "source": [
    "# 제 3절. 동시성 제어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322bd42a",
   "metadata": {},
   "source": [
    "- DBMS는 다수의 사용자를 가정하며, 동시에 작동하는 다중 트랜잭션의 상호 간섭 작용에서 데이터베이스를 보호 할 수 있어야 하며, 이를 동시성 제어(Concurrency Control)이라 한다.\n",
    "- 동시성을 제어할 수 있도록 하기 위해 모든 DBMS가 공통적으로 Lock 기능을 제공\n",
    "- SET TRANSACTION 명령어를 이용해 트랜잭션 격리성 수준을 조정할 수 있는 기능도 제공.\n",
    "- SQL Server의 경우, 기본 트랜잭션 격리성 수준인 Read committed 상태에선 레코드를 읽고 다음 레코드로 이동하자 마자 공유 Lock을 해제하지만,   Repeatable Read로 올리면 트랜잭션을 커밋될 때까지 공유 Lock을 유지\n",
    "- 동시성과 일관성의 상관관계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1d5d61",
   "metadata": {},
   "source": [
    "## 1. 비관적 동시성 제어 vs. 낙관적 동시성 제어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d1da44",
   "metadata": {},
   "source": [
    "### 가. 비관적 동시성 제어 (Pessimistic concurrency Contorl)\n",
    "- 사용자들이 같은 데이터를 동시에 수정할 것이라고 가정\n",
    "- 데이터를 읽는 시점에 Lock을 걸고 트랜잭션이 완료될 때까지 이를 유지\n",
    "- select 시점에 Lock을 거는 비관적 동시성 제어는 자칫 시스템 동시성을 심각하게 떨어뜨릴 우려가 있음\n",
    "- 아래와 같이 wait 또는 nowait 옵션을 함께 사용하는 것이 바람직"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29b4979",
   "metadata": {},
   "source": [
    "### 나. 낙관적 동시성 제어(Optimistic concurrency control)\n",
    "- 사용자들이 같은 데이터를 동시에 수정하지 않을 것이라고 가정\n",
    "- 이런 이유로 데이터를 읽을 때는 Lock을 설정하지 않음\n",
    "- 대신 수정 시점에, 다른 사용자에 의해 값이 변경됐는지를 반드시 검사해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defc636e",
   "metadata": {},
   "source": [
    "## 2. 다중버전 동시성 제어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91b5329",
   "metadata": {},
   "source": [
    "### 가. 일반적인 Locking 메커니즘의 문제점\n",
    "- 동시성 제어의 목표는 동시에 실행되는 트랜잭션 수를 최대화하면서도 입력, 수정, 삭제 ,검색 시 데이터 무결성이 유지하는데 있다. \n",
    "- 읽기 작업에 공유 Lock을 사용하는 일반적인 Locking 매커니즘에서는 읽기 작업과 쓰기 작업이 서로 방해를 일으키기 때문에 종종 동시성에 문제가 발생\n",
    "- 데이터를 일관성에 문제가 생기는 경우도 있어 이를 해결하려면 Lock을 더 오랫동안 유지하거나 테이블 레벨 Lock을 사용해야 하므로 동시성 저하 발생\n",
    "- 비일관성 읽기 문제를 해결하기 위한 일반적인 해법은 트랜잭션 격리성 수준을 상향  \n",
    "  기본 트랜잭션 격리성 수준(Read comitted)에서는 값을 읽는 순간에만 공유 Lock을 걸었다가 다음 레코드로 이동할 떄 Lock을 해제함으로써 위와 같은 현상이 발생\n",
    "- 트랜잭션 격리성 수준을 Repeatable Read로 올리면 TX1 쿼리가 진행되는 동안 읽은 레코드는 공유 Lock이 계속 유지되며 심지어 쿼리가 끝나고 다음 쿼리가 진행되는 동안에도 유지된다.\n",
    "- 트랜잭션 격리성 수준을 올리면 일관성이 높아지지만, Lock이 더 오래 유지됨으로 인해 동시성 저하 시키고 교착상태가 발생할 가능성도 커짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa053e85",
   "metadata": {},
   "source": [
    "### 나. 다중버전 동시성 제어\n",
    "- ORACLE은 버전 3부터 다중버전 동시성 제어(Multiversion Concurrency Control, MVCC) 매커니즘을 사용\n",
    "- MS SQL Server 2005, IBM DB2 9.7버전 부터 동시성 매커니즘을 제공하기 시작\n",
    "- MVCC란?\n",
    "    - 데이터를 변경할 때마다 그 변경사항을 UNDO 영역에 저장\n",
    "    - 데이터를 읽다가 쿼리(또는 트랜잭션)시작 시점 이후에 변경된(변경이 진행중이거나 이미 커밋된)값을 발견하면, UNDO 영역에 저장된 정보를 이용해 쿼리(또는 트랜잭션)시작 시점의 일관성 있는 버전(CR Copy)를 생성하고 읽음\n",
    "    - 쿼리 도중 배타적 Lock이 걸린, 즉 변경이 진행 중인 레코드를 만나더라도 대기하지 않기 때문에 동시성 측면에 유리\n",
    "    - UNDO 블록 I/O, CR Copy 생성, CR 블록 캐싱 같은 부가적인 작업의 오버헤드 발생\n",
    "    - Oracle은 UNDO 데이터를 UNDO 세그먼트에 저장 혹, SQL Server는 tempdb에 저장\n",
    "    - MVCC는 문자수중과 트랜잭션 수준의 읽기 일관성이 존재"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c8d3ab",
   "metadata": {},
   "source": [
    "### 다. 문장수준 읽기 일관성\n",
    "- 다른 트랜잭션에 의해 데이터의 추가, 변경, 삭제가 발생하더라도 단일 SQL문 내에서 일관성 있게 값을 읽는것을 말함.\n",
    "- 위의 그림은 10023 시점에서 시작된 쿼리가 10023 시점 이후에 변경된 데이터 블록을 만났을 때,   \n",
    "  Rollback(=UNDO) 세그먼트에 저장된 정보를 이용해 10023 이전 시점으로 되돌리고서 값을 읽는 것을 표현\n",
    "- SQL Server에서 문장수준 읽기 일관성 모드로 DB를 운영하려면 아래 명령어를 수행."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a11d2b",
   "metadata": {},
   "source": [
    "### 라. 트랜잭션 수준 읽기 일관성\n",
    "- 트랜잭션 수준 읽기 일관성은, 다른 트랜잭션에 의해 데이터의 추가, 변경 삭제가 발생하더라도 트랜잭션 내에서 일관성 있게 값을 읽는 것\n",
    "- Read committed에서 완벽한 문장수준의 읽기 일관성을 보장하는 MVCC 매커니즘도 트랜잭션 수준의 읽기 일관성은 보장하지 않음\n",
    "- 일반적인 Locking 매커니즘도 트랜잭션 수준의 읽기 일관성은 보장하지 않음\n",
    "- 트랜잭션 수준으로 완벽한 읽기 일관성을 보장받으려면 격리성 수준을 Serializable Read로 올려주어야 함.\n",
    "- Isolation Level을 Serializable Read로 상향조정하면, 일관성 기준 시점은 트랜잭션 시작 시점이 된다.  \n",
    "  물론 트랜잭션이 진행되는 동안 자신이 발생시킨 변경사항은 그대로 읽음\n",
    "- UNDO 데이터를 활용함으로써 높은 수준의 동시성과 읽기 일관성을 유지하는 대신, 일반적인 Locking 매커니즘에 없는 SNAPSHOT TOO OLD 에러가 MVCC에서 발생\n",
    "- UNDO 영역에 저장된 UNDO 정보가 다른 트랜잭션에 의해 재사용돼 필요한 CR Copy을 생성할 수 없을 때 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e4758",
   "metadata": {},
   "source": [
    "- SNAPSHOT TOO OLD 발생 가능성을 줄이는 방법\n",
    "    - UNDO 영역의 크기를 증가\n",
    "    - 불필요한 커밋을 자주 수행하지 않음\n",
    "    - FETCH ACROSS COMMIT 형태의 프로그램 작성을 피해 다른 방식으로 구현\n",
    "    - ANSI 표준에 따르면 커밋 이전에 열려 있던 커서는 더는 FETCH 하면 안됨\n",
    "    - 트랜잭션이 몰리는 시간대에 오래 걸리는 쿼리가 같이 수행되지 않도록 조정\n",
    "    - 큰 테이블을 일정 범위로 나누어 읽고 단계적으로 실행할 수 있도록 코딩\n",
    "    - SNAPSHOT TOO OLE 발생 가능성을 줄일 뿐 아니라 문제가 발생시 특정 부분부터 다시 시작할 수 있음 -> 읽기 일관성에 문제가 없을때만 적용\n",
    "    - 오랜 시간에 걸쳐 같은 블록을 여러번 방문하난 NL Join 형태의 조인문 또는 인덱스를 경유한 테이블 액세스를 수반하는 프로그램이 있는지 체크\n",
    "    - 이를 회피할 수 있는 방법(조인 메소드 변경, FUll Table Scan등)을 찾음\n",
    "    - 소트 부하를 감수하더라도 order by 등을 강제로 삽입해 소트 연산이 발생하도록 함 \n",
    "    - 대량 업데이트 후에 곧바로 해당 테이블 또는 인덱스를 Full Scan 하도록 쿼리를 수행하는 것도 하나의 해결 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e19621c",
   "metadata": {},
   "source": [
    "ㅇㄴㅇㄴ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cacaa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

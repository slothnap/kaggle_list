{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e69a03b2",
   "metadata": {},
   "source": [
    "# 01 분류(Classification)의 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e288a5b",
   "metadata": {},
   "source": [
    "### 지도학습 ###\n",
    "레이블(Label), 즉 명시적인 정답이 있는 데이터가 주어진 상태에서 학습하는 머신러닝 방식  \n",
    "\n",
    "**분류(Classification)**  \n",
    "* 지도학습의 대표적인 유형\n",
    "* 학습 데이터로 주어진 데이터의 피처와 레이블값(결정 값, 클래스 값)을 머신러닝 알고리즘으로 학습해 모델을 생성\n",
    "* 이렇게 생성된 모델에 새로운 데이터 값이 주어졌을 때 미지의 레이블 값을 예측하는 것  \n",
    "\n",
    "**머신러닝 알고리즘**  \n",
    "* 베이즈(Bayes) 통계와 생성 모델에 기반한 나이브 베이즈(Naive Dayes)\n",
    "* 독립변수와 종속변수의 선형 관계성에 기반한 로지스틱 회귀(Logistic Regression)\n",
    "* 데이터 균일도에 따른 규칙 기반의 결정 트리(Decision Tree)\n",
    "* 개별 클래스 간의 최대 분류 마진을 효과적으로 찾아주는 서포트 벡터 머신(Support Vector Machine)\n",
    "* 근접 거리를 기준으로 하는 최소 근접(Nearest Neighbor) 알고리즘\n",
    "* 심층 연결 기반의 신경망(Neural Network)\n",
    "* 서로 다른(또는 같은) 머신러닝 알고리즘을 결합한 앙상블(Ensemble)\n",
    "\n",
    "**신경망**\n",
    "* 이미지, 영상, 음성, NLP 영역에 효과\n",
    "\n",
    "**앙상블**\n",
    "* 신경망을 제외한 정형 데이터의 예측 분석 영역 효과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefdc203",
   "metadata": {},
   "source": [
    "### 앙상블  \n",
    "- 기본 알고리즘은 **결정 트리**\n",
    "\n",
    "**배깅(Bagging)** \n",
    "- 랜덤 포레스트(Random Forest)\n",
    "\n",
    "**부스팅(Boosting)**\n",
    "- 그래디언트 부스팅(Gradient Boosting)\n",
    "- XgBoost(eXtra Gradient Boost)\n",
    "- LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db624981",
   "metadata": {},
   "source": [
    "# 02 결정 트리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae955c3b",
   "metadata": {},
   "source": [
    "### 결정 트리(Decision Tree)\n",
    "- 데이터에 있는 규칙을 학습을 통해 자동으로 찾아내 트리(Tree) 기반의 분류 규칙을 만드는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1f5602",
   "metadata": {},
   "source": [
    "### 결정 트리 구조\n",
    "* 트리의 깊이(Depth)가 깊어질수록 결정 트리의 예측 성능이 저하될 가능성 증가\n",
    "\n",
    "**규칙 노드(Decision Node)**\n",
    "* 규칙 조건 \n",
    "\n",
    "**리프 노드(Leaf Node)**\n",
    "* 결정된 클래스 값\n",
    "\n",
    "**서브 트리(Sub Tree)**\n",
    "* 새로운 규직 조건"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8a1f3b",
   "metadata": {},
   "source": [
    "### 정보의 균일도\n",
    "- 엔트로피를 이용한 정보 이득(Information Gain) 지수와 지니 계수\n",
    "\n",
    "**엔트로피**\n",
    "- 주어진 데이터 집합의 혼잡도를 의미\n",
    "- 서로 다른 값이 섞여 있으면 엔트로피가 높다\n",
    "- 같은 값이 섞여 있으면 엔트로피가 낮다\n",
    "\n",
    "**정보 이득 지수**\n",
    "- 1에서 엔트로피 지수를 뺀 값 \"1 - 엔트로피\"\n",
    "- 결정 트리는 이 정보 이득 지수로 분할 기준을 정한다.\n",
    "- 정보 이득이 높은 속성을 기준으로 분할\n",
    "\n",
    "**지니 계수**\n",
    "- 0이 가장 평등\n",
    "- 1로 갈수록 불평등\n",
    "- 머신러닝 적용할 때는 지니 계수가 낮을 수록 데이터 균일도가 높다\n",
    "- 지니 계수가 낮은 속성을 기준으로 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c058e338",
   "metadata": {},
   "source": [
    "## 결정 트리 모델의 특징"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7ee689",
   "metadata": {},
   "source": [
    "### 장점 \n",
    "- 쉽다. 직관적이다\n",
    "- 정보의 '균일도'라는 룰을 기반\n",
    "- 정보의 균일도만 신경 쓰면 된다. \n",
    "- 각 피처의 스케일링과 정규화 같은 전처리 작업이 필요치 않다\n",
    "\n",
    "\n",
    "### 단점\n",
    "- 과적합으로 정확도가 떨어진다는 점\n",
    "- 트리의 크기를 사전에 제한하는 튜닝 필요\n",
    "- 피처 정보의 균일도에 따른 룰 규칙으로 서브 트리를 계속 만들다 보면  \n",
    "  피처가 많고 균일도가 다양하게 존재할 수록 트리의 깊이가 커지고 복잡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9920d69d",
   "metadata": {},
   "source": [
    "## 결정 트리 파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caea7cbd",
   "metadata": {},
   "source": [
    "### 사이킷런 결정 트리 알고리즘\n",
    "**DecisionTreeClassifier**\n",
    "- 분류를 위한 클래스\n",
    "\n",
    "**DecisionTreeRegressor**\n",
    "- 회귀를 위한 클래스\n",
    "\n",
    "**CART(Classification And Regression Trees)**\n",
    "- 사이킷런의 결정 트리 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15451468",
   "metadata": {},
   "source": [
    "### DecisionTreeRegressor 파라미터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84ec1d1",
   "metadata": {},
   "source": [
    "**min_samples_split**\n",
    "- 노드를 분할하기 위한 최소한의 샘플 데이터 수로 과적합을 제어하는 데 사용됨.\n",
    "- 디폴트는 2이고 작게 설정할 수록 분할되는 노드가 많아져서 과적합 가능성 증가\n",
    "- 과적합을 제어. 1로 설정할 경우 분할되는 노드가 많아져서 과적합 가능성 증가\n",
    "\n",
    "**min_samples_leaf**\n",
    "- 말단 노드(Leaf)가 되기 위한 최소한의 샘플 데이터 수\n",
    "- Min_samples_split와 유사하게 과적합 제어 용도. 그러나 비대칭적(imbalanced) 데이터의 경우  \n",
    "  특정 클래스의 데이터가 극도로 작을 수 있으므로 이 경우는 작게 설정 필요.\n",
    "  \n",
    "**max_features**\n",
    "- 최적의 분할을 위해 고려할 최대 피처 개수. 디폴트는 None으로 데이터 세트의 모든 피쳐를 사용해 분할 수행 \n",
    "- int 형으로 지정하면 대상 피처의 개수, float 형으로 지정하면 전체 피처 중 대상 피처의 퍼센트임\n",
    "- 'sqrt'는 전체 피처 중 sqrt(전체 피처 개수), 즉 √전체 피처 개수 만큼 선정\n",
    "- 'auto'로 지정하면 sqrt와 동일\n",
    "- 'log'는 전체 피처 중 log2(전체 피처 개수) 선정\n",
    "- 'None'은 전체 피처 선정\n",
    "\n",
    "**max_depth**\n",
    "- 트리의 최대 깊이를 규정.\n",
    "- 디폴트는 None. None으로 설정하면 완벽하게 클래스 결정 값이 될 때까지 깊이를 계속 키우며 분할하거나 노드가 가지는 데이터 개수가   \n",
    "  min_samples_split보다 작아질 때까지 계속 깊이를 증가시킴\n",
    "- 깊이가 깊어지면 min_samples_split 설정대로 최대 분할하여 과적합할 수 있으므로 적절한 값으로 제어 필요\n",
    "\n",
    "**max_leaf_nodes**\n",
    "- 말단 노드(Leaf)의 최대 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936c10c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07821453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3d704a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d8992c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a64ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d85b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90616392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff2458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
